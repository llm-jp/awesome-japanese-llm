# æ—¥æœ¬èªLLMã¾ã¨ã‚
[ [**English**](./en/) | [**FranÃ§ais**](./fr/) | æ—¥æœ¬èª ]

<div class="github-only">

> **ğŸ“– ã‚ˆã‚Šèª­ã¿ã‚„ã™ã„Webç‰ˆã‚’ã”åˆ©ç”¨ãã ã•ã„**
> 
> ã“ã®READMEã®å†…å®¹ã¯ã€**[llm-jp.github.io/awesome-japanese-llm](https://llm-jp.github.io/awesome-japanese-llm)** ã§ã‚ˆã‚Šè¦‹ã‚„ã™ã„å½¢å¼ã§ã”è¦§ã„ãŸã ã‘ã¾ã™ã€‚è¡¨ã®è¡¨ç¤ºå´©ã‚Œã‚„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å•é¡Œã‚’é˜²ããŸã‚ã€Webç‰ˆã®é–²è¦§ã‚’æ¨å¥¨ã„ãŸã—ã¾ã™ã€‚

</div>

ã“ã®è¨˜äº‹ã¯ã€ä¸€èˆ¬å…¬é–‹ã•ã‚Œã¦ã„ã‚‹æ—¥æœ¬èªLLMï¼ˆæ—¥æœ¬èªã‚’ä¸­å¿ƒã«å­¦ç¿’ã•ã‚ŒãŸLLMï¼‰ãŠã‚ˆã³æ—¥æœ¬èªLLMè©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚æƒ…å ±ã¯ã€æœ‰å¿—ã«ã‚ˆã‚Šåé›†ã•ã‚Œã¦ãŠã‚Šã€ãã®ä¸€éƒ¨ã¯è«–æ–‡ã‚„å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãƒªã‚½ãƒ¼ã‚¹ãªã©ã‹ã‚‰å¼•ç”¨ã—ã¦ã„ã¾ã™ã€‚

::: warning ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦ã€ã‚ã‚‰ã‹ã˜ã‚ã”ç†è§£ã¨ã”äº†æ‰¿ã‚’ãŠé¡˜ã„ã„ãŸã—ã¾ã™
1. æœ¬è¨˜äº‹ã®å†…å®¹ã¯ã€å®Œå…¨æ€§ã‚„æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã‚Œã‚‰ã®æƒ…å ±ã¯äºˆå‘Šãªãå¤‰æ›´ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã€ã¾ãŸæœ€æ–°ã®æƒ…å ±ã‚’å¸¸ã«æä¾›ã§ãã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚
2. ä¸€éƒ¨ã®æƒ…å ±ã¯ã€æ¨æ¸¬ã‚„å€‹ã€…ã®åˆ©ç”¨è€…ã®è§£é‡ˆã«ã‚‚ã¨ã¥ãã‚‚ã®ã§ã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãã®ãŸã‚ã€å…¨ã¦ã®èª­è€…ã«ã¨ã£ã¦å¿…ãšã—ã‚‚æ­£ç¢ºã§ã‚ã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚
3. æœ¬è¨˜äº‹ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å¤šãã¯ã€MIT ã‚„ Apache-2.0 ã¨ã„ã£ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒé©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã—ã‹ã—ãªãŒã‚‰ã€**ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã«ã¯ã€éå–¶åˆ©é™å®šã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ï¼ˆä¾‹ï¼šCC BY-NC-SA 4.0ï¼‰ã‚„é–‹ç™ºå…ƒç‰¹æœ‰ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒé©å¿œã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã¯å¿…ãšã—ã‚‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã¯è¨€ãˆãªã„å¯èƒ½æ€§ãŒã‚ã‚‹**ç‚¹ã«ã”æ³¨æ„ãã ã•ã„ã€‚
4. å€‹äººãŒé–‹ç™ºã—ãŸãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹è¨˜è¿°ã§ã¯ã€ä½œæˆè€…ã®æ•¬ç§°ã¯çœç•¥ã•ã›ã¦ã„ãŸã ã„ã¦ãŠã‚Šã¾ã™ã€‚
:::

ã“ã®è¨˜äº‹ã®ç®¡ç†ã¯ GitHub ã§è¡Œã£ã¦ã„ã¾ã™ã€‚è¨˜äº‹ã®é–“é•ã„ã‚’ç™ºè¦‹ã—ãŸå ´åˆã€ã‚ã‚‹ã„ã¯ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ ææ¡ˆã‚’è¡Œã„ãŸã„å ´åˆã¯ã€[GitHub Issues](https://github.com/llm-jp/awesome-japanese-llm/issues) çµŒç”±ã§å ±å‘Šã—ã¦ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚

::: details ç›®æ¬¡
[[toc]]
:::

<a id="generative"></a>
## ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ä¸»ã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«

*ç”»åƒã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯[ã“ã¡ã‚‰](#multimodal-text-generation)*

<a id="full-scratch-models"></a>
### ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒå­¦ç¿’ãƒ¢ãƒ‡ãƒ«

<a id="generative-scratch-general"></a>
#### æ±ç”¨

|    | å…¬é–‹å¹´ |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å…¥å‡ºåŠ›ã§æ‰±ãˆã‚‹<br>ãƒˆãƒ¼ã‚¯ãƒ³æ•°  |  å­¦ç¿’ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ / åˆ©ç”¨è¦ç´„ |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|
| [Sarashina2-8x70B](https://www.sbintuitions.co.jp/news/press/20241108_01/) | 2024 | MoE<br>([8x70b (**465b**)](https://huggingface.co/sbintuitions/sarashina2-8x70b)) | 8,192 | Sarashina2 (70B) ã«å¯¾ã—ã¦ Sparse Upcycling ã§å­¦ç¿’ | SB Intuitions | Sarashina Model NonCommercial License |
| [LLM-jp-3 172B](https://www.nii.ac.jp/news/release/2024/1224.html) | 2024 | Llama<br>([**172b**](https://huggingface.co/llm-jp/llm-jp-3-172b), [**172b**-instruct2](https://huggingface.co/llm-jp/llm-jp-3-172b-instruct2), [**172b**-instruct3](https://huggingface.co/llm-jp/llm-jp-3-172b-instruct3)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)<br>(è¨ˆ **2.1T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), [AnswerCarefully Dataset](https://llmc.nii.ac.jp/answercarefully-dataset/), [magpie-sft-v1.0](https://huggingface.co/datasets/llm-jp/magpie-sft-v1.0), Daring-Anteater, FLAN, ichikara-instruction-format, AutoMultiTurnByCalm3-22B, ramdom-to-fixed-multiturn-Calm3, wizardlm8x22b-logical-math-coding-sft-ja, wizardlm8x22b-logical-math-coding-sft_additional-ja, Synthetic-JP-EN-Coding-Dataset-567k<br>DPO (instruct3 only): [aya-ja-evol-inst](https://huggingface.co/datasets/llm-jp/aya-ja-evol-inst), [ac-self-inst](https://huggingface.co/datasets/llm-jp/ac-self-inst) | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: LLM-jp-3 172B Terms of Use<br>äº‹å¾Œå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: llm-jp-3-172b-instruct3åˆ©ç”¨è¨±è«¾å¥‘ç´„ |
| [LLM-jp-3 172B beta2](https://llmc.nii.ac.jp/topics/llm-jp-3-172b-beta2/) | 2024 | Llama<br>([**172b**-beta2](https://huggingface.co/llm-jp/llm-jp-3-172b-beta2), [**172b**-beta2-instruct2](https://huggingface.co/llm-jp/llm-jp-3-172b-beta2-instruct2)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)ã®ä¸€éƒ¨<br>(è¨ˆ **1.4T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), [AnswerCarefully Dataset](https://llmc.nii.ac.jp/answercarefully-dataset/), [magpie-sft-v1.0](https://huggingface.co/datasets/llm-jp/magpie-sft-v1.0), Daring-Anteater, FLAN, ichikara-instruction-format, AutoMultiTurnByCalm3-22B, ramdom-to-fixed-multiturn-Calm3, wizardlm8x22b-logical-math-coding-sft-ja, wizardlm8x22b-logical-math-coding-sft_additional-ja, Synthetic-JP-EN-Coding-Dataset-567k | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | LLM-jp-3 172B beta2 Terms of Use |
| [LLM-jp-3 172B beta1](https://www.nii.ac.jp/news/release/2024/0917.html) | 2024 | Llama<br>([**172b**-beta1](https://huggingface.co/llm-jp/llm-jp-3-172b-beta1), [**172b**-beta1-instruct](https://huggingface.co/llm-jp/llm-jp-3-172b-beta1-instruct)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)ã®ä¸€éƒ¨<br>(è¨ˆ **0.7T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), [AnswerCarefully Dataset](https://llmc.nii.ac.jp/answercarefully-dataset/), Dolly Dataset, OASST1, OASST2, Aya Dataset, 	ichikara-instruction-format, Daring-Anteater, FLAN | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | LLM-jp-3 172B beta1 Terms of Use |
| [LLM-jp-3 172B alpha](https://llmc.nii.ac.jp/topics/llm-jp-3-172b-alpha1-alpha2/) | 2024 | Llama<br>([**172b**-alpha1](https://huggingface.co/llm-jp/llm-jp-3-172b-alpha1), [**172b**-alpha1-instruct](https://huggingface.co/llm-jp/llm-jp-3-172b-alpha1-instruct), [**172b**-alpha2](https://huggingface.co/llm-jp/llm-jp-3-172b-alpha2), [**172b**-alpha2-instruct](https://huggingface.co/llm-jp/llm-jp-3-172b-alpha2-instruct)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)ã®ä¸€éƒ¨<br>(alpha1: è¨ˆ **0.7T** ãƒˆãƒ¼ã‚¯ãƒ³, alpha2: è¨ˆ **1.4T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), [AnswerCarefully Dataset](https://llmc.nii.ac.jp/answercarefully-dataset/), Dolly Dataset, OASST1, OASST2, Aya Dataset, 	ichikara-instruction-format, Daring-Anteater, FLAN | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 |
| [Stockmark-2-100B-Instruct-beta](https://stockmark.co.jp/news/20250318) | **2025** | Llama<br>([**100B**-Instruct-beta](https://huggingface.co/stockmark/Stockmark-2-100B-Instruct-beta), [**100B**-Instruct-beta-AWQ](https://huggingface.co/stockmark/Stockmark-2-100B-Instruct-beta-AWQ)) | 4,096 | äº‹å‰å­¦ç¿’: è¨ˆ **1.5T** ãƒˆãƒ¼ã‚¯ãƒ³<br>Instruction Tuning<br>DPO | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | MIT |
| [Stockmark-100b](https://stockmark.co.jp/news/20240516) | 2024 | Llama<br>([**100b**](https://huggingface.co/stockmark/stockmark-100b), [**100b**-instruct-v0.1](https://huggingface.co/stockmark/stockmark-100b-instruct-v0.1)) | 4,096 | äº‹å‰å­¦ç¿’: RedPajama, æ—¥æœ¬èª Wikipedia, Japanese mC4, Japanese CommonCrawl, æ—¥æœ¬èªç‰¹è¨±, Stockmark Web Corpus<br>(è¨ˆ **910B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning (LoRA): [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/) | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | MIT |
| [PLaMo-100B-Pretrained](https://www.preferred.jp/ja/news/pr20241015/) | 2024 | Llama[^22]<br>([**100b**](https://huggingface.co/pfnet/plamo-100b)) | 4,096 | äº‹å‰å­¦ç¿’: Japanese CommonCrawl, RefinedWeb, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ: **2.0T** ãƒˆãƒ¼ã‚¯ãƒ³) | Preferred Elements (Preferred Networks) | PLaMo Non-Commercial License |
| [LLM-jp-3.1](https://llm-jp.nii.ac.jp/ja/blog/blog-887/) | **2025** | Llama/MoE<br>([**8x13b**-instruct4](https://huggingface.co/llm-jp/llm-jp-3.1-8x13b-instruct4), [**13b**-instruct4](https://huggingface.co/llm-jp/llm-jp-3.1-13b-instruct4), [**1.8b**-instruct4](https://huggingface.co/llm-jp/llm-jp-3.1-1.8b-instruct4)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)<br>(è¨ˆ **2.5T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>ç¶™ç¶šäº‹å‰å­¦ç¿’: ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒšã‚¢<br>(è¨ˆ **90B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>SFT + DPO | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 |
| [LLM-jp-3 MoE](https://llm-jp.nii.ac.jp/ja/blog/blog-603/) | **2025** | MoE<br>([8x1.8b (**9.3b**)](https://huggingface.co/llm-jp/llm-jp-3-8x1.8b), [8x1.8b (**9.3b**)-instruct2](https://huggingface.co/llm-jp/llm-jp-3-8x1.8b-instruct2), [8x1.8b (**9.3b**)-instruct3](https://huggingface.co/llm-jp/llm-jp-3-8x1.8b-instruct3), [8x13b (**73b**)](https://huggingface.co/llm-jp/llm-jp-3-8x13b), [8x13b (**73b**)-instruct2](https://huggingface.co/llm-jp/llm-jp-3-8x13b-instruct2), [8x13b (**73b**)-instruct3](https://huggingface.co/llm-jp/llm-jp-3-8x13b-instruct3)) | 4,096 | LLM-jp-3 (1.8b, 13b) ã«å¯¾ã—ã¦ Drop-Upcycling ã§å­¦ç¿’ | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 |
| [Sarashina2](https://www.sbintuitions.co.jp/news/press/20240614_01/) | 2024 | Llama<br>([**7b**](https://huggingface.co/sbintuitions/sarashina2-7b), [**13b**](https://huggingface.co/sbintuitions/sarashina2-13b), [**70b**](https://huggingface.co/sbintuitions/sarashina2-70b)) | 7b, 13b: 4,096<br>70b: 8,192 | äº‹å‰å­¦ç¿’: Japanese Common Crawl, SlimPajama, StarCoder<br>(è¨ˆ **2.1T** ãƒˆãƒ¼ã‚¯ãƒ³) | SB Intuitions | MIT |
| [Sarashina1](https://www.sbintuitions.co.jp/news/press/20240614_01/) | 2024 | GPT-NeoX<br>([**7b**](https://huggingface.co/sbintuitions/sarashina1-7b), [**13b**](https://huggingface.co/sbintuitions/sarashina1-13b), [**65b**](https://huggingface.co/sbintuitions/sarashina1-65b)) | 2,048 | äº‹å‰å­¦ç¿’: Japanese Common Crawl<br>(è¨ˆ **1T** ãƒˆãƒ¼ã‚¯ãƒ³) | SB Intuitions | MIT |
| [Tanuki-8Ã—8B](https://weblab.t.u-tokyo.ac.jp/2024-08-30/) | 2024 | MoE (**47b**)<br>([v1.0](https://huggingface.co/weblab-GENIAC/Tanuki-8x8B-dpo-v1.0), [v1.0-AWQ](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0-AWQ), [v1.0-GPTQ-4bit](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0-GPTQ-4bit), [v1.0-GPTQ-8bit](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0-GPTQ-8bit), [v1.0-GGUF](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0-GGUF)) | 4,096 | äº‹å‰å­¦ç¿’: æ§˜ã€…ãª Web ä¸Šã®ãƒ‡ãƒ¼ã‚¿, åˆæˆãƒ‡ãƒ¼ã‚¿ï¼ˆè¨ˆ **1.7T** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰<br>SFT, DPO: æ§˜ã€…ãªåˆæˆãƒ‡ãƒ¼ã‚¿ [^19] | æ¾å°¾ç ”LLMé–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Apache 2.0 |
| [PLaMo 3](https://tech.preferred.jp/ja/blog/plamo_3_8b_31b/) | **2025** | Gemma ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>([**2b**-base](https://huggingface.co/pfnet/plamo-3-nict-2b-base), [**8b**-base](https://huggingface.co/pfnet/plamo-3-nict-8b-base), [**31b**-base](https://huggingface.co/pfnet/plamo-3-nict-31b-base)) | 4,096 | äº‹å‰å­¦ç¿’: è‹±èªã€æ—¥æœ¬èªã€ã‚³ãƒ¼ãƒ‰ã€å¤šè¨€èª<br>(2b: **200B** ãƒˆãƒ¼ã‚¯ãƒ³, 8b: **1T** ãƒˆãƒ¼ã‚¯ãƒ³, 31b: **3T** ãƒˆãƒ¼ã‚¯ãƒ³) | Preferred Networks | PLaMo community license |
| [Way-PLaMo-3-8b-chat](https://huggingface.co/WayBob/Way-sft-plamo-3-8b-chat) | **2025** | PLaMo 3ãƒ™ãƒ¼ã‚¹ ([**8b**-chat](https://huggingface.co/WayBob/Way-sft-plamo-3-8b-chat)) | 4,096 | Instruction Following SFT: [Alpaca](https://huggingface.co/datasets/yahma/alpaca-cleaned) (51.7K), [Dolly-15k-ja](https://huggingface.co/datasets/kunishou/databricks-dolly-15k-ja) (15K) | å€‹äºº (WayBob) | PLaMo community license |
| [CyberAgentLM3 (CALM3)](https://www.cyberagent.co.jp/news/detail/id=30463) | 2024 | Llama<br>([**22b**-chat](https://huggingface.co/cyberagent/calm3-22b-chat), [**22b**-chat-selfimprove-experimental](https://huggingface.co/cyberagent/calm3-22b-chat-selfimprove-experimental)) | **16,384** | ä¸æ˜<br>(è¨ˆ **2.0T** ãƒˆãƒ¼ã‚¯ãƒ³) | ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | Apache 2.0 |
| [LLM-jp-3 13B instruct3](https://llm-jp.nii.ac.jp/blog/2025/02/05/instruct3.html) | **2025** | Llama<br>([150m](https://huggingface.co/llm-jp/llm-jp-3-150m), [150m-instruct2](https://huggingface.co/llm-jp/llm-jp-3-150m-instruct2), [150m-instruct3](https://huggingface.co/llm-jp/llm-jp-3-150m-instruct3), [440m](https://huggingface.co/llm-jp/llm-jp-3-440m), [440m-instruct2](https://huggingface.co/llm-jp/llm-jp-3-440m-instruct2), [440m-instruct3](https://huggingface.co/llm-jp/llm-jp-3-440m-instruct3), [980m](https://huggingface.co/llm-jp/llm-jp-3-980m), [980m-instruct2](https://huggingface.co/llm-jp/llm-jp-3-980m-instruct2), [980m-instruct3](https://huggingface.co/llm-jp/llm-jp-3-980m-instruct3), [**1.8b**-instrcut2](https://huggingface.co/llm-jp/llm-jp-3-1.8b-instruct2), [**1.8b**-instruct3](https://huggingface.co/llm-jp/llm-jp-3-1.8b-instruct3), [**3.7b**-instruct2](https://huggingface.co/llm-jp/llm-jp-3-3.7b-instruct2), [**3.7b**-instruct3](https://huggingface.co/llm-jp/llm-jp-3-3.7b-instruct3), [**7.2b**-instruct2](https://huggingface.co/llm-jp/llm-jp-3-7.2b-instruct2), [**7.2b**-instruct3](https://huggingface.co/llm-jp/llm-jp-3-7.2b-instruct3), [**13b**-instruct2](https://huggingface.co/llm-jp/llm-jp-3-13b-instruct2), [**13b**-instruct3](https://huggingface.co/llm-jp/llm-jp-3-13b-instruct3)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)<br>(è¨ˆ **2.1T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), [AnswerCarefully Dataset](https://llmc.nii.ac.jp/answercarefully-dataset/), [magpie-sft-v1.0](https://huggingface.co/datasets/llm-jp/magpie-sft-v1.0), Daring-Anteater, FLAN, ichikara-instruction-format, AutoMultiTurnByCalm3-22B, ramdom-to-fixed-multiturn-Calm3, wizardlm8x22b-logical-math-coding-sft-ja, Synthetic-JP-EN-Coding-Dataset-567k<br>DPO (instruct3 only): [aya-ja-evol-inst](https://huggingface.co/datasets/llm-jp/aya-ja-evol-inst), [ac-self-inst](https://huggingface.co/datasets/llm-jp/ac-self-inst) | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 |
| [LLM-jp-3 13B](https://llmc.nii.ac.jp/topics/post-707/) | 2024 | Llama<br>([**1.8b**](https://huggingface.co/llm-jp/llm-jp-3-1.8b), [**1.8b**-instruct](https://huggingface.co/llm-jp/llm-jp-3-1.8b-instruct), [**3.7b**](https://huggingface.co/llm-jp/llm-jp-3-3.7b), [**3.7b**-instruct](https://huggingface.co/llm-jp/llm-jp-3-3.7b-instruct), [**7.2b**](https://huggingface.co/llm-jp/llm-jp-3-7.2b), [**7.2b**-instruct](https://huggingface.co/llm-jp/llm-jp-3-7.2b-instruct), [**13b**](https://huggingface.co/llm-jp/llm-jp-3-13b), [**13b**-instruct](https://huggingface.co/llm-jp/llm-jp-3-13b-instruct)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)<br>(è¨ˆ **2.1T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), [AnswerCarefully Dataset](https://llmc.nii.ac.jp/answercarefully-dataset/), FLAN, 	ichikara-instruction-format, AutoMultiTurnByCalm3-22B, ramdom-to-fixed-multiturn-Calm3, wizardlm8x22b-logical-math-coding-sft_additional-ja, Synthetic-JP-EN-Coding-Dataset-567k | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 |
| [llm-jp-3-3.7b-instruct-EZO](https://huggingface.co/AXCXEPT/llm-jp-3-3.7b-instruct-EZO-Common) | 2024 | Llama<br>([**3.7b**-instruct-EZO-Common](https://huggingface.co/AXCXEPT/llm-jp-3-3.7b-instruct-EZO-Common), [**3.7b**-instruct-EZO-Humanities](https://huggingface.co/AXCXEPT/llm-jp-3-3.7b-instruct-EZO-Humanities)) | 4,096 | LLM-jp-3 (3.7B) ã«å¯¾ã—ã¦è¿½åŠ å­¦ç¿’ | Axcxept | Apache 2.0 |
| [LLM-jp-13B v2.0](https://www.nii.ac.jp/news/release/2024/0430.html) | 2024 | Llama<br>([**13b**-v2.0](https://huggingface.co/llm-jp/llm-jp-13b-v2.0), [**13b**-instruct-full-dolly-ichikara_004_001_single-oasst-oasst2-v2.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-dolly-ichikara_004_001_single-oasst-oasst2-v2.0), [**13b**-instruct-full-ac_001-dolly-ichikara_004_001_single-oasst-oasst2-v2.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-ac_001-dolly-ichikara_004_001_single-oasst-oasst2-v2.0), [**13b**-instruct-full-ac_001_16x-dolly-ichikara_004_001_single-oasst-oasst2-v2.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-ac_001_16x-dolly-ichikara_004_001_single-oasst-oasst2-v2.0)) | 4,096 | äº‹å‰å­¦ç¿’: [llm-jp-corpus-v2](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v2)<br>(è¨ˆ **260B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), [AnswerCarefully Dataset](https://llmc.nii.ac.jp/answercarefully-dataset/), Dolly Dataset, OASST1, OASST2 | LLM-jp | Apache 2.0 |
| [Fugaku-LLM](https://pr.fujitsu.com/jp/news/2024/05/10.html) | 2024 | GPT<br>([**13B**](https://huggingface.co/Fugaku-LLM/Fugaku-LLM-13B), [**13B**-instruct](https://huggingface.co/Fugaku-LLM/Fugaku-LLM-13B-instruct), [**13B**-instruct-gguf](https://huggingface.co/Fugaku-LLM/Fugaku-LLM-13B-instruct-gguf)) | 2,048 | äº‹å‰å­¦ç¿’: ç‹¬è‡ª<br>Instruction Tuning: OASST1, Dolly Dataset, GSM8K | æ±å·¥å¤§, æ±åŒ—å¤§, å¯Œå£«é€š, ç†ç ”, åå¤§, ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ, Kotoba Technologies | Fugaku-LLM Terms of Use |
| [LLM-jp-13B v1.1](https://llm-jp.nii.ac.jp/blog/2024/02/09/v1.1-tuning.html) | 2024 | GPT<br>([**13b**-instruct-lora-dolly_en-dolly_ja-ichikara_003_001-oasst_en-oasst_ja-v1.1](https://huggingface.co/llm-jp/llm-jp-13b-instruct-lora-dolly_en-dolly_ja-ichikara_003_001-oasst_en-oasst_ja-v1.1), [**13b**-instruct-full-dolly_en-dolly_ja-ichikara_003_001-oasst_en-oasst_ja-v1.1](https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-dolly_en-dolly_ja-ichikara_003_001-oasst_en-oasst_ja-v1.1), [**13b**-dpo-lora-hh_rlhf_ja-v1.1](https://huggingface.co/llm-jp/llm-jp-13b-dpo-lora-hh_rlhf_ja-v1.1)) | 2,048 | Instruction Tuning (LoRA or Full-parameter FT): Dolly Dataset, OASST1, [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/)<br>DPO (LoRA): HH RLHF | LLM-jp | Apache 2.0 |
| [LLM-jp-13B](https://www.nii.ac.jp/news/release/2023/1020.html) | 2023 | GPT<br>([1.3b-v1.0](https://huggingface.co/llm-jp/llm-jp-1.3b-v1.0), [**13b**-v1.0](https://huggingface.co/llm-jp/llm-jp-13b-v1.0), [**13b**-instruct-full-jaster-v1.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-jaster-v1.0), [**13b**-instruct-full-jaster-dolly-oasst-v1.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0), [**13b**-instruct-full-dolly-oasst-v1.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-dolly-oasst-v1.0), [**13b**-instruct-lora-jaster-v1.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-lora-jaster-v1.0), [**13b**-instruct-lora-jaster-dolly-oasst-v1.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-lora-jaster-dolly-oasst-v1.0), [**13b**-instruct-lora-dolly-oasst-v1.0](https://huggingface.co/llm-jp/llm-jp-13b-instruct-lora-dolly-oasst-v1.0)) | 2,048 | äº‹å‰å­¦ç¿’: [llm-jp-corpus](https://github.com/llm-jp/llm-jp-corpus) (Wikipedia, Japanese mC4, The Pile, Stack) (è¨ˆ **300B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning (Full-parameter FT or LoRA): jaster, Dolly Dataset, OASST1 | LLM-jp | Apache 2.0 |
| [PLaMo-13B](https://www.preferred.jp/ja/news/pr20230928/) | 2023 | Llama[^1]<br>([**13b**](https://huggingface.co/pfnet/plamo-13b), [**13b**-instruct](https://huggingface.co/pfnet/plamo-13b-instruct), [**13b**-instruct-nc](https://huggingface.co/pfnet/plamo-13b-instruct-nc)) | base: 4,096<br>instruct, instruct-nc: 8,192 | äº‹å‰å­¦ç¿’: C4, Project Gutenberg, RedPajama, æ—¥æœ¬èª Wikipedia, Japanese mC4<br>(è¨ˆ **1.5T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, HH RLHF, OASST1, llm-japanese-datasetã®wikinews subset (NCãƒ¢ãƒ‡ãƒ«ã§ã¯å•†ç”¨åˆ©ç”¨ä¸å¯ã® Alpaca Dataset ã‚‚å«ã‚ã¦å­¦ç¿’) | Preferred Networks | Apache 2.0<br>(NC ãƒ¢ãƒ‡ãƒ«ã¯ CC BY-NC 4.0) |
| [Stockmark-13b](https://stockmark.co.jp/news/20231027) | 2023 | Llama<br>([**13b**](https://huggingface.co/stockmark/stockmark-13b), [**13b**-instruct](https://huggingface.co/stockmark/stockmark-13b-instruct)) | 2,048 | äº‹å‰å­¦ç¿’: æ—¥æœ¬èª Wikipediaã€Japanese CC-100ã€Japanese mC4ã€Japanese CommonCrawlã€æ—¥æœ¬èªç‰¹è¨±ã€Stockmark Web Corpus<br>(è¨ˆ **220B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning (LoRA): [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/) | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | baseãƒ¢ãƒ‡ãƒ«: MIT<br>instructãƒ¢ãƒ‡ãƒ«: CC BY-NC-SA 4.0 |
| [Weblab-10B](https://www.t.u-tokyo.ac.jp/press/pr2023-08-18-001) | 2023 | GPT-NeoX<br>([**10b**](https://huggingface.co/matsuo-lab/weblab-10b), [**10b**-instruction-sft](https://huggingface.co/matsuo-lab/weblab-10b-instruction-sft)) | 2,048 | Japanese mC4 + The Pileï¼ˆè¨ˆ **600B** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰<br>\*instruction-sft ãƒ¢ãƒ‡ãƒ«ã¯ Alpaca Dataset, FLAN ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | æ±å¤§ æ¾å°¾ç ” | CC BY-NC 4.0 |
| [PLaMo 2.1 8B](https://tech.preferred.jp/ja/blog/plamo-2-1-8b/) | **2025** | Samba ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>([**8b**-cpt](https://huggingface.co/pfnet/plamo-2.1-8b-cpt)) | **32,768** | è¨“ç·´è©³ç´°ä¸æ˜ | Preferred Networks | PLaMo community license |
| [PLaMo 2 8B](https://tech.preferred.jp/ja/blog/plamo-2-8b/) | **2025** | Samba ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>([**8b**](https://huggingface.co/pfnet/plamo-2-8b)) | | æ—¥æœ¬èªã€è‹±èªç­‰ã®ãƒ‡ãƒ¼ã‚¿<br>ï¼ˆè¨ˆ **6T** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ | Preferred Networks | PLaMo community license |
| [Tanuki-8B](https://weblab.t.u-tokyo.ac.jp/2024-08-30/) | 2024 | Tanuki (**8b**)<br>([v1.0](https://huggingface.co/weblab-GENIAC/Tanuki-8B-dpo-v1.0), [v1.0-AWQ](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8B-dpo-v1.0-AWQ), [v1.0-GPTQ-4bit](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8B-dpo-v1.0-GPTQ-4bit), [v1.0-GPTQ-8bit](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8B-dpo-v1.0-GPTQ-8bit), [v1.0-GGUF](https://huggingface.co/team-hatakeyama-phase2/Tanuki-8B-dpo-v1.0-GGUF)) | 4,096 | äº‹å‰å­¦ç¿’: æ§˜ã€…ãª Web ä¸Šã®ãƒ‡ãƒ¼ã‚¿, åˆæˆãƒ‡ãƒ¼ã‚¿ï¼ˆè¨ˆ **1.3T** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰<br>SFT, DPO: æ§˜ã€…ãªåˆæˆãƒ‡ãƒ¼ã‚¿ [^19] | æ¾å°¾ç ”LLMé–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Apache 2.0 |
| [Japanese StableLM Alpha](https://huggingface.co/stabilityai/japanese-stablelm-base-alpha-7b) | 2023 | GPT-NeoX<br>([base-alpha-**7b**](https://huggingface.co/stabilityai/japanese-stablelm-base-alpha-7b), [instruct-alpha-**7b**](https://huggingface.co/stabilityai/japanese-stablelm-instruct-alpha-7b), [instruct-alpha-**7b**-v2](https://huggingface.co/stabilityai/japanese-stablelm-instruct-alpha-7b-v2)) | 2,048 | Wikipedia, Japanese CC-100, Japanese mC4, Japanese OSCAR, RedPajama<br>(+ ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)[^2]<br>(è¨ˆ **750B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>\*instruct ãƒ¢ãƒ‡ãƒ«ã§ã¯ Alpaca Dataset, Dolly Dataset, HH RLHF, llm-japanese-datasetã®wikinews subsetã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°<br>(v2ã§ã¯å•†ç”¨åˆ©ç”¨ä¸å¯ã® Alpaca Dataset ã‚’é™¤å¤–) | Stability AI | baseãƒ¢ãƒ‡ãƒ«: Apache 2.0<br>instruct ãƒ¢ãƒ‡ãƒ« (v1): [ç‹¬è‡ªã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹](https://huggingface.co/stabilityai/japanese-stablelm-instruct-alpha-7b/tree/main)<br>instruct ãƒ¢ãƒ‡ãƒ« (v2): Apache 2.0 |
| [CyberAgentLM2 (CALM2)](https://www.cyberagent.co.jp/news/detail/id=29479) | 2023 | Llama<br>([**7b**](https://huggingface.co/cyberagent/calm2-7b), [**7b**-chat](https://huggingface.co/cyberagent/calm2-7b-chat), [**7b**-chat-dpo-experimental](https://huggingface.co/cyberagent/calm2-7b-chat-dpo-experimental)) | base: 4,096<br>chat: **32,768** |ä¸€èˆ¬å…¬é–‹ã•ã‚Œã¦ã„ã‚‹æ—¥æœ¬èªãƒ»è‹±èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆè©³ç´°ä¸æ˜ï¼‰ (è¨ˆ **1.3T** ãƒˆãƒ¼ã‚¯ãƒ³)<br>*dpo ãƒ¢ãƒ‡ãƒ«ã¯ Chatbot Arena Conversations JA (calm2) Dataset ã‚’ç”¨ã„ã¦ DPO ã§å­¦ç¿’ | ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | Apache 2.0<br>(dpo ãƒ¢ãƒ‡ãƒ«ã®ã¿ CC BY 4.0) |
| [OpenCALM](https://www.cyberagent.co.jp/news/detail/id=28817) | 2023 | GPT-NeoX<br>([small](https://huggingface.co/cyberagent/open-calm-small), [medium](https://huggingface.co/cyberagent/open-calm-medium), [large](https://huggingface.co/cyberagent/open-calm-large), [**1b(1.4b)**](https://huggingface.co/cyberagent/open-calm-1b), [**3b(2.7b)**](https://huggingface.co/cyberagent/open-calm-3b), [**7b(6.8b)**](https://huggingface.co/cyberagent/open-calm-7b)) | 2,048 | æ—¥æœ¬èª Wikipedia <br>+ Jpanese mC4<br>+ Japanese CC-100 | ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | CC BY-SA 4.0 |
| [Stormy](https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/422/1350) | 2023 | GPT-NeoX<br>([**7b(6.8b)**](https://huggingface.co/izumi-lab/stormy-7b-10ep)) | 2,048 | OpenCALM (6.8b) ã«å¯¾ã—ã¦<br>llm-japanese-dataset v0 ã®ã†ã¡ç¿»è¨³ã‚¿ã‚¹ã‚¯ã‚’é™¤ã„ãŸãƒ‡ãƒ¼ã‚¿ã§ LoRAãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | æ±å¤§ å’Œæ³‰ç ” | CC BY-SA 4.0 |
| [ByGPT-JP](https://huggingface.co/tohoku-nlp/bygpt-jp-multi-lm-head-6.5B-alpha) | **2025** | Llama ãƒ™ãƒ¼ã‚¹<br>([multi-lm-head-**6.5b**-alpha](https://huggingface.co/tohoku-nlp/bygpt-jp-multi-lm-head-6.5B-alpha)) | 5,760 | [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3) ã®ã‚µãƒ–ã‚»ãƒƒãƒˆ (ja_cc, ja_warp_html, ja_warp_pdf, ja_wiki, kaken) | æ±åŒ—å¤§<br>è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ— | Apache 2.0 |
| [rinna GPT <br> (è‹±èªã‚„ã‚³ãƒ¼ãƒ‰ã‚‚å«ã‚ã¦å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«)](https://huggingface.co/rinna/bilingual-gpt-neox-4b) | 2023 | GPT-NeoX<br>([**4b(3.8b)**](https://huggingface.co/rinna/bilingual-gpt-neox-4b), [**4b(3.8b)**-8k](https://huggingface.co/rinna/bilingual-gpt-neox-4b-8k), [**4b(3.8b)**-instruction-sft](https://huggingface.co/rinna/bilingual-gpt-neox-4b-instruction-sft), [**4b(3.8b)**-instruction-ppo](https://huggingface.co/rinna/bilingual-gpt-neox-4b-instruction-ppo)) | 8kãƒ¢ãƒ‡ãƒ«: 8,192<br>ä»–: 2,048 | Wikipedia, Japanese CC-100, Japanese C4, RedPajama, The Pile<br>(è¨ˆ **524B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>\*8k ãƒ¢ãƒ‡ãƒ«ã§ã¯ 4,000ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆã‚‹é•·ã„ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°<br>\*instruction-sft ãƒ¢ãƒ‡ãƒ«ã§ã¯ HH RLHFã€FLAN ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°<br>\*instruction-ppo ãƒ¢ãƒ‡ãƒ«ã§ã¯ HH RLHF ã§ PPO ãƒ™ãƒ¼ã‚¹ã®å¼·åŒ–å­¦ç¿’ | rinna | MIT |
| [japanese-large-lm](https://engineering.linecorp.com/ja/blog/3.6b-japanese-language-model-with-improved-dialog-performance-by-instruction-tuning) | 2023 | GPT-NeoX<br>([**1.7b**](https://huggingface.co/line-corporation/japanese-large-lm-1.7b), [**3.6b**](https://huggingface.co/line-corporation/japanese-large-lm-3.6b), [**1.7b**-instruction-sft](https://huggingface.co/line-corporation/japanese-large-lm-1.7b-instruction-sft), [**3.6b**-instruction-sft](https://huggingface.co/line-corporation/japanese-large-lm-3.6b-instruction-sft)) | 2,048 | æ—¥æœ¬èª Wikipedia, Japanese CC-100, Japanese C4, Japanese OSCAR ã‚„ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ãªã©<br>(è¨ˆ **650GB**)<br>\*instruction-sft ãƒ¢ãƒ‡ãƒ«ã§ã¯ OASST1 ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | LINE | Apache 2.0 |
| [rinna GPT <br> (æ—¥æœ¬èªã®ã¿ã§å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«)](https://huggingface.co/rinna/japanese-gpt2-xsmall) | 2023 | GPT ã¾ãŸã¯ GPT-NeoX<br>([xsmall](https://huggingface.co/rinna/japanese-gpt2-xsmall), [small](https://huggingface.co/rinna/japanese-gpt2-small), [medium](https://huggingface.co/rinna/japanese-gpt2-medium), [**1b**](https://huggingface.co/rinna/japanese-gpt-1b), [neox-small](https://huggingface.co/rinna/japanese-gpt-neox-small), [neox-**3.6b**-instruction-sft-v2](https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-sft-v2), [neox-**3.6b**-instruction-ppo](https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-ppo)) | â‰¤ 2,048 | æ—¥æœ¬èª Wikipedia <br> + Japanese CC-100 <br> (1b ä»¥é™ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯<br>ã•ã‚‰ã« Japanese mC4 ã‚’è¿½åŠ )<br>\*instruction-sft, sft-v2 ãƒ¢ãƒ‡ãƒ«ã§ã¯ HH RLHFã€FLANã€SHP ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã•ã‚‰ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°<br>\*instruction-ppo ãƒ¢ãƒ‡ãƒ«ã§ã¯ HH RLHF ã§ã•ã‚‰ã« PPO ãƒ™ãƒ¼ã‚¹ã®å¼·åŒ–å­¦ç¿’ | rinna | MIT |
| [Sarashina2.2](https://www.sbintuitions.co.jp/blog/entry/2025/03/07/093143) | **2025** | Llama<br>([0.5b](https://huggingface.co/sbintuitions/sarashina2.2-0.5b), [0.5b-instruct-v0.1](https://huggingface.co/sbintuitions/sarashina2.2-0.5b-instruct-v0.1), [**1b**](https://huggingface.co/sbintuitions/sarashina2.2-1b), [**1b**-instruct-v0.1](https://huggingface.co/sbintuitions/sarashina2.2-1b-instruct-v0.1), [**3b**](https://huggingface.co/sbintuitions/sarashina2.2-3b), [**3b**-instruct-v0.1](https://huggingface.co/sbintuitions/sarashina2.2-3b-instruct-v0.1)) | 8,192 || SB Intuitions | MIT |
| [ãƒ¬ãƒˆãƒªãƒT5](https://note.com/retrieva/n/n7b4186dc5ada) | 2023 | T5<br>([small (short)](https://huggingface.co/retrieva-jp/t5-small-short), [small (medium)](https://huggingface.co/retrieva-jp/t5-small-medium), [small (long)](https://huggingface.co/retrieva-jp/t5-small-long), [base (short)](https://huggingface.co/retrieva-jp/t5-base-short), [base (medium)](https://huggingface.co/retrieva-jp/t5-base-medium), [base (long)](https://huggingface.co/retrieva-jp/t5-base-long), [large (short)](https://huggingface.co/retrieva-jp/t5-large-short), [large (medium)](https://huggingface.co/retrieva-jp/t5-large-medium), [large (long)](https://huggingface.co/retrieva-jp/t5-large-long), [**xl(3b)**](https://huggingface.co/retrieva-jp/t5-xl)) | | æ—¥æœ¬èª Wikipedia + Japanese mC4 | ãƒ¬ãƒˆãƒªãƒ | CC BY-SA 4.0 |
| [Spiral-RetNet-3b-base](https://prtimes.jp/main/html/rd/p/000000014.000120221.html) | 2024 | RetNet<br>([**3b**](https://huggingface.co/Spiral-AI/Spiral-RetNet-3b-base)) | 2,048 |  Wikipedia, Japanese CC-100, CulturaX | Spiral.AI | MIT |
| [kotomamba-2.8B](https://huggingface.co/kotoba-tech/kotomamba-2.8B-v1.0) | 2024 | Mamba<br>([**2.8B**-v1.0](https://huggingface.co/kotoba-tech/kotomamba-2.8B-v1.0)) | 2,048 | æ—¥æœ¬èª Wikipedia, Swallow Corpus, SlimPajama | Kotoba Technologies | Apache 2.0 |
| [ABEJA GPT](https://tech-blog.abeja.asia/entry/abeja-gpt-project-202207) | 2022 | GPT ã¾ãŸã¯ GPT-NeoX<br>([large](https://huggingface.co/abeja/gpt2-large-japanese), [neox-**2.7b**](https://huggingface.co/abeja/gpt-neox-japanese-2.7b)) | | æ—¥æœ¬èª Wikipedia <br> + Japanese CC-100 <br> + Japanese OSCAR | ABEJA | MIT |
| [PLaMo 2.1 2B](https://tech.preferred.jp/ja/blog/plamo-2-1-8b/) | **2025** | Causal decoder-only transformer<br>([**2b**-cpt](https://huggingface.co/pfnet/plamo-2.1-2b-cpt)) | **32,768** | è¨“ç·´è©³ç´°ä¸æ˜ | Preferred Networks | PLaMo community license |
| [Rakuten AI 2.0 mini](https://corp.rakuten.co.jp/news/press/2025/0212_02.html) | **2025** | Mistral<br>([mini(**1.5b**)](https://huggingface.co/Rakuten/RakutenAI-2.0-mini), [mini(**1.5b**)-instruct](https://huggingface.co/Rakuten/RakutenAI-2.0-mini-instruct)) | **131,072** ||æ¥½å¤©|Apache 2.0|
| [æ—©å¤§GPT](https://huggingface.co/nlp-waseda/gpt2-xl-japanese) | 2022 | GPT<br>([small](https://huggingface.co/nlp-waseda/gpt2-small-japanese), [**xl(1.5b)**](https://huggingface.co/nlp-waseda/gpt2-xl-japanese)) | |  æ—¥æœ¬èª Wikipedia<br> + Japanese CC-100 | æ—©å¤§ æ²³åŸç ” | CC BY-SA 4.0 |
| [ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯GPT](https://stockmark.co.jp/news/20230808) | 2023 | GPT-NeoX<br>([**1.4b**](https://huggingface.co/stockmark/gpt-neox-japanese-1.4b)) |  | æ—¥æœ¬èª Wikipedia (0.88B ãƒˆãƒ¼ã‚¯ãƒ³)<br>+ Japanese CC-100 (10.5B ãƒˆãƒ¼ã‚¯ãƒ³)<br>+ ç‹¬è‡ªã®Webãƒ‡ãƒ¼ã‚¿ (8.6B ãƒˆãƒ¼ã‚¯ãƒ³) | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | MIT |
| [ã‚¤ã‚¨ãƒ­ãƒ¼ãƒãƒƒã‚¯GPT](https://tech.yellowback.net/posts/gpt-neo-japanese) | 2021 | GPT-NeoX<br>([**1.3b**](https://huggingface.co/yellowback/gpt-neo-japanese-1.3B)) |  | æ—¥æœ¬èª Wikipedia <br> + Japanese CC-100 <br> + Japanese OSCAR | ã‚¤ã‚¨ãƒ­ãƒ¼ãƒãƒƒã‚¯ | Apache 2.0 |
| [PLaMo 2 1B](https://tech.preferred.jp/ja/blog/plamo-2/) | **2025** | Samba ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>([**1b**](https://huggingface.co/pfnet/plamo-2-1b)) | | æ—¥æœ¬èªã€è‹±èªç­‰ã®ãƒ‡ãƒ¼ã‚¿<br>ï¼ˆè¨ˆ **4T** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ | Preferred Elements (Preferred Networks) | Apache 2.0 |
| [Sarashina2.1-1B](https://huggingface.co/sbintuitions/sarashina2.1-1b) | 2024 | Llama<br>([**1b**](https://huggingface.co/sbintuitions/sarashina2.1-1b)) | 8,192 | Web ä¸Šãªã©ã®æ—¥æœ¬èªãƒ»è‹±èªãƒ‡ãƒ¼ã‚¿ï¼ˆè¨ˆ **10T** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ | SB Intuitions | Sarashina Model NonCommercial License |
| [colorfulscoop GPT](https://huggingface.co/colorfulscoop/gpt2-small-ja) | 2021 | GPT<br>([small](https://huggingface.co/colorfulscoop/gpt2-small-ja)) | |  æ—¥æœ¬èª Wikipedia | Colorful Scoop | CC BY-SA 3.0 |
| [æ±å·¥å¤§GPT](https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/H9-1.pdf) | 2023 | GPT<br>([medium](https://huggingface.co/okazaki-lab/japanese-gpt2-medium-unidic), [medium (é€†æ–¹å‘)](https://huggingface.co/okazaki-lab/japanese-reversed-gpt2-medium-unidic)) [^3] | |  æ—¥æœ¬èª Wikipedia + Japanese CC-100 | æ±å·¥å¤§ å²¡å´ç ” | CC BY-SA 4.0 |
| [äº¬å¤§GPT](https://huggingface.co/ku-nlp/gpt2-medium-japanese-char) | 2022 | GPT<br>([small (æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/ku-nlp/gpt2-small-japanese-char), [medium (æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/ku-nlp/gpt2-medium-japanese-char), [large (æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/ku-nlp/gpt2-large-japanese-char)) | | æ—¥æœ¬èª Wikipedia (ç´„2,700ä¸‡æ–‡ (3.2GB)) <br>+ Japanese CC-100 (ç´„6å„„1,900ä¸‡æ–‡ (85GB)) <br>+ Japanese OSCAR (ç´„3å„„2,600ä¸‡æ–‡ (54GB)) | äº¬å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢ç ”ç©¶å®¤ | CC BY-SA 4.0 |
| [æ—¥æœ¬èªBART](https://huggingface.co/ku-nlp/bart-base-japanese) | 2023 | BART<br>([base](https://huggingface.co/ku-nlp/bart-base-japanese), [large](https://huggingface.co/ku-nlp/bart-large-japanese)) | |  æ—¥æœ¬èª Wikipedia (ç´„1,800ä¸‡æ–‡) | äº¬å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢ç ”ç©¶å®¤ | CC BY-SA 4.0 |
| [Megagon Labs T5](https://github.com/megagonlabs/t5-japanese) | 2021 | T5<br>([base](https://huggingface.co/megagonlabs/t5-base-japanese-web)) | |  Japanese mC4 (87,425,304 ãƒšãƒ¼ã‚¸ (782 GB))<br>+ Japanese wiki40b (828,236 è¨˜äº‹ (2 GB)) | Megagon Labs <br> (ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ) | Apache 2.0 |

<a id="generative-scratch-domain-specific"></a>
#### ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹

|    | ãƒ‰ãƒ¡ã‚¤ãƒ³ | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å­¦ç¿’ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|:---:|
| [SIP-med-LLM/SIP-jmed-llm-2-8x13b-OP-instruct](https://huggingface.co/SIP-med-LLM/SIP-jmed-llm-2-8x13b-OP-instruct) | åŒ»ç™‚ | MoE | åŒ»ç™‚ç³»ã‚³ãƒ¼ãƒ‘ã‚¹ (**44.2B** ãƒˆãƒ¼ã‚¯ãƒ³) ã§ LLM-jp-3 MoE (8x13b) ã«è¿½åŠ äº‹å‰å­¦ç¿’ã€ãã®å¾Œ Instruction Tuning | æˆ¦ç•¥çš„ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‰µé€ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆSIPï¼‰ç¬¬3æœŸèª²é¡Œã€Œçµ±åˆå‹ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«ãŠã‘ã‚‹ç”Ÿæˆ AI æ´»ç”¨ã€ãƒ†ãƒ¼ãƒ1ã€Œå®‰å…¨æ€§ãƒ»ä¿¡é ¼æ€§ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ãªåŒ»ç™‚ LLM ã®é–‹ç™ºãƒ»ç¤¾ä¼šå®Ÿè£…ã€ ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ— | Apache 2.0 |
| [æ—¥æœ¬èªå¯¾è©±Transformer](https://group.ntt/jp/topics/2021/09/30/transformer.html) | å¯¾è©± |Transformer | Twitter ä¸Šã®æ—¥æœ¬èªãƒªãƒ—ãƒ©ã‚¤ã®ãƒšã‚¢ | NTT | [ç‹¬è‡ªã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹](https://github.com/nttcslab/japanese-dialog-transformers/blob/main/LICENSE.md) |
| [æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹BART](https://tech.stockmark.co.jp/blog/bart-japanese-base-news/) | ãƒ“ã‚¸ãƒã‚¹ | BART ([base](https://huggingface.co/stockmark/bart-base-japanese-news)) | æ—¥æœ¬èªãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ï¼ˆç´„2,100ä¸‡è¨˜äº‹ (2.9å„„æ–‡)ï¼‰ | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | MIT |
| [AcademicBART](https://github.com/EhimeNLP/AcademicBART) | å­¦è¡“ | BART ([base](https://huggingface.co/EhimeNLP/AcademicBART)) | CiNii ã®æ—¥æœ¬èªè«–æ–‡ | æ„›åª›å¤§ äººå·¥çŸ¥èƒ½ç ”ç©¶å®¤ | Apache 2.0 |

<a id="english-based-models"></a>
### æµ·å¤–ãƒ¢ãƒ‡ãƒ«ã«æ—¥æœ¬èªã§ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’è¡Œã£ãŸãƒ¢ãƒ‡ãƒ«

<a id="generative-continual-general"></a>
#### æ±ç”¨

|    | å…¬é–‹å¹´ | ãƒ™ãƒ¼ã‚¹ã®LLM  | å­¦ç¿’ãƒ†ã‚­ã‚¹ãƒˆ | é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ / åˆ©ç”¨è¦ç´„ |
|:---|:---:|:---:|:---:|:---:|:---:|
| [Llama 3.3 Swallow 70B](https://swallow-llm.github.io/llama3.3-swallow.ja.html)<br>([70B-v0.4](https://huggingface.co/tokyotech-llm/Llama-3.3-Swallow-70B-v0.4), [70B-Instruct-v0.4](https://huggingface.co/tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4)) | **2025** | Llama 3.3 (**70b**) | äº‹å‰å­¦ç¿’: Wikipedia, DCLM-baseline-1.0, Swallow Corpus Version 2, Cosmopedia, Laboro ParaCorpus, FineMath-4+, Swallow Code Version 0.3<br>Instruction Tuning: Gemma-2-LMSYS-Chat-1M-Synth, Swallow-Magpie-Ultra-v0.1, Swallow-Gemma-Magpie-v0.1, Swallow-Code-v0.3-Instruct-style | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3.3 Community License & Gemma Terms of Use |
| [Llama 3.1 Swallow 70B](https://swallow-llm.github.io/llama3.1-swallow.ja.html)<br>([70B-v0.1](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-70B-v0.1), [70B-Instruct-v0.1](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1), [70B-Instruct-v0.3](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3)) | 2024 | Llama 3.1 (**70b**) | äº‹å‰å­¦ç¿’: The Stack v2, Wikipedia, DCLM-baseline-1.0, Swallow Corpus Version 2, Cosmopedia, Laboro ParaCorpus<br>Instruction Tuning: lmsys-chat-1m-synth-ja-wo-pii-and-template-instructions, lmsys-chat-1m-synth-en-wo-pii-and-template-instructions, filtered-magpie-ultra-ja, filtered-magpie-ultra-en, gemma-magpie | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3.1 Community License<br>(Instructãƒ¢ãƒ‡ãƒ«ã¯ Gemma Terms of Use ã‚‚é©ç”¨) |
| [cyberagent/Llama-3.1-70B-Japanese-Instruct-2407](https://huggingface.co/cyberagent/Llama-3.1-70B-Japanese-Instruct-2407) | 2024 | Llama 3.1 (**70b**) | ä¸æ˜ | ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | Llama 3.1 Community License |
| [Llama 3 Swallow 70B](https://swallow-llm.github.io/llama3-swallow.ja.html)<br>([70B-v0.1](https://huggingface.co/tokyotech-llm/Llama-3-Swallow-70B-v0.1), [70B-Instruct-v0.1](https://huggingface.co/tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1)) | 2024 | Llama 3 (**70b**) | äº‹å‰å­¦ç¿’: Algebraic Stack, Wikipedia, RefinedWeb, Swallow Corpus, Cosmopedia, Laboro ParaCorpus, OpenWebMath<br>Instruction Tuning: OASST1 [^17] | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3 Community License |
| [turing-motors/Llama-3-heron-brain-70B-v0.3](https://huggingface.co/turing-motors/Llama-3-heron-brain-70B-v0.3) | 2024 | Llama 3 (**70b**) | Llama 3 Swallow 70B ã«å¯¾ã—ã¦è¿½åŠ å­¦ç¿’ï¼ˆè©³ç´°ä¸æ˜ï¼‰ | Turing | Llama 3 Community License |
| [Llama 3 Youko 70B](https://huggingface.co/rinna/llama-3-youko-70b)<br>([70b](https://huggingface.co/rinna/llama-3-youko-70b), [70b-instruct](https://huggingface.co/rinna/llama-3-youko-70b-instruct), [70b-gptq](https://huggingface.co/rinna/llama-3-youko-70b-gptq), [70b-instruct-gptq](https://huggingface.co/rinna/llama-3-youko-70b-instruct-gptq)) | 2024 | Llama 3 (**70b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese C4, Japanese CC-100, Japanese OSCAR, The Pile, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ **5B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ[^11] | rinna | Llama 3 Community License |
| [Swallow 70B](https://swallow-llm.github.io/swallow-llama.ja.html)<br>([70b-hf](https://huggingface.co/tokyotech-llm/Swallow-70b-hf), [70b-instruct-hf](https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-hf), [70b-instruct-v0.1](https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-v0.1), [70b-NVE-hf](https://huggingface.co/tokyotech-llm/Swallow-70b-NVE-hf), [70b-NVE-instruct-hf](https://huggingface.co/tokyotech-llm/Swallow-70b-NVE-instruct-hf)) | 2023 | Llama 2 (**70b**) | äº‹å‰å­¦ç¿’: æ—¥æœ¬èª Wikipedia, RefinedWeb, Swallow Corpus, The Pile<br>Instruction Tuning: Dolly Dataset, HH RLHF, OASST1<br>*v0.1ãƒ¢ãƒ‡ãƒ«ã§ã¯ OASST1, OASST2 ã‚’ä½¿ç”¨ | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 2 Community License |
| [KARAKURI LM](https://karakuri.ai/seminar/news/karakuri-lm/)<br>([70b-v0.1](https://huggingface.co/karakuri-ai/karakuri-lm-70b-v0.1), [70b-chat-v0.1](https://huggingface.co/karakuri-ai/karakuri-lm-70b-chat-v0.1)) | 2024 | Llama 2 (**70b**) | äº‹å‰å­¦ç¿’: mC4, CC100, OSCAR, RedPajama, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ **16B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>SteerLM: OASST2, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ã‚«ãƒ©ã‚¯ãƒª | Llama 2 Community License[^13] |
| [Japanese Stable LM Beta 70B](https://huggingface.co/stabilityai/japanese-stablelm-base-beta-70b)<br>([base-beta-70b](https://huggingface.co/stabilityai/japanese-stablelm-base-beta-70b), [instruct-beta-70b](https://huggingface.co/stabilityai/japanese-stablelm-instruct-beta-70b)) | 2023 | Llama 2 (**70b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese mC4, Japanese CC-100, Japanese OSCAR, SlimPajama(Books3ã‚’é™¤å¤–)<br>(è¨ˆ **100B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, HH RLHF, OASST1 | Stability AI | Llama 2 Community License |
| [Fujitsu-LLM-KG](https://blog.fltech.dev/entry/2024/10/15/Fujitsu-LLM-KG-ja)<br>([8x7B_cpt](https://huggingface.co/Fujitsu-LLM-KG/Fujitsu-LLM-KG-8x7B_cpt), [8x7B_inst-infer_v1](https://huggingface.co/Fujitsu-LLM-KG/Fujitsu-LLM-KG-8x7B_inst-infer_v1), [8x7B_inst-infer_v2](https://huggingface.co/Fujitsu-LLM-KG/Fujitsu-LLM-KG-8x7B_inst-infer_v2), [8x7B_inst-gen_ja](https://huggingface.co/Fujitsu-LLM-KG/Fujitsu-LLM-KG-8x7B_inst-gen_ja), [8x7B_inst-gen_en](https://huggingface.co/Fujitsu-LLM-KG/Fujitsu-LLM-KG-8x7B_inst-gen_en)) | **2025** | Mixtral-8x7B-Instruct-v0.1 (**46.7b**) | äº‹å‰å­¦ç¿’: çŸ¥è­˜ã‚°ãƒ©ãƒ•ä¸¦åˆ—ã‚³ãƒ¼ãƒ‘ã‚¹(æ£®ç¾…ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€Wikipediaç­‰ã‹ã‚‰åˆæˆ) **2.1B**ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã‚€è¨ˆç´„**300B**ãƒˆãƒ¼ã‚¯ãƒ³<br>Instruction Tuning: çŸ¥è­˜ã‚°ãƒ©ãƒ•æ¨è«–ãƒ»ç”Ÿæˆã‚¿ã‚¹ã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | å¯Œå£«é€š | Apache 2.0 |
| [Swallow-MX 8x7B](https://swallow-llm.github.io/swallow-mistral.ja.html)<br>([8x7b-NVE-v0.1](https://huggingface.co/tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1)) | 2024 | Mixtral-8x7B-Instruct-v0.1 (**46.7b**) | äº‹å‰å­¦ç¿’: Algebraic Stack, Japanese Wikipedia, RefinedWeb, Swallow Corpus, The Pile, The Vault | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Apache 2.0 |
| [KARAKURI LM 8x7B Instruct v0.1](https://karakuri.ai/seminar/news/karakuri-lm-8x7b-instruct-v0-1/)<br>([8x7b-instruct-v0.1](https://huggingface.co/karakuri-ai/karakuri-lm-8x7b-instruct-v0.1)) | 2024 | Mixtral-8x7B-Instruct-v0.1 (**46.7b**) | Swallow-MX 8x7B ã«å¯¾ã—ã¦ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’: Dolly Dataset, OASST2, HelpSteer, glaive-code-assistant-v3, glaive-function-calling-v2, synthetic_text_to_sql, MetaMathQA, orca-math-word-problems-200k, rag-dataset-12000, rag-hallucination-dataset-1000, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ã‚«ãƒ©ã‚¯ãƒª | Apache 2.0 (?)[^12] |
| [KARAKURI LM 8x7B Chat v0.1](https://karakuri.ai/seminar/news/aws_trainium_moe/)<br>([8x7b-chat-v0.1](https://huggingface.co/karakuri-ai/karakuri-lm-8x7b-chat-v0.1)) | 2024 | Mixtral-8x7B-Instruct-v0.1 (**46.7b**) | Swallow-MX 8x7B ã«å¯¾ã—ã¦<br>SteerLM: OASST2, HelpSteer, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ã‚«ãƒ©ã‚¯ãƒª | Apache 2.0 |
| [ABEJA-Mixtral-8x7B-japanese](https://tech-blog.abeja.asia/entry/abeja-nedo-project-part1-202404)<br>([8x7B-v0.1-japanese](https://huggingface.co/abeja/Mixtral-8x7B-v0.1-japanese), [8x7B-Instruct-v0.1-japanese](https://huggingface.co/abeja/Mixtral-8x7B-Instruct-v0.1-japanese), [8x7B-Instruct-v0.1-japanese-alpha](https://huggingface.co/abeja/Mixtral-8x7B-Instruct-v0.1-japanese-alpha), [8x7B-Instruct-v0.1-japanese-alpha-merged](https://huggingface.co/abeja/Mixtral-8x7B-Instruct-v0.1-japanese-alpha-merged)) | 2024 | Mixtral-8x7B-Instruct-v0.1 (**46.7b**)<br>\*InstructãŒåå‰ã«ä»˜ã„ã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã®ã¿ Mixtral-8x7B-v0.1 ãŒãƒ™ãƒ¼ã‚¹ |  äº‹å‰å­¦ç¿’: Japanese CC,	Redpajama, ç‹¬è‡ª<br>ï¼ˆè¨ˆ **450B** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ | ABEJA | Apache 2.0 |
| [ELYZA-Thinking-1.0-Qwen-32B](https://zenn.dev/elyza/articles/bc68f53fc0a83b)<br>([32B](https://huggingface.co/elyza/ELYZA-Thinking-1.0-Qwen-32B)) | **2025** | Qwen 2.5 (**32b**) | äº‹å‰å­¦ç¿’ + SFT (Reasoning) | ELYZA | Apache 2.0 |
| [ELYZA-Shortcut-1.0-Qwen-32B](https://zenn.dev/elyza/articles/bc68f53fc0a83b)<br>([32B](https://huggingface.co/elyza/ELYZA-Shortcut-1.0-Qwen-32B)) | **2025** | Qwen 2.5 (**32b**) | äº‹å‰å­¦ç¿’ + SFT | ELYZA | Apache 2.0 |
| [ABEJA-Qwen2.5-32b-Japanese-v1.0](https://tech-blog.abeja.asia/entry/geniac2-qwen25-32b-v1.0)<br>([v1.0](https://huggingface.co/abeja/ABEJA-Qwen2.5-32b-Japanese-v1.0)) | **2025** | Qwen2.5-32B-Instruct (**32b**) | ç¶™ç¶šäº‹å‰å­¦ç¿’ + SFT + DPO: ç´„2ä¸‡ä»¶ã®åˆæˆãƒ‡ãƒ¼ã‚¿ãƒ»äººæ‰‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæŠ½å‡ºãƒ»æ¨è«–èƒ½åŠ›ã«ç‰¹åŒ–ï¼‰ | ABEJA | Apache 2.0 |
| [Qwen2.5 Bakeneko 32B](https://huggingface.co/rinna/qwen2.5-bakeneko-32b)<br>([qwen2.5-bakeneko-32b](https://huggingface.co/rinna/qwen2.5-bakeneko-32b), [qwen2.5-bakeneko-32b-instruct](https://huggingface.co/rinna/qwen2.5-bakeneko-32b-instruct), [deepseek-r1-distill-qwen2.5-bakeneko-32b](https://huggingface.co/rinna/deepseek-r1-distill-qwen2.5-bakeneko-32b), [qwq-bakeneko-32b](https://huggingface.co/rinna/qwq-bakeneko-32b)) | **2025** | Qwen 2.5 (**32b**) || rinna | Apache 2.0 |
| [ABEJA-QwQ32b-Reasoning-Japanese-v1.0](https://tech-blog.abeja.asia/entry/geniac2-qwen25-32b-reasoning-v1.0)<br>([v1.0](https://huggingface.co/abeja/ABEJA-QwQ32b-Reasoning-Japanese-v1.0)) | **2025** | Qwen 2.5 (**32b**) | ABEJA-Qwen2.5-32b-Japanese-v0.1 ã« QwQ 32b ã® Chat Vector ã‚’ãƒãƒ¼ã‚¸ã—ãŸä¸Šã§è¿½åŠ å­¦ç¿’ | ABEJA | Apache 2.0 |
| [ABEJA-Qwen2.5-32b-Japanese-v0.1](https://tech-blog.abeja.asia/entry/geniac2-qwen25-32b-v0.1)<br>([32b-Japanese-v0.1](https://huggingface.co/abeja/ABEJA-Qwen2.5-32b-Japanese-v0.1)) | **2025** | Qwen 2.5 (**32b**) | äº‹å‰å­¦ç¿’: Common Crawl, Cosmopedia, ç‹¬è‡ª<br>ï¼ˆè¨ˆ **100B** ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰<br>+ Chat Vector | ABEJA | Apache 2.0 |
| [neoAI-JP-QwQ-32B](https://zenn.dev/neoai/articles/1670bd029093b0)<br>([32B](https://huggingface.co/neoai-inc/neoAI-JP-QwQ-32B)) | **2025** | Qwen 2.5 (**32b**) | ç¶™ç¶šäº‹å‰å­¦ç¿’: [llm-jp-corpus v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)ã‹ã‚‰ç´„**4B**ãƒˆãƒ¼ã‚¯ãƒ³<br>+ QwQ-32Bã®Chat Vector | neoAI | Apache 2.0 |
| [neoAI-JP-DeepSeek-Qwen-32B](https://zenn.dev/neoai/articles/1670bd029093b0)<br>([32B](https://huggingface.co/neoai-inc/neoAI-JP-DeepSeek-Qwen-32B)) | **2025** | Qwen 2.5 (**32b**) | ç¶™ç¶šäº‹å‰å­¦ç¿’: [llm-jp-corpus v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3)ã‹ã‚‰ç´„**4B**ãƒˆãƒ¼ã‚¯ãƒ³<br>+ DeepSeek-R1-Distill-Qwen-32Bã®Chat Vector | neoAI | Apache 2.0 |
| [Gemma-2-Llama Swallow 27B](https://swallow-llm.github.io/gemma2-llama-swallow.ja.html)<br>([27b-pt-v0.1](https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1), [27b-it-v0.1](https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1)) | **2025** | Gemma 2 (**27b**) | äº‹å‰å­¦ç¿’: Wikipedia, DCLM-baseline-1.0, Swallow Corpus Version 2, Cosmopedia, Laboro ParaCorpus, FineMath-4+, Swallow Code Version 0.3<br>Instruction Tuning: Gemma-2-LMSYS-Chat-1M-Synth, Swallow-Magpie-Ultra-v0.1, Swallow-Gemma-Magpie-v0.1 | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3.3 Community License & Gemma Terms of Use |
| [Nekomata 14B](https://huggingface.co/rinna/nekomata-14b)<br>([14b](https://huggingface.co/rinna/nekomata-14b), [14b-instruction](https://huggingface.co/rinna/nekomata-14b-instruction), [14b-gguf](https://huggingface.co/rinna/nekomata-14b-gguf), [14b-instruction-gguf](https://huggingface.co/rinna/nekomata-14b-instruction-gguf)) | 2023 | Qwen (**14b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese C4, Japanese CC-100, Japanese OSCAR, The Pile, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ **66B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, FLAN, llm-japanese-datasetã®ä¸€éƒ¨ | rinna | Tongyi Qianwen LICENSE |
| [Swallow 13B](https://swallow-llm.github.io/swallow-llama.ja.html)<br>([13b-hf](https://huggingface.co/tokyotech-llm/Swallow-13b-hf), [13b-instruct-hf](https://huggingface.co/tokyotech-llm/Swallow-13b-instruct-hf), [13b-instruct-v0.1](https://huggingface.co/tokyotech-llm/Swallow-13b-instruct-v0.1), [13b-NVE-hf](https://huggingface.co/tokyotech-llm/Swallow-13b-NVE-hf)) | 2023 | Llama 2 (**13b**) | äº‹å‰å­¦ç¿’: æ—¥æœ¬èª Wikipedia, RefinedWeb, Swallow Corpus, The Pile<br>Instruction Tuning: Dolly Dataset, HH RLHF, OASST1<br>*v0.1ãƒ¢ãƒ‡ãƒ«ã§ã¯ OASST1, OASST2 ã‚’ä½¿ç”¨ | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 2 Community License |
| [LEIA-Swallow-13B](https://www.ousia.jp/news/leia)<br>([13b](https://huggingface.co/leia-llm/Leia-Swallow-13b)) | 2024 | Llama 2 (**13b**) | Swallow 13B ã«å¯¾ã—ã¦ LEIA ã§è¿½åŠ å­¦ç¿’ | å€‹äºº ([å±±ç”°è‚²çŸ¢](https://scholar.google.com/citations?user=M7YivToAAAAJ), [æå‡Œå¯’](https://scholar.google.co.jp/citations?user=z9is5FAAAAAJ)) | Llama 2 Community License |
| [ELYZA-japanese-Llama-2-13b](https://note.com/elyza/n/n5d42686b60b7)<br>([13b](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b), [13b-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b-instruct), [13b-fast](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b-fast), [13b-fast-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b-fast-instruct)) | 2023 | Llama 2 (**13b**) | äº‹å‰å­¦ç¿•: æ—¥æœ¬èª Wikipedia, Japanese OSCAR, ãã®ä»–ã‚¯ãƒ­ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ãªã©<br>(è¨ˆ **18B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ELYZA | Llama 2 Community License |
| [cyberagent/Mistral-Nemo-Japanese-Instruct-2408](https://huggingface.co/cyberagent/Mistral-Nemo-Japanese-Instruct-2408) | 2024 | Mistral NeMo (**12b**) | ä¸æ˜ | ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | Apache 2.0 |
| [Gemma-2-Llama Swallow 9B](https://swallow-llm.github.io/gemma2-llama-swallow.ja.html)<br>([9b-pt-v0.1](https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1), [9b-it-v0.1](https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1)) | **2025** | Gemma 2 (**9b**) | äº‹å‰å­¦ç¿’: Wikipedia, DCLM-baseline-1.0, Swallow Corpus Version 2, Cosmopedia, Laboro ParaCorpus, FineMath-4+, Swallow Code Version 0.3<br>Instruction Tuning: Gemma-2-LMSYS-Chat-1M-Synth, Swallow-Magpie-Ultra-v0.1, Swallow-Gemma-Magpie-v0.1 | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3.3 Community License & Gemma Terms of Use |
| [Llama 3.1 Swallow 8B](https://swallow-llm.github.io/llama3.1-swallow.ja.html)<br>([8B-v0.1](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-v0.1), [8B-Instruct-v0.1](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1), [8B-v0.2](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-v0.2), [8B-Instruct-v0.2](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2), [8B-Instruct-v0.3](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3), [8B-Instruct-v0.5](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5)) | **2025** | Llama 3.1 (**8b**) | äº‹å‰å­¦ç¿’: The Stack v2, Wikipedia, DCLM-baseline-1.0, Swallow Corpus Version 2, Cosmopedia, Laboro ParaCorpus<br>Instruction Tuning: lmsys-chat-1m-synth-ja-wo-pii-and-template-instructions, lmsys-chat-1m-synth-en-wo-pii-and-template-instructions, filtered-magpie-ultra-ja, filtered-magpie-ultra-en, gemma-magpie, Gemma-3-LMSYS-Chat-1M-Synth | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3.1 Community License<br>(Instructãƒ¢ãƒ‡ãƒ«ã¯ Gemma Terms of Use ã‚‚é©ç”¨) |
| [Llama 3 Swallow 8B](https://swallow-llm.github.io/llama3-swallow.ja.html)<br>([8B-v0.1](https://huggingface.co/tokyotech-llm/Llama-3-Swallow-8B-v0.1), [8B-Instruct-v0.1](https://huggingface.co/tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1)) | 2023 | Llama 3 (**8b**) | äº‹å‰å­¦ç¿’: Algebraic Stack, Wikipedia, RefinedWeb, Swallow Corpus, Cosmopedia, Laboro ParaCorpus, OpenWebMath<br>Instruction Tuning: OASST1 [^17] | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3 Community License |
| [turing-motors/Llama-3-heron-brain-8B-v0.3](https://huggingface.co/turing-motors/Llama-3-heron-brain-8B-v0.3) | 2024 | Llama 3 (**8b**) | Llama 3 Swallow 8B ã«å¯¾ã—ã¦è¿½åŠ å­¦ç¿’ï¼ˆè©³ç´°ä¸æ˜ï¼‰ | Turing | Llama 3 Community License |
| [Llama 3 Youko 8B](https://huggingface.co/rinna/llama-3-youko-8b)<br>([8b](https://huggingface.co/rinna/llama-3-youko-8b), [8b-instruct](https://huggingface.co/rinna/llama-3-youko-8b-instruct), [8b-gptq](https://huggingface.co/rinna/llama-3-youko-8b-gptq), [8b-instruct-gptq](https://huggingface.co/rinna/llama-3-youko-8b-instruct-gptq)) | 2024 | Llama 3 (**8b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese C4, Japanese CC-100, Japanese OSCAR, The Pile, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ **22B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning[^11]: Aya Dataset (Japanese subset), FLAN, Dolly Dataset, HH RLHF, OASST1, OASST2, MetaMathQA, CodeAlpaca Dataset, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>DPO: HelpSteer, HelpSteer2, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | rinna | Llama 3 Community License |
| [Llama 3 ELYZA JP 8B](https://note.com/elyza/n/n360b6084fdbd)<br>([8B](https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B), [8B-GGUF](https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B-GGUF), [8B-AWQ](https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B-AWQ)) | 2024 | Llama 3 (**8b**) | ä¸æ˜ | ELYZA | Llama 3 Community License |
| [Llama 3 neoAI 8B Chat v0.1](https://prtimes.jp/main/html/rd/p/000000017.000109048.html)<br>([8B-Chat-v0.1](https://huggingface.co/neoai-inc/Llama-3-neoAI-8B-Chat-v0.1)) | 2024 | Llama 3 (**8b**) | ä¸æ˜ | neoAI | Llama 3 Community License |
| [Llama 3 tedllm](https://www.teldevice.co.jp/pro_info/2024/press_241023.php)<br>([v0](https://huggingface.co/tokyo-electron-device-ai/llama3-tedllm-8b-v0)) | 2024 | Llama 3 (**8b**) | äº‹å‰å­¦ç¿’: æ—¥æœ¬èªã®ä¸€èˆ¬ã‚³ãƒ¼ãƒ‘ã‚¹ | æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³ ãƒ‡ãƒã‚¤ã‚¹ | Llama 3 Community License |
| [ELYZA-Shortcut-1.0-Qwen-7B](https://zenn.dev/elyza/articles/bc68f53fc0a83b)<br>([7B](https://huggingface.co/elyza/ELYZA-Shortcut-1.0-Qwen-7B)) | **2025** | Qwen 2.5 (**7b**) | äº‹å‰å­¦ç¿’ + SFT | ELYZA | Apache 2.0 |
| [Swallow 7B](https://swallow-llm.github.io/swallow-llama.ja.html)<br>([7b-hf](https://huggingface.co/tokyotech-llm/Swallow-7b-hf), [7b-instruct-hf](https://huggingface.co/tokyotech-llm/Swallow-7b-instruct-hf), [7b-instruct-v0.1](https://huggingface.co/tokyotech-llm/Swallow-7b-instruct-v0.1), [7b-NVE-hf](https://huggingface.co/tokyotech-llm/Swallow-7b-NVE-hf), [7b-NVE-instruct-hf](https://huggingface.co/tokyotech-llm/Swallow-7b-NVE-instruct-hf), [7b-plus-hf](https://huggingface.co/tokyotech-llm/Swallow-7b-plus-hf)) | 2023 | Llama 2 (**7b**) | äº‹å‰å­¦ç¿’: æ—¥æœ¬èª Wikipedia, RefinedWeb, Swallow Corpus, The Pile<br>Instruction Tuning: Dolly Dataset, HH RLHF, OASST1<br>*v0.1ãƒ¢ãƒ‡ãƒ«ã§ã¯ OASST1, OASST2 ã‚’ä½¿ç”¨ | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 2 Community License |
| [LEIA-Swallow-7B](https://www.ousia.jp/news/leia)<br>([7b](https://huggingface.co/leia-llm/Leia-Swallow-7b)) | 2024 | Llama 2 (**7b**) | Swallow 7B ã«å¯¾ã—ã¦ LEIA ã§è¿½åŠ å­¦ç¿’ | å€‹äºº ([å±±ç”°è‚²çŸ¢](https://scholar.google.com/citations?user=M7YivToAAAAJ), [æå‡Œå¯’](https://scholar.google.co.jp/citations?user=z9is5FAAAAAJ)) | Llama 2 Community License |
| [ELYZA-japanese-Llama-2-7b](https://note.com/elyza/n/na405acaca130)<br> ([7b](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b), [7b-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-instruct), [7b-fast](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-fast), [7b-fast-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-fast-instruct)) | 2023 | Llama 2 (**7b**) | äº‹å‰å­¦ç¿’: æ—¥æœ¬èª Wikipedia, Japanese OSCAR, ãã®ä»–ã‚¯ãƒ­ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ãªã©<br>(è¨ˆ **18B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ELYZA | Llama 2 Community License |
| [Youri 7B](https://huggingface.co/rinna/youri-7b)<br>([7b](https://huggingface.co/rinna/youri-7b), [7b-instruction](https://huggingface.co/rinna/youri-7b-instruction), [7b-chat](https://huggingface.co/rinna/youri-7b-chat), [7b-gptq](https://huggingface.co/rinna/youri-7b-gptq), [7b-instruction-gptq](https://huggingface.co/rinna/youri-7b-instruction-gptq), [7b-chat-gptq](https://huggingface.co/rinna/youri-7b-chat-gptq)) | 2023 | Llama 2 (**7b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese C4, Japanese CC-100, Japanese OSCAR, The Pile, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ **40B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, FLAN, llm-japanese-datasetã®ä¸€éƒ¨ | rinna | Llama 2 Community License |
| [houou-7b](https://corp.moneyforward.com/news/release/corp/20231206-mf-press-1/)<br>([instruction-7b-v1](https://huggingface.co/moneyforward/houou-instruction-7b-v1), [instruction-7b-v2](https://huggingface.co/moneyforward/houou-instruction-7b-v2), [instruction-7b-v3](https://huggingface.co/moneyforward/houou-instruction-7b-v3)) | 2023 | Llama 2 (**7b**) | Youri 7B (base) ã«å¯¾ã—ã¦ Instruction Tuning: [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/) | ãƒãƒãƒ¼ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ | Llama 2 Community License |
| [Japanese Stable LM Beta 7B](https://huggingface.co/stabilityai/japanese-stablelm-base-beta-70b)<br>([base-beta-7b](https://huggingface.co/stabilityai/japanese-stablelm-base-beta-7b), [base-ja_vocab-beta-7b](https://huggingface.co/stabilityai/japanese-stablelm-base-ja_vocab-beta-7b), [instruct-beta-7b](https://huggingface.co/stabilityai/japanese-stablelm-instruct-beta-7b), [instruct-ja_vocab-beta-7b](https://huggingface.co/stabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b)) | 2023 | Llama 2 (**7b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese mC4, Japanese CC-100, Japanese OSCAR, SlimPajama(Books3ã‚’é™¤å¤–)<br>(è¨ˆ **100B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, HH RLHF, OASST1 | Stability AI | Llama 2 Community License |
| [SambaLingo-Japanese](https://sambanova.ai/blog/sambalingo-open-source-language-experts)<br>([Base](https://huggingface.co/sambanovasystems/SambaLingo-Japanese-Base), [Chat](https://huggingface.co/sambanovasystems/SambaLingo-Japanese-Chat)) | 2024 | Llama 2 (**7b**) | äº‹å‰å­¦ç¿’: CulturaX<br>Instruction Tuning: ultrachat_200k<br>DPO: ultrafeedback, cai-conversation-harmless | SambaNova Systems | Llama 2 Community License (?)[^12] |
| [blue-lizard](https://prtimes.jp/main/html/rd/p/000000010.000125694.html)<br>([blue-lizard](https://huggingface.co/Deepreneur/blue-lizard)) | 2024 | Llama 2 (**7b**) | ä¸æ˜ | Deepreneur | Llama 2 Community License |
| [Swallow-MS 7B](https://swallow-llm.github.io/swallow-mistral.ja.html)<br>([7b-v0.1](https://huggingface.co/tokyotech-llm/Swallow-MS-7b-v0.1), [7b-instruct-v0.1](https://huggingface.co/tokyotech-llm/Swallow-MS-7b-instruct-v0.1)) | 2024 | Mistral-7B-v0.1 (**7b**) | äº‹å‰å­¦ç¿’: Algebraic Stack, Japanese Wikipedia, RefinedWeb, Swallow Corpus, The Pile<br>Instruction Tuning: Dolly Dataset, OASST1 | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Apache 2.0 |
| [Rakuten AI 2.0](https://corp.rakuten.co.jp/news/press/2025/0212_02.html)<br>([8x7B](https://huggingface.co/Rakuten/RakutenAI-2.0-8x7B), [8x7B-instruct](https://huggingface.co/Rakuten/RakutenAI-2.0-8x7B-instruct)) | **2025** | Mistral-7B-v0.1 (**7b**) | | æ¥½å¤© | Apache 2.0 |
| [RakutenAI-7B](https://corp.rakuten.co.jp/news/press/2024/0321_01.html?year=2024&month=3&category=corp)<br>([7B](https://huggingface.co/Rakuten/RakutenAI-7B), [7B-instruct](https://huggingface.co/Rakuten/RakutenAI-7B-instruct), [7B-chat](https://huggingface.co/Rakuten/RakutenAI-7B-chat)) | 2024 | Mistral-7B-v0.1 (**7b**) | äº‹å‰å­¦ç¿’: ä¸æ˜<br>Instruction Tuning: Dolly Dataset, OASST1, ï¼ˆjasterã¨åŒæ§˜ã«ï¼‰è¨€èªç†è§£ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ Instruction Tuning ç”¨ã«å¤‰æ›ã—ãŸã‚‚ã®, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | æ¥½å¤© | Apache 2.0 |
| [Japanese Stable LM Gamma 7B](https://huggingface.co/stabilityai/japanese-stablelm-base-gamma-7b)<br>([base-gamma-7b](https://huggingface.co/stabilityai/japanese-stablelm-base-gamma-7b), [instruct-gamma-7b](https://huggingface.co/stabilityai/japanese-stablelm-instruct-gamma-7b)) | 2023 | Mistral-7B-v0.1 (**7b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese mC4, Japanese CC-100, Japanese OSCAR, SlimPajama(Books3ã‚’é™¤å¤–)<br>(è¨ˆ **100B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, HH RLHF, llm-japanese-dataSetã®wikinews subset | Stability AI |  Apache 2.0  |
| [ChatNTQ JA 7B](https://huggingface.co/NTQAI/chatntq-ja-7b-v1.0)<br>([7b-v1.0](https://huggingface.co/NTQAI/chatntq-ja-7b-v1.0)) | 2024 | Mistral-7B-v0.1 (**7b**) | Japanese Stable LM Gamma 7B (base) ã«å¯¾ã—ã¦ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ Instruction Tuning | NTQ Solution | Apache 2.0  |
| [Shisa Gamma 7B](https://huggingface.co/augmxnt/shisa-gamma-7b-v1)<br>([7b-v1](https://huggingface.co/augmxnt/shisa-gamma-7b-v1)) | 2023 | Mistral-7B-v0.1 (**7b**) | Japanese Stable LM Gamma 7B (base) ã«å¯¾ã—ã¦ ultra-orca-boros-en-ja ã§ Instruction Tuning | AUGMXNT | Apache 2.0 (?)[^12]  |
| [Shisa 7B](https://github.com/AUGMXNT/shisa/wiki)<br>([base-7b-v1](https://huggingface.co/augmxnt/shisa-base-7b-v1), [7b-v1](https://huggingface.co/augmxnt/shisa-7b-v1)) | 2023 | Mistral-7B-v0.1 (**7b**) | äº‹å‰å­¦ç¿’: shisa-pretrain-en-ja-v1 (**8B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning & DPO: ultra-orca-boros-en-ja, shisa-en-ja-dpo-v1  | AUGMXNT |  Apache 2.0 (?)[^12]  |
| [Karasu](https://www.lightblue-tech.com/2024/01/15/20240115_news/)<br>([7B](https://huggingface.co/lightblue/karasu-7B), [7B-chat](https://huggingface.co/lightblue/karasu-7B-chat), [7B-chat-plus](https://huggingface.co/lightblue/karasu-7B-chat-plus), [7B-chat-plus-unleashed](https://huggingface.co/lightblue/karasu-7B-chat-plus-unleashed)) | 2024 | Mistral-7B-v0.1 (**7b**) | Shisa 7B (base) ã«å¯¾ã—ã¦ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¿½åŠ äº‹å‰å­¦ç¿’: é’ç©ºæ–‡åº«, æ—¥æœ¬ã®æ³•å¾‹ãƒ»åˆ¤ä¾‹, æ—¥æœ¬èª Wikipedia, CulturaX ã®æ—¥æœ¬ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿, UltraChat 200k (è¨ˆ **7B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: ultra-orca-boros-en-ja-v1, OASST1, ShareGPT, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | Lightblue | Apache 2.0 (?)[^12]  |
| [Nekomata 7B](https://huggingface.co/rinna/nekomata-7b)<br>([7b](https://huggingface.co/rinna/nekomata-7b), [7b-instruction](https://huggingface.co/rinna/nekomata-7b-instruction), [7b-gguf](https://huggingface.co/rinna/nekomata-7b-gguf), [7b-instruction-gguf](https://huggingface.co/rinna/nekomata-7b-instruction-gguf)) | 2023 | Qwen (**7b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese C4, Japanese CC-100, Japanese OSCAR, The Pile, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ **66B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, FLAN, llm-japanese-datasetã®ä¸€éƒ¨ | rinna | Tongyi Qianwen LICENSE |
| [lightblue/japanese-mpt-7b](https://huggingface.co/lightblue/japanese-mpt-7b) | 2023 | MPT (**7b**) | Japanese mC4 | Lightblue | Apache 2.0 |
| [Japanese Stable LM 3B-4E1T](https://huggingface.co/stabilityai/japanese-stablelm-base-gamma-7b)<br>([3b-4e1t-base](https://huggingface.co/stabilityai/japanese-stablelm-3b-4e1t-base), [3b-4e1t-instruct](https://huggingface.co/stabilityai/japanese-stablelm-3b-4e1t-instruct)) | 2024 | StableLM-3B-4E1T (**3b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese mC4, Japanese CC-100, Japanese OSCAR, SlimPajama(Books3ã‚’é™¤å¤–)<br>(è¨ˆ **100B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>Instruction Tuning: Dolly Dataset, HH RLHF, llm-japanese-datasetã®wikinews subset | Stability AI |  Apache 2.0  |
| [kotomamba-2.8B-CL](https://huggingface.co/kotoba-tech/kotomamba-2.8B-CL-v1.0) | 2024 | mamba-2.8b-slimpj<br>(**2.8b**) | æ—¥æœ¬èª Wikipedia, Swallow Corpus, SlimPajama | Kotoba Technologies | Apache 2.0 |
| [Gemma-2-Llama Swallow 2B](https://swallow-llm.github.io/gemma2-llama-swallow.ja.html)<br>([2b-pt-v0.1](https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1), [2b-it-v0.1](https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1)) | **2025** | Gemma 2 (**2b**) | äº‹å‰å­¦ç¿’: Wikipedia, DCLM-baseline-1.0, Swallow Corpus Version 2, Cosmopedia, Laboro ParaCorpus, FineMath-4+, Swallow Code Version 0.3<br>Instruction Tuning: Gemma-2-LMSYS-Chat-1M-Synth, Swallow-Magpie-Ultra-v0.1, Swallow-Gemma-Magpie-v0.1 | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Llama 3.3 Community License & Gemma Terms of Use |
| [Gemma 2 Baku 2B](https://huggingface.co/rinna/gemma-2-baku-2b)<br>([2b](https://huggingface.co/rinna/gemma-2-baku-2b), [2b-it](https://huggingface.co/rinna/gemma-2-baku-2b-it)) | 2024 | Gemma 2 (**2b**) | äº‹å‰å­¦ç¿’: Wikipedia, Japanese C4, Japanese CC-100, Japanese OSCAR, The Pile, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>(è¨ˆ **80B** ãƒˆãƒ¼ã‚¯ãƒ³)<br>OPRO: ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ [^20] | rinna | Gemma Terms of Use |
| [Japanese Stable LM 2 1.6B](https://huggingface.co/stabilityai/japanese-stablelm-2-base-1_6b)<br>([base](https://huggingface.co/stabilityai/japanese-stablelm-2-base-1_6b), [instruct](https://huggingface.co/stabilityai/japanese-stablelm-2-instruct-1_6b)) | 2024 | Stable LM 2 1.6B (**1.6b**) | äº‹å‰å­¦ç¿’: Wikipedia, CulturaX<br>Instruction Tuning: jaster, [ichikara-instruction](https://liat-aip.sakura.ne.jp/wp/llm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%A9%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90/), alpaca-gpt4-japanese, ultra-orca-boros-en-ja-v1 | Stability AI | STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE |
| [TinySwallow-1.5B](https://sakana.ai/taid-jp/)<br>([1.5B](https://huggingface.co/SakanaAI/TinySwallow-1.5B), [1.5B-Instruct](https://huggingface.co/SakanaAI/TinySwallow-1.5B-Instruct), [1.5B-Instruct-q4f32_1-MLC](https://huggingface.co/SakanaAI/TinySwallow-1.5B-Instruct-q4f32_1-MLC), [1.5B-Insturct-GGUF](https://huggingface.co/SakanaAI/TinySwallow-1.5B-Instruct-GGUF)) | **2025** | Qwen2.5 (**1.5b**) | äº‹å‰å­¦ç¿’: Qwen2.5 (32b) ã‚’æ•™å¸«ã¨ã—ã¦ TAID ã§å­¦ç¿’<br>Instruction Tuning: Gemma-2-LMSYS-Chat-1M-Synth, swallow-magpie-ultra-v0.1, swallow-gemma-magpie-v0.1 | Sakana AI, Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Apache 2.0 |
| [EQUES/OpenRS3-GRPO-ja](https://huggingface.co/EQUES/OpenRS3-GRPO-ja) | **2025** | TinySwallow-1.5B-Instruct (**1.5b**) | kunishou/OpenMathInstruct-1-1.8m-ja ã§GRPOå­¦ç¿’ | EQUES Inc. | ï¼Ÿ |
| [EQUES/TinyDeepSeek-JP-1.5B](https://huggingface.co/EQUES/TinyDeepSeek-JP-1.5B) | **2025** | TinySwallow-1.5B-Instruct (**1.5b**) | EQUES/japanese_ultrachat_6.6k ã§TAIDè’¸ç•™ | EQUES Inc. | Apache 2.0 |
| [EQUES/TinySwallow-Stratos-1.5B](https://huggingface.co/EQUES/TinySwallow-Stratos-1.5B) | **2025** | TinySwallow-1.5B-Instruct (**1.5b**) | Bespoke-Stratos-35k ã§æ¨è«–èƒ½åŠ›å¼·åŒ– | EQUES Inc. | Apache 2.0 |
| [karasu-1.1B](https://huggingface.co/lightblue/karasu-1.1B) | 2023 | TinyLlama (**1.1b**) | äº‹å‰å­¦ç¿’: Japanese OSCAR, Japanese mC4<br>(è¨ˆ **3B** ãƒˆãƒ¼ã‚¯ãƒ³) | Lightblue | Apache 2.0 |

<a id="generative-continual-domain-specific"></a>
#### ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹

|    | ãƒ‰ãƒ¡ã‚¤ãƒ³ | ãƒ™ãƒ¼ã‚¹ã®LLM  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [pfnet/Preferred-MedLLM-Qwen-72B](https://huggingface.co/pfnet/Preferred-MedLLM-Qwen-72B) | åŒ»ç™‚ | Qwen2.5 (**72b**) | Preferred Networks | Qwen LICENSE |
| [Llama3-Preferred-MedSwallow-70B](https://tech.preferred.jp/ja/blog/llama3-preferred-medswallow-70b/)<br>([70B](https://huggingface.co/pfnet/Llama3-Preferred-MedSwallow-70B)) | åŒ»ç™‚ | Llama 3 (**70b**) | Preferred Networks | Llama 3 Community License |
| [AIgroup-CVM-utokyohospital/MedSwallow-70b](https://huggingface.co/AIgroup-CVM-utokyohospital/MedSwallow-70b) | åŒ»ç™‚ | Llama 2 (**70b**) | æ±äº¬å¤§å­¦åŒ»å­¦éƒ¨é™„å±ç—…é™¢ å¾ªç’°å™¨å†…ç§‘ AIã‚°ãƒ«ãƒ¼ãƒ— | CC BY-NC-SA 4.0 |
| [nekomata-14b-pfn-qfin](https://tech.preferred.jp/ja/blog/qfin-llm-continual-pretraining/)<br>([qfin](https://huggingface.co/pfnet/nekomata-14b-pfn-qfin), [qfin-inst-merge](https://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge)) | é‡‘è | Qwen (**14b**) | Preferred Networks | Tongyi Qianwen LICENSE |
| [Watashiha-Llama-2-13B-Ogiri-sft](https://huggingface.co/watashiha/Watashiha-Llama-2-13B-Ogiri-sft)<br>([sft](https://huggingface.co/watashiha/Watashiha-Llama-2-13B-Ogiri-sft), [sft-neuron](https://huggingface.co/watashiha/Watashiha-Llama-2-13B-Ogiri-sft-neuron)) | å¤§å–œåˆ© | Llama 2 (**13b**) | ã‚ãŸã—ã¯ | Llama 2 Community License |
| [ã‹ã‚‰ã¾ã‚‹](https://sakana.ai/karamaru/)<br>([Karamaru-v1](https://huggingface.co/SakanaAI/Llama-3-Karamaru-v1)) | æ±Ÿæˆ¸æ™‚ä»£ã®å¤æ–‡ | Llama 3 (**8b**) | Sakana AI | Llama 3 Community License |
| [Llama 3.1 Future Code Ja 8B](https://huggingface.co/future-architect/Llama-3.1-Future-Code-Ja-8B) | ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° | Llama 3.1<br>(**8b**) | ãƒ•ãƒ¥ãƒ¼ãƒãƒ£ãƒ¼ | Llama 3.1 Community License |
| [JPharmatron](https://huggingface.co/collections/EQUES/pharmatron-680a330b4dfce3ac43009984)<br>([7B-base](https://huggingface.co/EQUES/JPharmatron-7B-base), [7B](https://huggingface.co/EQUES/JPharmatron-7B)) | è–¬å­¦ | Qwen2.5 (**7b**) | EQUES Inc. | CC BY-SA 4.0 |
| [ELYZA-japanese-CodeLlama-7b](https://note.com/elyza/n/n5bce23d7c9c8)<br>([7b](https://huggingface.co/elyza/ELYZA-japanese-CodeLlama-7b), [7b-instruct](https://huggingface.co/elyza/ELYZA-japanese-CodeLlama-7b-instruct)) | ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° |  Code Llama<br>(**7b**) | ELYZA | Llama 2 Community License |
| [AIBunCho/japanese-novel-gpt-j-6b](https://huggingface.co/AIBunCho/japanese-novel-gpt-j-6b) | ç‰©èªç”Ÿæˆ | GPT-J (**6b**) | å€‹äºº ([å¤§æ›½æ ¹å®å¹¸](https://scholar.google.co.jp/citations?user=6ID5K3oAAAAJ)) | CreativeML OpenRAIL-M License |
| [NovelAI/genji-jp](https://huggingface.co/NovelAI/genji-jp) | ç‰©èªç”Ÿæˆ | GPT-J (**6b**) | NovelAI |  ï¼Ÿ  |

<a id="instruction-only-models"></a>
### æµ·å¤–ãƒ¢ãƒ‡ãƒ«ã«æ—¥æœ¬èªã§äº‹å¾Œå­¦ç¿’ã®ã¿è¡Œã£ãŸãƒ¢ãƒ‡ãƒ«

<a id="generative-instruction-only-general"></a>
#### æ±ç”¨

|    | ãƒ™ãƒ¼ã‚¹ã®LLM  | å­¦ç¿’ãƒ†ã‚­ã‚¹ãƒˆ | é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ / åˆ©ç”¨è¦ç´„ |
|:---|:---:|:---:|:---:|:---:|
| [Llama 3.1 Shisa V2 405B](https://shisa.ai/posts/shisa-v2-405b-ja-pr/)<br>([**405b**](https://huggingface.co/shisa-ai/shisa-v2-llama3.1-405b)) | Llama 3.1 (**405b**) | é«˜å“è³ªãªæ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§SFT/DPO | Shisa.AI | Llama 3.1 Community License |
| [AXCXEPT/EZO-Qwen2.5-72B-Instruct](https://huggingface.co/AXCXEPT/EZO-Qwen2.5-72B-Instruct)<br>[AXCXEPT/EZO-AutoCoTRAG-Qwen2.5-72B-Instruct_q4](https://huggingface.co/AXCXEPT/EZO-AutoCoTRAG-Qwen2.5-72B-Instruct_q4) | Qwen2.5 (**72b**) || Axcxept | Qwen License |
| [ao-Karasu](https://note.com/lightblue_tech/n/nfda12435b262)<br>([72B](https://huggingface.co/lightblue/ao-karasu-72B)) | Qwen1.5 (**72b**) | ultra-orca-boros-en-ja-v1, OASST1, ShareGPT, æ—¥æœ¬èªã®å…¬é–‹æŠ€è¡“ãƒ–ãƒ­ã‚°, ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹, QAã‚µã‚¤ãƒˆã®å›ç­”, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | Lightblue |  Tongyi Qianwen LICENSE (?)[^12] |
| [Shisa V2.1 70B](https://shisa.ai/posts/shisa-v2.1-ja-pr/)<br>([**70b**](https://huggingface.co/shisa-ai/shisa-v2.1-llama3.3-70b)) | Llama 3.3 (**70b**) | SFT/DPO/å¼·åŒ–å­¦ç¿’/ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸå­¦ç¿’ | Shisa.AI | Llama 3.3 Community License |
| [shisa-ai/shisa-v2-llama3.3-70b](https://huggingface.co/shisa-ai/shisa-v2-llama3.3-70b) | Llama 3.3 (**70b**) || Shisa.AI | Llama 3.3 Community License |
| [AXCXEPT/Llama-3.1-70B-EZO-1.1-it](https://huggingface.co/AXCXEPT/Llama-3.1-70B-EZO-1.1-it) | Llama 3.1 (**70b**) || Axcxept | Llama 3.1 Community License |
| [Llama 3 shisa-v1-llama3-70b](https://huggingface.co/shisa-ai/shisa-v1-llama3-70b)<br>([70b](https://huggingface.co/shisa-ai/shisa-v1-llama3-70b)) | Llama 3 (**70b**) | ultra-orca-boros-en-ja-v1 | Shisa.AI | Llama 3 Community License (?)[^12] |
| [AIgroup-CVM-utokyohospital/Llama-2-70b-chat-4bit-japanese](https://huggingface.co/AIgroup-CVM-utokyohospital/Llama-2-70b-chat-4bit-japanese) | Llama 2 (**70b**) || æ±äº¬å¤§å­¦åŒ»å­¦éƒ¨é™„å±ç—…é™¢ å¾ªç’°å™¨å†…ç§‘ AIã‚°ãƒ«ãƒ¼ãƒ— | Llama 2 Community License |
| [doshisha-mil/llama-2-70b-chat-4bit-japanese-v1](https://huggingface.co/doshisha-mil/llama-2-70b-chat-4bit-japanese-v1) | Llama 2 (**70b**) || åŒå¿—ç¤¾å¤§å­¦ ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±å­¦ç ”ç©¶å®¤ | ï¼Ÿ |
| [cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese](https://huggingface.co/cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese) | DeepSeek-R1-Distill-Qwen (**32b**) || ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | MIT |
| [Flux-Japanese-Qwen2.5-32B-Instruct-V1.0](https://flux.jp/news/1093/)<br>([V1.0](https://huggingface.co/flux-inc/Flux-Japanese-Qwen2.5-32B-Instruct-V1.0)) | Qwen2.5-32B-Instruct (**32b**) | Precise-tuning: æ—¥æœ¬èªã®çŸ¥è­˜ãƒ»æ¨è«–ãƒ»è¨€èªå›è·¯ã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆç‰¹å®šã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®5%ã®ã¿ã«å¯¾ã—ã¦èª¿æ•´ã‚’å®Ÿæ–½ã€‚3ã¤ã®å°‚é–€ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆå¾Œã€ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚¸ã§çµ±åˆ | FLUX | Apache 2.0 |
| [karakuri-ai/karakuri-lm-32b-thinking-2501-exp](https://huggingface.co/karakuri-ai/karakuri-lm-32b-thinking-2501-exp) | QwQ (**32b**) || ã‚«ãƒ©ã‚¯ãƒª | Apache 2.0 |
| [shisa-ai/shisa-v2-qwen2.5-32b](https://huggingface.co/shisa-ai/shisa-v2-qwen2.5-32b) | Qwen2.5 (**32b**) || Shisa.AI | Apache 2.0 |
| [AXCXEPT/EZO-Qwen2.5-32B-Instruct](https://huggingface.co/AXCXEPT/EZO-Qwen2.5-32B-Instruct)<br>[AXCXEPT/EZO-AutoCoTRAG-Qwen2.5-32B-Instruct](https://huggingface.co/AXCXEPT/EZO-AutoCoTRAG-Qwen2.5-32B-Instruct) | Qwen2.5 (**32b**) || Axcxept | Apache 2.0 |
| [cyberagent/DeepSeek-R1-Distill-Qwen-14B-Japanese](https://huggingface.co/cyberagent/DeepSeek-R1-Distill-Qwen-14B-Japanese) | DeepSeek-R1-Distill-Qwen (**14b**) || ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | MIT |
| [Shisa V2.1 14B](https://shisa.ai/posts/shisa-v2.1-ja-pr/)<br>([**14b**](https://huggingface.co/shisa-ai/shisa-v2.1-unphi4-14b)) | Phi-4 (**14b**) | SFT/DPO/å¼·åŒ–å­¦ç¿’/ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸå­¦ç¿’ | Shisa.AI | MIT |
| [shisa-ai/shisa-v2-unphi4-14b](https://huggingface.co/shisa-ai/shisa-v2-unphi4-14b) | Phi-4 (**14b**) || Shisa.AI | MIT |
| [EZO-Phi-4](https://huggingface.co/collections/AXCXEPT/ezo-phi-4-678a461c325df99089b387f3)<br>([phi-4-open-R1-Distill-EZOv1](https://huggingface.co/AXCXEPT/phi-4-open-R1-Distill-EZOv1), [phi-4-deepseek-R1K-RL-EZO](https://huggingface.co/AXCXEPT/phi-4-deepseek-R1K-RL-EZO)) | Phi-4 (**14b**) || Axcxept | MIT |
| [Qarasu](https://www.lightblue-tech.com/2024/01/15/20240115_news/)<br>([14B-chat-plus-unleashed](https://huggingface.co/lightblue/qarasu-14B-chat-plus-unleashed)) | Qwen (**14b**) | ultra-orca-boros-en-ja-v1, OASST1, ShareGPT, ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | Lightblue | Tongyi Qianwen LICENSE (?)[^12] |
| [Sparticle/llama-2-13b-chat-japanese-lora](https://huggingface.co/Sparticle/llama-2-13b-chat-japanese-lora) | Llama 2 (**13b**) || Sparticle | ï¼Ÿ |
| [izumi-lab/llama-13b-japanese-lora-v0-1ep](https://huggingface.co/izumi-lab/llama-13b-japanese-lora-v0-1ep) | Llama (**13b**) || æ±å¤§ å’Œæ³‰ç ” |  ï¼Ÿ |
| [shisa-ai/shisa-v2-mistral-nemo-12b](https://huggingface.co/shisa-ai/shisa-v2-mistral-nemo-12b) | Mistral NeMo (**12b**) || Shisa.AI | Apache 2.0 |
| [AXCXEPT/EZO-Common-9B-gemma-2-it](https://huggingface.co/AXCXEPT/EZO-Common-9B-gemma-2-it) | Gemma 2 (**9b**) || Axcxept | Gemma Terms of Use |
| [AXCXEPT/EZO-Humanities-9B-gemma-2-it](https://huggingface.co/AXCXEPT/EZO-Humanities-9B-gemma-2-it) |Gemma 2 (**9b**) || Axcxept | Gemma Terms of Use |
| [Shisa V2.1 8B](https://shisa.ai/posts/shisa-v2.1-ja-pr/)<br>([**8b**](https://huggingface.co/shisa-ai/shisa-v2.1-qwen3-8b)) | Qwen3 (**8b**) | SFT/DPO/å¼·åŒ–å­¦ç¿’/ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸå­¦ç¿’ | Shisa.AI | Apache 2.0 |
| [AXCXEPT/Qwen3-EZO-8B-beta](https://huggingface.co/AXCXEPT/Qwen3-EZO-8B-beta) | Qwen3 (**8b**) | Deep-ThinkæŠ€è¡“ã«ã‚ˆã‚‹é«˜æ€§èƒ½æ¨è«– | Axcxept | Apache 2.0 |
| [shisa-ai/shisa-v2-llama3.1-8b](https://huggingface.co/shisa-ai/shisa-v2-llama3.1-8b) | Llama 3.1 (**8b**) || Shisa.AI | Llama 3.1 Community License |
| [AXCXEPT/Llama-3.1-8B-EZO-1.1-it](https://huggingface.co/AXCXEPT/Llama-3.1-8B-EZO-1.1-it) |Llama 3.1 (**8b**) || Axcxept | Llama 3.1 Community License |
| [Llama 3 Suzume 8B](https://huggingface.co/lightblue/suzume-llama-3-8B-japanese)<br>([8B-japanese](https://huggingface.co/lightblue/suzume-llama-3-8B-japanese), [8B-japanese-gguf](https://huggingface.co/lightblue/suzume-llama-3-8B-japanese-gguf)) | Llama 3 (**8b**) | megagonlabs/instruction_ja, ShareGPT,  ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | Lightblue | Llama 3 Community License (?)[^12] |
| [Llama 3 shisa-v1-llama3-8b](https://huggingface.co/shisa-ai/shisa-v1-llama3-8b)<br>([8b](https://huggingface.co/shisa-ai/shisa-v1-llama3-8b)) | Llama 3 (**8b**) | ultra-orca-boros-en-ja-v1 | Shisa.AI | Llama 3 Community License (?)[^12] |
| [AXCXEPT/Llama-3-EZO-8b-Common-it](https://huggingface.co/AXCXEPT/Llama-3-EZO-8b-Common-it) |Llama 3 (**8b**) || Axcxept | Llama 3 Community License |
| [lightblue/DeepSeek-R1-Distill-Qwen-7B-Japanese](https://huggingface.co/lightblue/DeepSeek-R1-Distill-Qwen-7B-Japanese) | DeepSeek-R1-Distill-Qwen (**7b**) || Lightblue | Apache 2.0 |
| [ABEJA-Qwen2.5-7b-Japanese-v0.1](https://tech-blog.abeja.asia/entry/geniac2-qwen25-7b-v0.1)<br>([v0.1](https://huggingface.co/abeja/ABEJA-Qwen2.5-7b-Japanese-v0.1)) | Qwen 2.5 (**7b**) || ABEJA | Apache 2.0 |
| [shisa-ai/shisa-v2-qwen2.5-7b](https://huggingface.co/shisa-ai/shisa-v2-qwen2.5-7b) | Qwen 2.5 (**7b**) || Shisa.AI | Apache 2.0 |
| [Karasu DPO](https://note.com/lightblue_tech/n/n6967ff462f4a)<br>([7B](https://huggingface.co/lightblue/Karasu-DPO-7B)) | Qwen 2.5 (**7b**) || Lightblue | Apache 2.0 |
| [ganchengguang/Yoko-7B-Japanese-v1](https://huggingface.co/ganchengguang/Yoko-7B-Japanese-v1) | Llama 2 (**7b**) || æ¨ªæµœå›½å¤§ æ£®ç ” |  ï¼Ÿ  |
| [Sparticle/llama-2-7b-chat-japanese-lora](https://huggingface.co/Sparticle/llama-2-7b-chat-japanese-lora) | Llama 2 (**7b**) || Sparticle |  ï¼Ÿ  |
| [izumi-lab/llama-7b-japanese-lora-v0-5ep](https://huggingface.co/izumi-lab/llama-7b-japanese-lora-v0-5ep) | Llama (**7b**) || æ±å¤§ å’Œæ³‰ç ” |  ï¼Ÿ  |
| [lightblue/jod](https://huggingface.co/lightblue/jod) | Mistral-7B-SlimOrca (**7b**) || Lightblue | Apache 2.0 |
| [NTQAI/chatntq-7b-jpntuned](https://huggingface.co/NTQAI/chatntq-7b-jpntuned) | RWKV-4 World (**7b**) || NTQ Solution |  ï¼Ÿ  |
| [Borea](https://prtimes.jp/main/html/rd/p/000000008.000129878.html)<br>([Jp](https://huggingface.co/AXCXEPT/Borea-Phi-3.5-mini-Instruct-Jp), [Common](https://huggingface.co/AXCXEPT/Borea-Phi-3.5-mini-Instruct-Common), [Coding](https://huggingface.co/AXCXEPT/Borea-Phi-3.5-mini-Instruct-Coding)) | Phi-3.5 (**3.8b**) | | Axcxept | MIT |
| [Shisa V2.1 3B](https://shisa.ai/posts/shisa-v2.1-ja-pr/)<br>([**3b**](https://huggingface.co/shisa-ai/shisa-v2.1-llama3.2-3b)) | Llama 3.2 (**3b**) | SFT/DPO/å¼·åŒ–å­¦ç¿’/ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸå­¦ç¿’ | Shisa.AI | Llama 3.2 Community License |
| [AXCXEPT/EZO-Llama-3.2-3B-Instruct-dpoE](https://huggingface.co/AXCXEPT/EZO-Llama-3.2-3B-Instruct-dpoE) | Llama 3.2 (**3b**) || Axcxept | Llama 3.2 Community License |
| [æ—¥æœ¬èªç‰ˆ Gemma 2 2B](https://developers-jp.googleblog.com/2024/10/gemma-2-for-japan.html)<br>([2b-jpn-it](https://huggingface.co/google/gemma-2-2b-jpn-it)) | Gemma 2 (**2b**) || Google | Gemma Terms of Use |
| [AXCXEPT/EZO-gemma-2-2b-jpn-it](https://huggingface.co/AXCXEPT/EZO-gemma-2-2b-jpn-it) | Gemma 2 (**2b**) || Axcxept | Gemma Terms of Use |
| [AXCXEPT/EZO-Common-T2-2B-gemma-2-it](https://huggingface.co/AXCXEPT/EZO-Common-T2-2B-gemma-2-it) | Gemma 2 (**2b**) || Axcxept | Gemma Terms of Use |
| [Shisa V2.1 1.2B](https://shisa.ai/posts/shisa-v2.1-ja-pr/)<br>([**1.2b**](https://huggingface.co/shisa-ai/shisa-v2.1-lfm2-1.2b)) | LFM2 (**1.2b**) | SFT/DPO/å¼·åŒ–å­¦ç¿’/ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸå­¦ç¿’ | Shisa.AI | LFM Open License v1.0 |

<a id="generative-instruction-only-domain-specific"></a>
#### ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹

|    | ãƒ‰ãƒ¡ã‚¤ãƒ³ | ãƒ™ãƒ¼ã‚¹ã®LLM  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [JMedLoRA](https://arxiv.org/pdf/2310.10083.pdf)<br>([llama2-jmedlora-6.89ep](https://huggingface.co/AIgroup-CVM-utokyohospital/llama2-jmedlora-6.89ep)) | åŒ»ç™‚ | Llama 2 (**70b**) | æ±äº¬å¤§å­¦åŒ»å­¦éƒ¨é™„å±ç—…é™¢ å¾ªç’°å™¨å†…ç§‘ AIã‚°ãƒ«ãƒ¼ãƒ— | CC BY-NC 4.0 |
| [pfnet/Qwen3-1.7B-pfn-qfin](https://huggingface.co/pfnet/Qwen3-1.7B-pfn-qfin) | é‡‘è | Qwen3 (**1.72b**) | Preferred Networks | PLaMo Community License |
| [pfnet/Qwen2.5-1.5B-pfn-qfin](https://huggingface.co/pfnet/Qwen2.5-1.5B-pfn-qfin) | é‡‘è | Qwen2.5 (**1.54b**) | Preferred Networks | PLaMo Community License |

<a id="merged-models"></a>
### è¤‡æ•°ã®LLMã‚’ãƒãƒ¼ã‚¸ã—ã¦ä½œæˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«

|    |  ãƒãƒ¼ã‚¸å…ƒã®LLMï¼ˆå¤ªå­—ã¯æ—¥æœ¬èªLLMï¼‰  | é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|
 [EQUES/MedLLama3-JP-v2](https://huggingface.co/EQUES/MedLLama3-JP-v2) | **Llama 3 Swallow 8B (Instruct)**, OpenBioLLM-8B, MMed-Llama 3 8B, **Llama 3 ELYZA JP 8B** | EQUES | Llama 3 Community License |
| [EvoLLM-JP-A](https://sakana.ai/evolutionary-model-merge-jp/)<br>([v1-7B](https://huggingface.co/SakanaAI/EvoLLM-JP-A-v1-7B)) | **Shisa Gamma 7B (v1)**, Arithmo2 Mistral 7B, Abel 7B 002 | Sakana AI | Apache 2.0 |
| [EvoLLM-JP](https://sakana.ai/evolutionary-model-merge-jp/)<br>([v1-7B](https://huggingface.co/SakanaAI/EvoLLM-JP-v1-7B), [v1-10B](https://huggingface.co/SakanaAI/EvoLLM-JP-v1-10B)) | **Shisa Gamma 7B (v1)**, WizardMath-7B-V1.1, Abel 7B 002 | Sakana AI | MICROSOFT RESEARCH LICENSE |
| [EQUES/TinyQwens-Merge-1.5B](https://huggingface.co/EQUES/TinyQwens-Merge-1.5B) | **SakanaAI/TinySwallow-1.5B-Instruct**, **EQUES/TinySwallow-Stratos-1.5B**, deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, Qwen/Qwen2.5-1.5B-Instruct | EQUES Inc. | Apache 2.0 |

<a id="api-based-models"></a>
### APIã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«

|    |  å…¥å‡ºåŠ›ã§æ‰±ãˆã‚‹<br>ãƒˆãƒ¼ã‚¯ãƒ³æ•° | é–‹ç™ºå…ƒ  |  ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  |
|:---|:---:|:---:|:---:|
| [PLaMo API](https://plamo.preferredai.jp/api) | 32,768 | Preferred Networks | ç‹¬è‡ª |
| [AIã®ã¹ã‚Šã™ã¨](https://ai-novel.com/account_api.php) | 2,400 ~ 8,192 | Bit192 | ç‹¬è‡ª |
| [LHTM-OPT](https://aws.amazon.com/jp/blogs/psa/how-to-deploy-japanese-llm-lhtm-opt-on-aws-marketplace-developed-by-alt/) | | ã‚ªãƒ«ãƒ„ | AWS Marketplace |
| [tsuzumi](https://www.nttdata.com/global/ja/news/topics/2024/112000/)<br>([tsuzumi-7b](https://ai.azure.com/catalog/models/tsuzumi-7b)) | | NTT | Microsoft Foundry |

<a id="autoencoding"></a>
## å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†ã«ä¸»ã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«

<a id="autoencoding-general"></a>
### æ±ç”¨

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å…¥åŠ›ã§æ‰±ãˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°  |  å­¦ç¿’ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ | HuggingFace ã§ã™ãä½¿ãˆã‚‹ï¼Ÿ [^4]  |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|
| [ModernBERT-Ja](https://huggingface.co/sbintuitions/modernbert-ja-310m) | ModernBERT | **8,192** | æ—¥æœ¬èªãƒ»è‹±èªãƒ‡ãƒ¼ã‚¿ | SB Intuitions | MIT | â—¯ ([30m](https://huggingface.co/sbintuitions/modernbert-ja-30m), [70m](https://huggingface.co/sbintuitions/modernbert-ja-70m), [130m](https://huggingface.co/sbintuitions/modernbert-ja-130m), [310m](https://huggingface.co/sbintuitions/modernbert-ja-310m)) |
| [llm-jp-modernbert](https://llm-jp.nii.ac.jp/news/post-765/) | ModernBERT | **8,192** | llm-jp-corpus-v4 ã®æ—¥æœ¬èªã‚µãƒ–ã‚»ãƒƒãƒˆï¼ˆç´„**0.69T**ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰| å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 | [â—¯](https://huggingface.co/llm-jp/llm-jp-modernbert-base) |
|  [äº¬å¤§BERT](https://nlp.ist.i.kyoto-u.ac.jp/?ku_bert_japanese)  |  BERT (base, large)  | 512 |  æ—¥æœ¬èª Wikipedia (ç´„1,800ä¸‡æ–‡)  |  äº¬å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢ç ”ç©¶å®¤  | Apache 2.0 | â–³ |
|  [æ±åŒ—å¤§BERT](https://github.com/cl-tohoku/bert-japanese)  |  BERT (base, large)  | 512 |  base (v1):<br>æ—¥æœ¬èª Wikipedia ç´„1,700ä¸‡æ–‡ (2.6GB)<br>base (v2) & large:<br>æ—¥æœ¬èª Wikipedia ç´„3,000ä¸‡æ–‡ (4.0GB)<br>base (v3) & large (v2):<br>æ—¥æœ¬èª Wikipedia ç´„3,400ä¸‡æ–‡ (4.9GB)<br>+ æ—¥æœ¬èª CC-100 ç´„3å„„9,200ä¸‡æ–‡ (74.3GB)   |  æ±åŒ—å¤§<br>è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ— | base (v1, v2) & large: CC BY-SA 3.0<br>base (v3) & large (v2): Apache 2.0 |â—¯ ([base (v1)](https://huggingface.co/tohoku-nlp/bert-base-japanese-whole-word-masking), [base (v1, æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/tohoku-nlp/bert-base-japanese-char-whole-word-masking), [base (v2)](https://huggingface.co/tohoku-nlp/bert-base-japanese-v2), [base (v2, æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/tohoku-nlp/bert-base-japanese-char-v2), [large](https://huggingface.co/tohoku-nlp/bert-large-japanese), [large (æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/tohoku-nlp/bert-large-japanese-char), [base (v3)](https://huggingface.co/tohoku-nlp/bert-base-japanese-v3), [base (v3, æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/tohoku-nlp/bert-base-japanese-char-v3), [large (v2)](https://huggingface.co/tohoku-nlp/bert-large-japanese-v2), [large (v2, æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/tohoku-nlp/bert-large-japanese-char-v2)) |
| [TohokuNLP BERT-alpha 500M](https://huggingface.co/tohoku-nlp/tohokunlp-bert-500m-sq8192-alpha)  | Llama ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€[^23] | **4,096**<br>ã¾ãŸã¯<br>**8,192** | [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3) ã®æ—¥æœ¬èªã‚µãƒ–ã‚»ãƒƒãƒˆ | æ±åŒ—å¤§<br>è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ— | Apache 2.0 | â—¯ ([sq4096-alpha](https://huggingface.co/tohoku-nlp/tohokunlp-bert-500m-sq4096-alpha), [sq8192-alpha](https://huggingface.co/tohoku-nlp/tohokunlp-bert-500m-sq8192-alpha)) |
| [ByBERT-JP](https://huggingface.co/collections/tohoku-nlp/bybert-jp-68ca50cd4ea72d6d6b348fcd) | Llama ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€[^23] | 100m, 200m, 400m: 3,072<br>v2-100m: **4,096** | [llm-jp-corpus-v3](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3) ã®ã‚µãƒ–ã‚»ãƒƒãƒˆ<br>100m: 623B ãƒˆãƒ¼ã‚¯ãƒ³<br>200m: 637B ãƒˆãƒ¼ã‚¯ãƒ³<br>400m: 1.23T ãƒˆãƒ¼ã‚¯ãƒ³<br>v2-100m: 2.76T ãƒˆãƒ¼ã‚¯ãƒ³ | æ±åŒ—å¤§<br>è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ— | Apache 2.0 | â—¯ ([100m](https://huggingface.co/tohoku-nlp/bybert-jp-100m), [200m](https://huggingface.co/tohoku-nlp/bybert-jp-200m), [400m](https://huggingface.co/tohoku-nlp/bybert-jp-400m), [v2-100m](https://huggingface.co/tohoku-nlp/bybert-jp-v2-100m)) |
| [NICT BERT](https://alaginrc.nict.go.jp/nict-bert/index.html)   |  BERT (base)  | 512 |  æ—¥æœ¬èª Wikipedia  |  NICT  | CC BY 4.0 | â–³ |
| [Laboro BERT](https://github.com/laboroai/Laboro-BERT-Japanese) | BERT (base, large) | 512 | æ—¥æœ¬èª Web ã‚³ãƒ¼ãƒ‘ã‚¹ <br> (ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆã‚„ãƒ–ãƒ­ã‚°ãªã©<br>è¨ˆ4,307ã®Webã‚µã‚¤ãƒˆã€2,605,280ãƒšãƒ¼ã‚¸ (12GB)) | Laboro.AI | CC BY-NC 4.0 | âœ• |
| [colorfulscoop BERT](https://huggingface.co/colorfulscoop/bert-base-ja) | BERT (base) | 512 | æ—¥æœ¬èª Wikipedia | Colorful Scoop | CC BY-SA 3.0 | [â—¯](https://huggingface.co/colorfulscoop/bert-base-ja) |
| [æ±å¤§BERT](https://sites.google.com/socsim.org/izumi-lab/tools/language-model) | BERT (small) | 512 | æ—¥æœ¬èª Wikipedia (ç´„2,000ä¸‡æ–‡ (2.9GB)) | æ±å¤§ å’Œæ³‰ç ” | CC BY-SA 4.0 | [â—¯](https://huggingface.co/izumi-lab/bert-small-japanese) |
| [chiTra (Sudachi Transformers)](https://www.worksap.co.jp/news/2022/0225/) | BERT (base) | 512 | å›½èªç ”æ—¥æœ¬èªã‚¦ã‚§ãƒ–ã‚³ãƒ¼ãƒ‘ã‚¹ (NWJC) (148GB) | NINJAL, ãƒ¯ãƒ¼ã‚¯ã‚¹å¾³å³¶äººå·¥çŸ¥èƒ½NLPç ” | Apache 2.0 | â–³ |
| [ACCMS BERT](https://huggingface.co/ku-accms/bert-base-japanese-ssuw) | BERT (base) | 512 | æ—¥æœ¬èª Wikipedia (3.3GB) | äº¬å¤§ ACCMS | CC BY-SA 4.0 | [â—¯](https://huggingface.co/ku-accms/bert-base-japanese-ssuw) |
| [æ—¥ç«‹BERT](https://aclanthology.org/2023.acl-srw.5.pdf) | BERT (base) | 512 | æ—¥æœ¬èª Wikipedia <br>+ Japanese CC-100 | æ—¥ç«‹è£½ä½œæ‰€ | CC BY-NC-SA 4.0 | [â—¯](https://huggingface.co/hitachi-nlp/bert-base-japanese_jumanpp-bpe) [^6] |
| [RetrievaBERT](https://note.com/retrieva/n/n715bea2c2cd1) | BERT [^5] | **2,048** | Japanese CommonCrawl, RefinedWeb, Chinese Wikipedia, Korean Wikipedia, The Stack | ãƒ¬ãƒˆãƒªãƒ | Apache 2.0 | [â—¯](https://huggingface.co/retrieva-jp/bert-1.3b) |
| [Bandai Namco DistilBERT](https://github.com/BandaiNamcoResearchInc/DistilBERT-base-jp/blob/main/docs/GUIDE.md) | DistilBERT | 512 | - ï¼ˆæ±åŒ—å¤§BERT(base) ã‚’è¦ªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦çŸ¥è­˜è’¸ç•™ï¼‰ | Bandai Namco Research | MIT | [â—¯](https://huggingface.co/bandainamco-mirai/distilbert-base-japanese) |
| [Laboro DistilBERT](https://github.com/laboroai/Laboro-DistilBERT-Japanese) | DistilBERT | 512 | - ï¼ˆLaboro BERT(base) ã‚’è¦ªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦çŸ¥è­˜è’¸ç•™ï¼‰| Laboro.AI | CC BY-NC 4.0 | [â—¯](https://huggingface.co/laboro-ai/distilbert-base-japanese) |
| [LINE DistilBERT](https://engineering.linecorp.com/ja/blog/line-distilbert-high-performance-fast-lightweight-japanese-language-model) | DistilBERT | 512 | - ï¼ˆLINEç¤¾å†…ã®BERTã‚’è¦ªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦çŸ¥è­˜è’¸ç•™ï¼‰| LINE | Apache 2.0 | [â—¯](https://huggingface.co/line-corporation/line-distilbert-base-japanese) |
| [rinna RoBERTa](https://huggingface.co/rinna/japanese-roberta-base) | RoBERTa (base) | 512 |  æ—¥æœ¬èª Wikipedia <br>+ Japanese CC-100 | rinna | MIT | [â—¯](https://huggingface.co/rinna/japanese-roberta-base) |
| [æ—©å¤§RoBERTa](https://huggingface.co/nlp-waseda/roberta-base-japanese-with-auto-jumanpp) | RoBERTa (base, large) | 512 | æ—¥æœ¬èª Wikipedia <br>+ Japanese CC-100 | æ—©å¤§ æ²³åŸç ” | CC BY-SA 4.0 | â—¯ ([base](https://huggingface.co/nlp-waseda/roberta-base-japanese-with-auto-jumanpp), [large](https://huggingface.co/nlp-waseda/roberta-large-japanese-with-auto-jumanpp), [large (seq512)](https://huggingface.co/nlp-waseda/roberta-large-japanese-seq512-with-auto-jumanpp)) [^7] |
| [ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹RoBERTa](https://www.informatix.co.jp/pr-roberta/) | RoBERTa (base) | 512 | æ—¥æœ¬èª Wikipedia<br> + Web ä¸Šã®è¨˜äº‹ (è¨ˆ25GB) | ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ | Apache 2.0 | â–³ |
| [äº¬å¤§RoBERTa](https://huggingface.co/ku-nlp/roberta-base-japanese-char-wwm) | RoBERTa (base, large) | 512 | æ—¥æœ¬èª Wikipedia <br>+ Japanese CC-100 | äº¬å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢ç ”ç©¶å®¤ | CC BY-SA 4.0 | â—¯ ([base (æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/ku-nlp/roberta-base-japanese-char-wwm), [large (æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/ku-nlp/roberta-large-japanese-char-wwm)) |
| [æ¨ªæµœå›½å¤§RoBERTa](https://huggingface.co/ganchengguang/RoBERTa-base-janpanese) | RoBERTa (base) | 512 | æ—¥æœ¬èª Wikipedia (3.45GB) | æ¨ªæµœå›½å¤§ æ£®ç ” | Apache 2.0 | [â—¯](https://huggingface.co/ganchengguang/RoBERTa-base-janpanese) |
| [Megagon Labs RoBERTa](https://huggingface.co/megagonlabs/roberta-long-japanese) | RoBERTa (base) [^8] | **1,282** | Japanese mC4 (ç´„2å„„æ–‡) | Megagon Labs <br> (ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ) | MIT | [â—¯](https://huggingface.co/megagonlabs/roberta-long-japanese)  |
| [ACCMS RoBERTa](https://huggingface.co/ku-accms/roberta-base-japanese-ssuw) | RoBERTa (base) | 512 | æ—¥æœ¬èª Wikipedia (3.3GB) + Japanese CC-100 (70GB) | äº¬å¤§ ACCMS | CC BY-SA 4.0 | [â—¯](https://huggingface.co/ku-accms/roberta-base-japanese-ssuw) |
| [ã‚·ãƒŠãƒ¢ãƒ³ELECTRA](https://cinnamon.ai/ideas/20200619_research_001/) | ELECTRA (small) | 512 | æ—¥æœ¬èª Wikipedia | ã‚·ãƒŠãƒ¢ãƒ³ | Apache 2.0 | [â—¯](https://huggingface.co/Cinnamon/electra-small-japanese-discriminator)  |
| [Megagon Labs ELECTRA](https://www.recruit.co.jp/newsroom/pressrelease/2021/0826_9293.html) | ELECTRA (base) | 512 | Japanese mC4 (ç´„2å„„æ–‡) | Megagon Labs <br> (ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ) | MIT | [â—¯](https://huggingface.co/megagonlabs/electra-base-japanese-discriminator)  |
| [æ±å¤§ELECTRA](https://sites.google.com/socsim.org/izumi-lab/tools/language-model) | ELECTRA (small, base) | 512 | æ—¥æœ¬èª Wikipedia (ç´„2,000ä¸‡æ–‡ (2.9GB)) | æ±å¤§ å’Œæ³‰ç ” | CC BY-SA 4.0 | â—¯ ([small](https://huggingface.co/izumi-lab/electra-small-japanese-discriminator), [base](https://huggingface.co/izumi-lab/electra-base-japanese-discriminator))  |
| [æ—¥æœ¬èªRoFormer](https://huggingface.co/ganchengguang/Roformer-base-japanese) | RoFormer (base) | 512 | æ—¥æœ¬èª Wikipedia (3.45GB) | æ¨ªæµœå›½å¤§ æ£®ç ” | Apache 2.0 | [â—¯](https://huggingface.co/ganchengguang/Roformer-base-japanese) |
| [æ—¥æœ¬èªLUKE](https://www.ousia.jp/news/luke-japanese) | LUKE (base, large) | 512 | æ—¥æœ¬èª Wikipedia | Studio Ousia | Apache 2.0 | â—¯ ([base](https://huggingface.co/studio-ousia/luke-japanese-base-lite), [large](https://huggingface.co/studio-ousia/luke-japanese-large-lite)) |
| [äº¬å¤§DeBERTaV2](https://huggingface.co/ku-nlp/deberta-v2-base-japanese) | DeBERTaV2 (tiny, base, large) | 512 | æ—¥æœ¬èª Wikipedia <br> + Japanese CC-100 <br> + Japanese OSCAR<br>ï¼ˆè¨ˆ171GBï¼‰ | äº¬å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢ç ”ç©¶å®¤ | CC BY-SA 4.0 | â—¯ ([tiny](https://huggingface.co/ku-nlp/deberta-v2-tiny-japanese), [tiny (æ–‡å­—ãƒ¬ãƒ™ãƒ«)](https://huggingface.co/ku-nlp/deberta-v2-tiny-japanese-char-wwm), [base](https://huggingface.co/ku-nlp/deberta-v2-base-japanese), [large](https://huggingface.co/ku-nlp/deberta-v2-large-japanese)) |
| [äº¬å¤§DeBERTaV3](https://huggingface.co/ku-nlp/deberta-v3-base-japanese) | DeBERTaV3 (base) | 512 | [llm-jp-corpus](https://github.com/llm-jp/llm-jp-corpus) | äº¬å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢ç ”ç©¶å®¤ | Apache 2.0 | [â—¯](https://huggingface.co/ku-nlp/deberta-v3-base-japanese) |
| [æ±å¤§DeBERTaV2](https://sites.google.com/socsim.org/izumi-lab/tools/language-model) | DeBERTaV2 (small, base) | 512 | æ—¥æœ¬èª Wikipedia, æ—¥æœ¬èª Wikinews, Japanese CC-100, Japanese mC4, Japanese OSCAR | æ±å¤§ å’Œæ³‰ç ” | CC BY-SA 4.0 | â—¯ ([small](https://huggingface.co/izumi-lab/deberta-v2-small-japanese), [base](https://huggingface.co/izumi-lab/deberta-v2-base-japanese)) |
| [GLOBIS DeBERTaV3](https://qiita.com/akeyhero/items/d7c215ceac37b7d3290a) | DeBERTaV3 (xsmall, base, large) | 512 | Wikipedia, WikiBooks, é’ç©ºæ–‡åº«, Japanese CC-100, Japanese mC4, Japanese OSCAR | ã‚°ãƒ­ãƒ¼ãƒ“ã‚¹ | CC BY-SA 4.0 | â—¯ ([xsmall](https://huggingface.co/globis-university/deberta-v3-japanese-xsmall), [base](https://huggingface.co/globis-university/deberta-v3-japanese-base), [large](https://huggingface.co/globis-university/deberta-v3-japanese-large)) |
| [æ—¥æœ¬èªBigBird](https://huggingface.co/nlp-waseda/bigbird-base-japanese) | BigBird (base) | **4,096** | æ—¥æœ¬èª Wikipedia <br> + Japanese CC-100 <br> + Japanese OSCAR | æ—©å¤§ æ²³åŸç ” | CC BY-SA 4.0 | [â—¯](https://huggingface.co/nlp-waseda/bigbird-base-japanese) |
| [æ—¥æœ¬èªLayoutLM](https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/Q2-7.pdf) | LayoutLM (base) | 512 | æ±åŒ—å¤§BERT (base, v2) ã§é‡ã¿ã‚’åˆæœŸåŒ–ã—ãŸä¸Šã§ã€æ—¥æœ¬èª Wikipedia ã®æ–‡ç« ã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§äº‹å‰å­¦ç¿’ | æ—¥æœ¬ç·åˆç ”ç©¶æ‰€ | CC BY-SA 3.0 | [â—¯](https://huggingface.co/jri-advtechlab/layoutlm-wikipedia-ja) |

<a id="autoencoding-domain-specific"></a>
### ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹

|    |  ãƒ‰ãƒ¡ã‚¤ãƒ³  |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å­¦ç¿’ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ | HuggingFace ã§ã™ãä½¿ãˆã‚‹ï¼Ÿ  |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|
| [æ—¥æœ¬èªãƒ–ãƒ­ã‚°ELECTRA](https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/E2-5.pdf) | å£èª | ELECTRA (small) | æ—¥æœ¬èªãƒ–ãƒ­ã‚°ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆ3å„„5,400ä¸‡æ–‡ï¼‰ | åŒ—è¦‹å·¥å¤§ æ¡äº•ãƒ»ãƒ—ã‚¿ã‚·ãƒ³ã‚¹ã‚­ç ” | CC BY-SA 4.0 | [â—¯](https://huggingface.co/ptaszynski/yacis-electra-small-japanese)  |
| [æ—¥æœ¬èªè©±ã—è¨€è‘‰BERT](https://retrieva-tech.hatenablog.com/entry/2021/04/01/114943) | è©±ã—è¨€è‘‰ | BERT (base) | æ±åŒ—å¤§BERTã«å¯¾ã—ã¦æ—¥æœ¬èªè©±ã—è¨€è‘‰ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆCSJï¼‰ã‚’ç”¨ã„ã¦è¿½åŠ å­¦ç¿’<br>ï¼ˆDAPTãƒ¢ãƒ‡ãƒ«ã§ã¯å›½ä¼šè­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ã‚‚ä½¿ç”¨ï¼‰ | ãƒ¬ãƒˆãƒªãƒ | Apache 2.0 | [â—¯](https://huggingface.co/retrieva-jp/japanese-spoken-language-bert) |
| [AcademicRoBERTa](https://github.com/EhimeNLP/AcademicRoBERTa) | å­¦è¡“ | RoBERTa (base) | CiNii ã®æ—¥æœ¬èªè«–æ–‡ (ç´„628ä¸‡æ–‡) | æ„›åª›å¤§ äººå·¥çŸ¥èƒ½ç ”ç©¶å®¤ | Apache 2.0 | [â—¯](https://huggingface.co/EhimeNLP/AcademicRoBERTa) |
| [local-politics-BERT](http://local-politics.jp/%e5%85%ac%e9%96%8b%e7%89%a9/local-politics-bert/) | æ”¿æ²» | BERT (base) | Wikipedia, å›½ä¼šä¼šè­°éŒ², åœ°æ–¹è­°ä¼šä¼šè­°éŒ² | åœ°æ–¹è­°ä¼šä¼šè­°éŒ²ã‚³ãƒ¼ãƒ‘ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | CC BY-SA 4.0 | â—¯ ([SC-min](https://huggingface.co/local-politics-jp/bert-base-japanese-minutes-scratch), [SC-minwiki](https://huggingface.co/local-politics-jp/bert-base-japanese-minutes-wikipedia-scratch), [SC-2M-wiki](https://huggingface.co/local-politics-jp/bert-base-japanese-wikipedia-scratch-2m), [SC-2M-min](https://huggingface.co/local-politics-jp/bert-base-japanese-minutes-scratch-2m), [SC-2M-minwiki](https://huggingface.co/local-politics-jp/bert-base-japanese-minutes-wikipedia-scratch-2m), [FP-min](https://huggingface.co/local-politics-jp/bert-base-japanese-minutes-further), [FP-minwiki](https://huggingface.co/local-politics-jp/bert-base-japanese-minutes-wikipedia-further)) [^18] |
| [UBKE-LUKE](https://tech.uzabase.com/entry/2024/12/24/173942) | çµŒæ¸ˆ | LUKE (base) | æ—¥æœ¬èª Wikipedia, æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸, çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ | ãƒ¦ãƒ¼ã‚¶ãƒ™ãƒ¼ã‚¹ | CC BY-NC | [â—¯](https://huggingface.co/uzabase/UBKE-LUKE) |
| [æ—¥æœ¬èªé‡‘èBERT](https://sites.google.com/socsim.org/izumi-lab/tools/language-model) | é‡‘è | BERT (small, base) [^9] | æ—¥æœ¬èª Wikipedia<br> + æ—¥æœ¬èªé‡‘èã‚³ãƒ¼ãƒ‘ã‚¹ (ç´„2,700ä¸‡æ–‡ (5.2GB)) | æ±å¤§ å’Œæ³‰ç ” | CC BY-SA 4.0 |â—¯ ([small](https://huggingface.co/izumi-lab/bert-small-japanese-fin), [base](https://huggingface.co/izumi-lab/bert-base-japanese-fin-additional)) |
| [æ—¥æœ¬èªé‡‘èELECTRA](https://sites.google.com/socsim.org/izumi-lab/tools/language-model) | é‡‘è | ELECTRA (small) | æ—¥æœ¬èª Wikipedia (ç´„2,000ä¸‡æ–‡ (2.9GB)) <br> + æ—¥æœ¬èªé‡‘èã‚³ãƒ¼ãƒ‘ã‚¹ (ç´„2,700ä¸‡æ–‡ (5.2GB)) | æ±å¤§ å’Œæ³‰ç ” | CC BY-SA 4.0 |  [â—¯](https://huggingface.co/izumi-lab/electra-small-japanese-fin-discriminator)  |
| [æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹BERT](https://qiita.com/mkt3/items/3c1278339ff1bcc0187f) | ãƒ“ã‚¸ãƒã‚¹ | BERT (base) | æ—¥æœ¬èªãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹(300ä¸‡è¨˜äº‹) | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | CC BY 4.0 | â–³ |
| [æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹XLNet](https://qiita.com/mkt3/items/4d0ae36f3f212aee8002) |  ãƒ“ã‚¸ãƒã‚¹  | XLNet (base) | æ—¥æœ¬èªãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹(300ä¸‡è¨˜äº‹) | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | ï¼Ÿ | â€» éå…¬å¼ã® HuggingFace å‘ã‘ã«å¤‰æ›ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒ[å…¬é–‹ã•ã‚Œã¦ã„ã‚‹](https://huggingface.co/hajime9652/xlnet-japanese) |
| [æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹ALBERT](https://qiita.com/mkt3/items/b41dcf0185e5873f5f75) | ãƒ“ã‚¸ãƒã‚¹  | ALBERT (base) | æ—¥æœ¬èªãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹(300ä¸‡è¨˜äº‹) | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | ï¼Ÿ | â–³ |
| [ã¿ã‚“ã±ãBERT](https://proceedings-of-deim.github.io/DEIM2022/papers/F43-4.pdf) | æ–‡åŒ–è²¡ | BERT (base) | æ±åŒ—å¤§BERTã«å¯¾ã—ã¦å›½ç«‹æ°‘æ—å­¦åšç‰©é¤¨ã®æ–‡åŒ–è²¡ãƒ‡ãƒ¼ã‚¿ã§è¿½åŠ å­¦ç¿’ | å…µåº«çœŒç«‹å¤§å­¦ å¤§å³¶ç ” | MIT | â—¯ ([minpaku-v1](https://huggingface.co/ohshimalab/bert-base-minpaku-v1), [minpaku-v3](https://huggingface.co/ohshimalab/bert-base-minpaku-v3), [minpaku-v3-no-additional-token](https://huggingface.co/ohshimalab/bert-base-minpaku-v3-no-additional-token)) |
| [JPharmaBERT](https://huggingface.co/EQUES/jpharma-bert-base) | è–¬å­¦ | BERT (base, large) | æ—¥æœ¬èªè–¬å­¦æ–‡æ›¸ (2Bãƒˆãƒ¼ã‚¯ãƒ³)<br>+ PubMedè‹±èªè¦æ—¨ (8Bãƒˆãƒ¼ã‚¯ãƒ³)<br>+ è–¬å­¦é–¢é€£å¤šè¨€èªãƒ‡ãƒ¼ã‚¿ (1.2Bãƒˆãƒ¼ã‚¯ãƒ³) | EQUES | ä¸æ˜ | â—¯ ([base](https://huggingface.co/EQUES/jpharma-bert-base), [large](https://huggingface.co/EQUES/jpharma-bert-large)) |
| [UTH-BERT](https://ai-health.m.u-tokyo.ac.jp/home/research/uth-bert) | åŒ»ç™‚ | BERT (base) | æ—¥æœ¬èªè¨ºç™‚è¨˜éŒ²(ç´„1å„„2,000ä¸‡è¡Œ) | æ±å¤§ç—…é™¢ <br>åŒ»ç™‚AIé–‹ç™ºå­¦è¬›åº§ | CC BY-NC-SA 4.0 | â–³ |
| [medBERTjp](https://github.com/ou-medinfo/medbertjp) | åŒ»ç™‚ | BERT (base) | æ—¥æœ¬èª Wikipedia <br> + æ—¥æœ¬èªåŒ»ç™‚ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆã€ä»Šæ—¥ã®è¨ºç™‚ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã€Webç‰ˆï¼‰ | é˜ªå¤§ç—…é™¢ <br> åŒ»ç™‚æƒ…å ±å­¦ç ”ç©¶å®¤ | CC BY-NC-SA 4.0 | â–³ |
| [JMedRoBERTa](https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/P3-1.pdf) | åŒ»ç™‚ | RoBERTa (base) | æ—¥æœ¬èªåŒ»å­¦è«–æ–‡ (ç´„1,100ä¸‡æ–‡ (1.8GB)) | NII ç›¸æ¾¤ç ” | CC BY-NC-SA 4.0 | â—¯ ([ä¸‡ç—…WordPiece](https://huggingface.co/alabnii/jmedroberta-base-manbyo-wordpiece), [SentencePiece](https://huggingface.co/alabnii/jmedroberta-base-sentencepiece)) [^10] |

<a id="embeddings"></a>
## åŸ‹ã‚è¾¼ã¿ (Embeddings) ä½œæˆã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ« [^21]

### Bi-Encoders

#### Single-representation bi-encoders

|    | å…¥åŠ›ã§æ‰±ãˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•° | é–‹ç™ºå…ƒ  |  ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|
| [Ruri-v3](https://huggingface.co/collections/cl-nagoya/ruri-v3-67f382536e80902074ec6252)<br>([v3-30m](https://huggingface.co/cl-nagoya/ruri-v3-30m), [v3-70m](https://huggingface.co/cl-nagoya/ruri-v3-70m), [v3-130m](https://huggingface.co/cl-nagoya/ruri-v3-130m), [v3-310m](https://huggingface.co/cl-nagoya/ruri-v3-310m)) | 8,192 | åå¤§ ç¬¹é‡ç ” | Apache 2.0 |
| [PLaMo-Embedding-1B](https://tech.preferred.jp/ja/blog/plamo-embedding-1b/)<br>([1b](https://huggingface.co/pfnet/plamo-embedding-1b)) | 4,096 | Preferred Networks | Apache 2.0 |
| [Sarashina-Embedding-v2](https://www.sbintuitions.co.jp/blog/entry/2025/08/20/160139)<br>([v2-1b](https://huggingface.co/sbintuitions/sarashina-embedding-v2-1b)) | 8,192 | SB Intuitions | Sarashina Model NonCommercial License |
| [sbintuitions/sarashina-embedding-v1-1b](https://huggingface.co/sbintuitions/sarashina-embedding-v1-1b) | 8,192 | SB Intuitions | Sarashina Model NonCommercial License |
| [AMBER](https://retrieva.jp/news/ENCTPk6I)<br>([base](https://huggingface.co/retrieva-jp/amber-base), [large](https://huggingface.co/retrieva-jp/amber-large)) | 512 | ãƒ¬ãƒˆãƒªãƒ | Apache 2.0 |
| [RoSEtta](https://prtimes.jp/main/html/rd/p/000000169.000022705.html)<br>([base-ja](https://huggingface.co/pkshatech/RoSEtta-base-ja)) | 1,024 | PKSHA Technology | Apache 2.0 |
| [GLuCoSE v2](https://prtimes.jp/main/html/rd/p/000000169.000022705.html)<br>([base-ja-v2](https://huggingface.co/pkshatech/GLuCoSE-base-ja-v2)) | 512 | PKSHA Technology | Apache 2.0 |
| [Ruri](https://arxiv.org/abs/2409.07737)<br>([small](https://huggingface.co/cl-nagoya/ruri-small), [base](https://huggingface.co/cl-nagoya/ruri-base), [large](https://huggingface.co/cl-nagoya/ruri-large), [small-v2](https://huggingface.co/cl-nagoya/ruri-small-v2), [base-v2](https://huggingface.co/cl-nagoya/ruri-base-v2), [large-v2](https://huggingface.co/cl-nagoya/ruri-large-v2)) | 512 | åå¤§ ç¬¹é‡ç ” | Apache 2.0 |
| [Japanese SimCSE](https://github.com/hppRC/simple-simcse-ja)<br>([unsup-simcse-ja-base](https://huggingface.co/cl-nagoya/unsup-simcse-ja-base), [unsup-simcse-ja-large](https://huggingface.co/cl-nagoya/unsup-simcse-ja-large), [sup-simcse-ja-base](https://huggingface.co/cl-nagoya/sup-simcse-ja-base), [sup-simcse-ja-large](https://huggingface.co/cl-nagoya/sup-simcse-ja-large)) | 512 | åå¤§ ç¬¹é‡ç ” | CC BY-SA 4.0 |
| [GLuCoSE](https://prtimes.jp/main/html/rd/p/000000123.000022705.html)<br>([base-ja](https://huggingface.co/pkshatech/GLuCoSE-base-ja)) | 512 | PKSHA Technology | Apache 2.0 |
| [colorfulscoop/sbert-base-ja](https://huggingface.co/colorfulscoop/sbert-base-ja) || Colorful Scoop | CC BY-SA 4.0 |
| [MU-Kindai/SBERT-JSNLI-base](https://huggingface.co/MU-Kindai/SBERT-JSNLI-base)<br>[MU-Kindai/SBERT-JSNLI-large](https://huggingface.co/MU-Kindai/SBERT-JSNLI-large) || è¿‘ç•¿å¤§å­¦ (ç ”ç©¶å®¤ä¸æ˜) | ï¼Ÿ |
| [MU-Kindai/Japanese-SimCSE-BERT-base-unsup](https://huggingface.co/MU-Kindai/Japanese-SimCSE-BERT-base-unsup)<br>[MU-Kindai/Japanese-SimCSE-BERT-large-unsup](https://huggingface.co/MU-Kindai/Japanese-SimCSE-BERT-large-unsup)<br>[MU-Kindai/Japanese-SimCSE-RoBERTa-base-unsup](https://huggingface.co/MU-Kindai/Japanese-SimCSE-RoBERTa-base-unsup)<br>[MU-Kindai/Japanese-SimCSE-BERT-base-sup](https://huggingface.co/MU-Kindai/Japanese-SimCSE-BERT-base-sup)<br>[MU-Kindai/Japanese-SimCSE-BERT-large-sup](https://huggingface.co/MU-Kindai/Japanese-SimCSE-BERT-large-sup) || è¿‘ç•¿å¤§å­¦ (ç ”ç©¶å®¤ä¸æ˜) | MIT |
| [pkshatech/simcse-ja-bert-base-clcmlp](https://huggingface.co/pkshatech/simcse-ja-bert-base-clcmlp) || PKSHA Technology | CC BY-SA 4.0 |
| [MU-Kindai/Japanese-MixCSE-BERT-base](https://huggingface.co/MU-Kindai/Japanese-MixCSE-BERT-base)<br>[MU-Kindai/Japanese-MixCSE-BERT-large](https://huggingface.co/MU-Kindai/Japanese-MixCSE-BERT-large) || è¿‘ç•¿å¤§å­¦ (ç ”ç©¶å®¤ä¸æ˜) | MIT |
| [MU-Kindai/Japanese-DiffCSE-BERT-base](https://huggingface.co/MU-Kindai/Japanese-DiffCSE-BERT-base) || è¿‘ç•¿å¤§å­¦ (ç ”ç©¶å®¤ä¸æ˜) | MIT |
| [bclavie/fio-base-japanese-v0.1](https://huggingface.co/bclavie/fio-base-japanese-v0.1) || å€‹äºº ([Benjamin ClaviÃ©](https://scholar.google.com/citations?user=vuMln98AAAAJ)) | |
| [cl-nagoya/shioriha-large-pt](https://huggingface.co/cl-nagoya/shioriha-large-pt) || åå¤§ ç¬¹é‡ç ” | |

#### Multi-representation bi-encoders

|    |  é–‹ç™ºå…ƒ  |  ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|
| [JaColBERTv2.5](https://www.answer.ai/posts/2024-08-02-jacolbert-v25.html)<br>([JaColBERTv2.4](https://huggingface.co/answerdotai/JaColBERTv2.4), [JaColBERTv2.5](https://huggingface.co/answerdotai/JaColBERTv2.5)) | Answer.AI | MIT |
| [JaColBERTv2](https://huggingface.co/bclavie/JaColBERTv2)<br>([JaColBERTv2](https://huggingface.co/bclavie/JaColBERTv2)) | å€‹äºº ([Benjamin ClaviÃ©](https://scholar.google.com/citations?user=vuMln98AAAAJ)) | MIT |
| [JaColBERT](https://arxiv.org/pdf/2312.16144.pdf)<br>([JaColBERT](https://huggingface.co/bclavie/JaColBERT)) | å€‹äºº ([Benjamin ClaviÃ©](https://scholar.google.com/citations?user=vuMln98AAAAJ)) | MIT |

### Cross-Encoders

|    |  é–‹ç™ºå…ƒ  |  ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|
| [Ruri-v3 Reranker](https://huggingface.co/cl-nagoya/ruri-v3-reranker-310m)<br>([310m](https://huggingface.co/cl-nagoya/ruri-v3-reranker-310m)) | åå¤§ ç¬¹é‡ç ” | Apache 2.0 |
| [Ruri-Reranker](https://arxiv.org/abs/2409.07737)<br>([stage1-small](https://huggingface.co/cl-nagoya/ruri-reranker-stage1-small), [stage1-base](https://huggingface.co/cl-nagoya/ruri-reranker-stage1-base), [stage1-large](https://huggingface.co/cl-nagoya/ruri-reranker-stage1-large), [small](https://huggingface.co/cl-nagoya/ruri-reranker-small), [base](https://huggingface.co/cl-nagoya/ruri-reranker-base), [large](https://huggingface.co/cl-nagoya/ruri-reranker-large)) | åå¤§ ç¬¹é‡ç ” | Apache 2.0 |
| [hotchpotch/japanese-reranker-cross-encoder-xsmall-v1](https://huggingface.co/hotchpotch/japanese-reranker-cross-encoder-xsmall-v1)<br>[hotchpotch/japanese-reranker-cross-encoder-small-v1](https://huggingface.co/hotchpotch/japanese-reranker-cross-encoder-small-v1)<br>[hotchpotch/japanese-reranker-cross-encoder-base-v1](https://huggingface.co/hotchpotch/japanese-reranker-cross-encoder-base-v1)<br>[hotchpotch/japanese-reranker-cross-encoder-large-v1](https://huggingface.co/hotchpotch/japanese-reranker-cross-encoder-large-v1)<br>[hotchpotch/japanese-bge-reranker-v2-m3-v1](https://huggingface.co/hotchpotch/japanese-bge-reranker-v2-m3-v1) | å€‹äºº (èˆ˜é‡ç¥ä¸€) | MIT |

<a id="multimodal"></a>
## è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ« (Vision-Language Models)

<a id="multimodal-text-generation"></a>
### ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ

#### ã‚¹ã‚¯ãƒ©ãƒƒãƒå­¦ç¿’ãƒ¢ãƒ‡ãƒ«

**æ±ç”¨**

|    | å…¬é–‹å¹´ |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ |  å­¦ç¿’ç”»åƒ/ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ / åˆ©ç”¨è¦ç´„ |
|:---|:---:|:---:|:---:|:---:|:---:|
| [Stockmark-2-VL-100B-beta](https://stockmark-tech.hatenablog.com/entry/2025/06/03/101007)<br>([**100B**-beta](https://huggingface.co/stockmark/Stockmark-2-VL-100B-beta)) | **2025** | LLaVA-OneVision | 3æ®µéšå­¦ç¿’: ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆäº‹å‰å­¦ç¿’ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ‹¡å¼µã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ»æ¨è«–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°<br>åˆæˆãƒ‡ãƒ¼ã‚¿: Qwen2.5-VL-72B ã‹ã‚‰ç”Ÿæˆ | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ | Qwen License |
| [Llama-3.1-70B-Instruct-multimodal-JP-Graph](https://jp.ricoh.com/release/2025/0610_1)<br>([v0.1](https://huggingface.co/r-g2-2024/Llama-3.1-70B-Instruct-multimodal-JP-Graph-v0.1)) | **2025** | LLaVA (Llama-3.1-Swallow-70B-Instruct-v0.3 + Qwen2-VL-7B-Instruct) | å›³è¡¨ãƒ»ã‚°ãƒ©ãƒ•ç†è§£ç‰¹åŒ–ã®600ä¸‡æšè¶…ã®åˆæˆè¦–è¦šãƒ‡ãƒ¼ã‚¿ (æ–‡å­—ã€å††ã‚°ãƒ©ãƒ•ã€æ£’ã‚°ãƒ©ãƒ•ã€ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆãªã©)ã€å®Ÿãƒ‡ãƒ¼ã‚¿ (FastLabel å”åŠ›) | ãƒªã‚³ãƒ¼ | Llama 3.1 Community License & Gemma Terms of Use & Qwen License & MIT & Apache 2.0 |
| [KARAKURI VL](https://karakuri.ai/news/GENIAC)<br>([**32b**-instruct-2507](https://huggingface.co/karakuri-ai/karakuri-vl-32b-instruct-2507), [**32b**-thinking-2507-exp](https://huggingface.co/karakuri-ai/karakuri-vl-32b-thinking-2507-exp)) | **2025** | Vision-Language (Qwen2.5-VL-32B ãƒ™ãƒ¼ã‚¹) | æ—¥æœ¬èªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¦ãƒ¼ã‚¹ç‰¹åŒ–ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: æ—¥æœ¬èªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿æ“ä½œè¨˜éŒ²ã€æ—¥æœ¬èªæ–‡æ›¸ç”»åƒQAã€è¦–è¦šæƒ…å ±è§£é‡ˆã€æ—¥æœ¬èªOCRã€ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç†è§£<br>3æ®µéšå­¦ç¿’: Supervised Fine-Tuning (SFT) + ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ + å¼·åŒ–å­¦ç¿’<br>*thinking ãƒ¢ãƒ‡ãƒ«ã¯ Chain of Thought (CoT) ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹æ˜ç¤º | ã‚«ãƒ©ã‚¯ãƒª | Apache 2.0 |
| [Heron-NVILA](https://tur.ing/posts/pQLCubIm)<br>([1B](https://huggingface.co/turing-motors/Heron-NVILA-Lite-1B), [2B](https://huggingface.co/turing-motors/Heron-NVILA-Lite-2B), [15B](https://huggingface.co/turing-motors/Heron-NVILA-Lite-15B), [33B](https://huggingface.co/turing-motors/Heron-NVILA-Lite-33B)) | **2025** | NVILA | 3æ®µéšå­¦ç¿’: ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ (558kæ—¥æœ¬èªç”»åƒãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ + 595k LLaVA-Pretrain)ã€äº‹å‰å­¦ç¿’ (MOMIJI 13Mã€æ—¥æœ¬èªç”»åƒãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ 6Mã€æ—¥æœ¬èªã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ 2Mã€coyo-700m 6Mã€mmc4-core 4Mã€Wikipedia-jaã€LLaVA-Pretrain-JAã€STAIR captions)ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (LLaVA-instruct-v1.5-enã€LLaVA-instruct-jaã€æ—¥æœ¬èªå†™çœŸä¼šè©±ã€JA-VG-VQAä¼šè©±ã€SynthDog-jaã€AI2Dã€SynthDog-enã€Sherlock) | Turing | Apache 2.0 & OpenAI Terms of Use |
| [NABLA-VL](https://note.com/nablas/n/n86298d28cdea)<br>([15B](https://huggingface.co/nablasinc/NABLA-VL)) | **2025** | microsoft/phi-4 + HuggingFaceM4/siglip-so400m-14-980-flash-attn2-navit | å˜ä¸€ç”»åƒãƒ»è¤‡æ•°ç”»åƒãƒ»å‹•ç”»å…¥åŠ›å¯¾å¿œã€‚è¨“ç·´è©³ç´°ä¸æ˜ | NABLAS | Apache 2.0 |
| [Sarashina2-Vision](https://www.sbintuitions.co.jp/blog/entry/2025/03/17/111659)<br>([8b](https://huggingface.co/sbintuitions/sarashina2-vision-8b), [14b](https://huggingface.co/sbintuitions/sarashina2-vision-14b)) | **2025** | Sarashina2 + Qwen2-VL + 2-layer MLP | 3æ®µéšå­¦ç¿’: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— (LLaVA-Pretrain 78Mè‹±èªãƒˆãƒ¼ã‚¯ãƒ³)ã€è¦–è¦šã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼äº‹å‰å­¦ç¿’ (CC3Mã€CC12Mã€llm-jp-japanese-image-text-pairsã€å†…éƒ¨OCRãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€å†…éƒ¨ãƒãƒ£ãƒ¼ãƒˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ 3.8Bæ—¥æœ¬èª+7.7Bè‹±èªãƒˆãƒ¼ã‚¯ãƒ³)ã€è¦–è¦šçš„ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Japanese Visual Genome VQAã€OCR-VQAã€TextVQAã€PlotQAã€CLEVRç¿»è¨³ç‰ˆã€DOCCIç¿»è¨³ç‰ˆã€å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ 2.5Bæ—¥æœ¬èª+1.0Bè‹±èªãƒˆãƒ¼ã‚¯ãƒ³) | SB Intuitions | MIT |
| [Asagi](https://uehara-mech.github.io/asagi-vlm?v=1)<br>([2B](https://huggingface.co/MIL-UT/Asagi-2B), [4B](https://huggingface.co/MIL-UT/Asagi-4B), [8B](https://huggingface.co/MIL-UT/Asagi-8B), [14B](https://huggingface.co/MIL-UT/Asagi-14B)) | **2025** | LLaVA | æ–°è¦ã‚¯ãƒ­ãƒ¼ãƒ«æ—¥æœ¬èªã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆç”»åƒã€æ—¢å­˜æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€è‹±èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ—¥æœ¬èªç¿»è¨³ ç´„2000ä¸‡ä»¶ (English VLM Phi-3.5-vision-instruct ã¨ Japanese LLM CALM3-22B-Chat ã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿åˆæˆ) | æ±å¤§ åŸç”°ç ” | Apache 2.0 |
| [llava-calm2-siglip](https://www.cyberagent.co.jp/news/detail/id=30344)<br>([llava-calm2-siglip](https://huggingface.co/cyberagent/llava-calm2-siglip)) | 2024 | LLaVA | MS-COCO ã¨ VisualGenome ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸå¯¾è©±ãƒ‡ãƒ¼ã‚¿ | ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | Apache 2.0 |
| [LLM-jp-3 VILA 14B](https://llmc.nii.ac.jp/topics/llm-jp-3-vila-14b/)<br>([14b](https://huggingface.co/llm-jp/llm-jp-3-vila-14b)) | 2024 | LLaVA | [Japanese image text pairs](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-japanese-image-text-pairs), LLaVA-Pretrain, [Japanese interleaved data](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-japanese-interleaved-data), coyo (subset), mmc4-core (subset), [llava-instruct-ja](https://huggingface.co/datasets/llm-jp/llava-instruct-ja), [japanese-photos-conv](https://huggingface.co/datasets/llm-jp/japanese-photos-conversation), ja-vg-vqa, synthdog-ja, LLaVA-1.5 instruction data (subset) | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 & OpenAI Terms of Use |
| [Heron](https://github.com/turingmotors/heron/blob/main/docs/README_JP.md)<br>([blip-ja-stablelm-base-7b-v0](https://huggingface.co/turing-motors/heron-chat-blip-ja-stablelm-base-7b-v0), [blip-ja-stablelm-base-7b-v1](https://huggingface.co/turing-motors/heron-chat-blip-ja-stablelm-base-7b-v1), [blip-ja-stablelm-base-7b-v1-llava-620k](https://huggingface.co/turing-motors/heron-chat-blip-ja-stablelm-base-7b-v1-llava-620k), [git-ja-stablelm-base-7b-v0](https://huggingface.co/turing-motors/heron-chat-git-ja-stablelm-base-7b-v0), [git-ELYZA-fast-7b-v0](https://huggingface.co/turing-motors/heron-chat-git-ELYZA-fast-7b-v0), [git-ja-stablelm-base-7b-v1](https://huggingface.co/turing-motors/heron-chat-git-ja-stablelm-base-7b-v1)) | 2023 | BLIP-2 ã¾ãŸã¯ GIT | v1: LLaVA-Instruct-150K-JA ã¾ãŸã¯ LLaVA-Instruct-620K-JA<br>v0: LLaVA-Instruct-150K-JA, Japanese STAIR Captions, Japanese Visual Genome VQA dataset | Turing | CC BY-NC 4.0 |
| [Japanese Stable VLM](https://huggingface.co/stabilityai/japanese-stable-vlm)<br>([japanese-stable-vlm](https://huggingface.co/stabilityai/japanese-stable-vlm)) | 2023 | LLaVA | Japanese CC12M, STAIR Captions, Japanese Visual Genome VQA dataset | Stability AI | STABILITY AI JAPANESE STABLE VLM COMMUNITY LICENSE |
| [Japanese InstructBLIP Alpha](https://huggingface.co/stabilityai/japanese-instructblip-alpha)<br>([japanese-instructblip-alpha](https://huggingface.co/stabilityai/japanese-instructblip-alpha)) | 2023 | InstructBLIP | Japanese CC12M, STAIR Captions, Japanese Visual Genome VQA dataset | Stability AI | JAPANESE STABLELM RESEARCH LICENSE |
| [rinna MiniGPT-4](https://huggingface.co/rinna/bilingual-gpt-neox-4b-minigpt4)<br>([bilingual-gpt-neox-4b-minigpt4](https://huggingface.co/rinna/bilingual-gpt-neox-4b-minigpt4)) | 2023 | MiniGPT-4 | CC12M, COCO 2014, Visual Genome, STAIR Captions, Japanese Visual Genome VQA dataset | rinna | MIT |
| [Sarashina2.2-Vision-3B](https://www.sbintuitions.co.jp/blog/entry/2025/11/25/100000)<br>([**3.8b**](https://huggingface.co/sbintuitions/sarashina2.2-vision-3b)) | **2025** | Sarashina2.2-3B-Instruct + SigLIP + 2-layer MLP | 4æ®µéšå­¦ç¿’ + Post-training: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— (è‹±èªç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³)ã€è¦–è¦šã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼äº‹å‰å­¦ç¿’ (æ—¥æœ¬èªãƒãƒ£ãƒ¼ãƒˆã€OCRã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³)ã€å…¨ãƒ¢ãƒ‡ãƒ«äº‹å‰å­¦ç¿’ (ç”»åƒãƒ†ã‚­ã‚¹ãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿)ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°<br>Post-training: Mixed Preference Optimization<br>(è¨ˆ æ—¥æœ¬èª103B + è‹±èª157.1B ãƒˆãƒ¼ã‚¯ãƒ³) | SB Intuitions | MIT |

**ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹**

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  ãƒ‰ãƒ¡ã‚¤ãƒ³ | é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [watashiha/Watashiha-Llama-2-13B-Ogiri-sft-vlm](https://huggingface.co/watashiha/Watashiha-Llama-2-13B-Ogiri-sft-vlm) | LLaVA | å¤§å–œåˆ© | ã‚ãŸã—ã¯ | Llama 2 Community License |

#### æµ·å¤–ãƒ¢ãƒ‡ãƒ«ã«æ—¥æœ¬èªã§è¿½åŠ å­¦ç¿’ã‚’è¡Œã£ãŸãƒ¢ãƒ‡ãƒ«

|    |  ãƒ™ãƒ¼ã‚¹ã®VLM  |  å­¦ç¿’ç”»åƒ/ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [AXCXEPT/EZO-InternVL2-26B](https://huggingface.co/AXCXEPT/EZO-InternVL2-26B) | InternVL2 | - | ã€€Axcxept | MIT |

#### è¤‡æ•°ã®VLMãƒ»LLMã‚’ãƒãƒ¼ã‚¸ã—ã¦ä½œæˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«

|    |  ãƒãƒ¼ã‚¸å…ƒã®LLMãƒ»VLMï¼ˆå¤ªå­—ã¯æ—¥æœ¬èªLLMï¼‰  | é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|
| [Llama-3-EvoVLM-JP-v2](https://sakana.ai/evovlm-jp/)<br>([v2](https://huggingface.co/SakanaAI/Llama-3-EvoVLM-JP-v2)) | Mantis-8B-SigLIP-Llama-3, **Llama-3-ELYZA-JP-8B**, Bunny-v1.1-Llama-3-8B-V | Sakana AI | Llama 3 Community License |
| [AXCXEPT/Llama-3-EZO-VLM-1](https://huggingface.co/AXCXEPT/Llama-3-EZO-VLM-1) | - (Llama-3-EvoVLM-JP-v2 ã«å¯¾ã—ã¦è¿½åŠ å­¦ç¿’) | Axcxept | Llama 3 Community License |
| [EvoVLM-JP](https://sakana.ai/evolutionary-model-merge-jp/)<br>([v1-7B](https://huggingface.co/SakanaAI/EvoVLM-JP-v1-7B)) | **Shisa Gamma 7B (v1)**, LLaVA-1.6-Mistral-7B | Sakana AI | Apache 2.0 |

<a id="multimodal-text-to-image"></a>
### ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ç”»åƒç”Ÿæˆ

<a id="multimodal-text-to-image-general"></a>
#### æ±ç”¨

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å­¦ç¿’ç”»åƒ/ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [CommonArt Î²](https://note.com/aipicasso/n/nf17f876839b2)<br>([commonart-beta](https://huggingface.co/aipicasso/commonart-beta)) | PixArt-Î£ | CommonCatalog-cc-by, Megalith-10M, Smithonian Open Access, ArtBench (CC-0 only) | AI Picasso | Apache 2.0 |
| [EvoSDXL-JP](https://sakana.ai/evosdxl-jp/)<br>([v1](https://huggingface.co/SakanaAI/EvoSDXL-JP-v1)) | Stable Diffusion | - ï¼ˆJapanese Stable Diffusion XL ã‚’å«ã‚€è¤‡æ•°ã®ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ¼ã‚¸ï¼‰ | Sakana AI | Apache 2.0[^14] |
| [Japanese Stable Diffusion XL](https://huggingface.co/stabilityai/japanese-stable-diffusion-xl)<br>([japanese-stable-diffusion-xl](https://huggingface.co/stabilityai/japanese-stable-diffusion-xl)) | Stable Diffusion | ä¸æ˜ | Stability AI | STABILITY AI JAPANESE STABLE DIFFUSION XL COMMUNITY LICENSE |
| [æ±åŒ—å¤§Stable Diffusion](https://huggingface.co/tohoku-nlp/stable-diffusion-xl-jp-base-1.0)<br>([base](https://huggingface.co/tohoku-nlp/stable-diffusion-xl-jp-base-1.0), [refiner](https://huggingface.co/tohoku-nlp/stable-diffusion-xl-jp-refiner-1.0)) | Stable Diffusion | WMT2023 Shared Task ã®æ—¥è‹±å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã€laion2B-multi ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç´„ 1,300 ä¸‡ä»¶ | æ±åŒ—å¤§<br>è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ— | CreativeML OpenRAIL-M License |
| [rinna Stable Diffusion](https://huggingface.co/rinna/japanese-stable-diffusion)<br>([japanese-stable-diffusion](https://huggingface.co/rinna/japanese-stable-diffusion)) | Stable Diffusion |  LAION-5B ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã†ã¡ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãŒæ—¥æœ¬èªã®ã‚‚ã®ï¼ˆç”»åƒç´„ 1 å„„æšï¼‰| rinna | CreativeML OpenRAIL-M License |

<a id="multimodal-text-to-image-domain-specific"></a>
#### ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  ãƒ‰ãƒ¡ã‚¤ãƒ³  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [Evo-Nishikie](https://sakana.ai/evo-ukiyoe/)<br>([v1](https://huggingface.co/SakanaAI/Evo-Nishikie-v1)) | Stable Diffusion (ControlNet) | æµ®ä¸–çµµ | Sakana AI | Apache 2.0[^14] |
| [Evo-Ukiyoe](https://sakana.ai/evo-ukiyoe/)<br>([v1](https://huggingface.co/SakanaAI/Evo-Ukiyoe-v1)) | Stable Diffusion | æµ®ä¸–çµµ | Sakana AI | Apache 2.0[^14] |

### ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®å‹•ç”»ç”Ÿæˆ

| | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ | å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ | é–‹ç™ºå…ƒ | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [AIdeaLab VideoJP](https://aidealab.com/news/QSvdcQfA)<br>([AIdeaLab-VideoJP](https://huggingface.co/aidealab/AIdeaLab-VideoJP)) | CogVideoX | Pixabay, FineVideo | AIdeaLab | Apache 2.0 |

<a id="multimodal-others"></a>
### ãã®ä»–

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å­¦ç¿’ç”»åƒ/ãƒ†ã‚­ã‚¹ãƒˆ  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [llm-jp-clip](https://huggingface.co/llm-jp/llm-jp-clip-vit-base-patch16)<br>([llm-jp-clip-vit-base-patch16](https://huggingface.co/llm-jp/llm-jp-clip-vit-base-patch16), [llm-jp-clip-vit-large-patch14](https://huggingface.co/llm-jp/llm-jp-clip-vit-large-patch14)) | CLIP | ReLAION-5Bã®è‹±èªã‚µãƒ–ã‚»ãƒƒãƒˆã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç´„15å„„ä»¶ã®ç¿»è¨³ | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ | Apache 2.0 |
| [LINEãƒ¤ãƒ•ãƒ¼CLIP](https://techblog.lycorp.co.jp/ja/20240514b)<br>([clip-japanese-base](https://huggingface.co/line-corporation/clip-japanese-base), [v2](https://huggingface.co/line-corporation/clip-japanese-base-v2)) | CLIP | CommonCrawl, CC12M, YFCC100M<br>(v2: Common Crawl ç´„20å„„ç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ + çŸ¥è­˜è’¸ç•™) | LINEãƒ¤ãƒ•ãƒ¼ | Apache 2.0 |
| [ãƒªã‚¯ãƒ«ãƒ¼ãƒˆCLIP](https://blog.recruit.co.jp/data/articles/japanese-clip/)<br>([japanese-clip-vit-b-32-roberta-base](https://huggingface.co/recruit-jp/japanese-clip-vit-b-32-roberta-base)) | CLIP | laion2B-multi ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç´„1å„„2000ä¸‡ä»¶ | ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ | CC BY-4.0 |
| [Japanese Stable CLIP](https://huggingface.co/stabilityai/japanese-stable-clip-vit-l-16)<br>([japanese-stable-clip-vit-l-16](https://huggingface.co/stabilityai/japanese-stable-clip-vit-l-16)) | SigLIP | CC12M ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ãŸã‚‚ã®ã€STAIR Captions | Stability AI | STABILITY AI JAPANESE STABLE CLIP COMMUNITY LICENSE |
| [rinna CLIP](https://huggingface.co/rinna/japanese-clip-vit-b-16)<br>([japanese-clip-vit-b-16](https://huggingface.co/rinna/japanese-clip-vit-b-16)) | CLIP | CC12M ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ãŸã‚‚ã® | rinna | Apache 2.0 |
| [rinna CLOOB](https://huggingface.co/rinna/japanese-cloob-vit-b-16)<br>([japanese-cloob-vit-b-16](https://huggingface.co/rinna/japanese-cloob-vit-b-16)) | CLOOB | CC12M ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ãŸã‚‚ã® | rinna | Apache 2.0 |
| [åšå ±å ‚ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚ºCLIP](https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/B6-5.pdf)<br>([base](https://huggingface.co/hakuhodo-tech/japanese-clip-vit-h-14-bert-base), [deeper](https://huggingface.co/hakuhodo-tech/japanese-clip-vit-h-14-bert-deeper), [wider](https://huggingface.co/hakuhodo-tech/japanese-clip-vit-h-14-bert-wider)) | CLIP | laion2B-multi ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç´„1å„„2000ä¸‡ä»¶ | åšå ±å ‚ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚º | CC BY-NC-SA 4.0 |

<a id="speech"></a>
## éŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ« (Speech-Language Models)

<a id="speech-asr"></a>
### éŸ³å£°èªè­˜

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [Kotoba-Whisper](https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0)<br>([v1.0](https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0), [v1.0-ggml](https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0-ggml), [v1.0-faster](https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0-faster), [v1.1](https://huggingface.co/kotoba-tech/kotoba-whisper-v1.1), [bilingual-v1.0](https://huggingface.co/kotoba-tech/kotoba-whisper-bilingual-v1.0), [bilingual-v1.0-ggml](https://huggingface.co/kotoba-tech/kotoba-whisper-bilingual-v1.0-ggml), [bilingual-v1.0-faster](https://huggingface.co/kotoba-tech/kotoba-whisper-bilingual-v1.0-faster), [v2.0](https://huggingface.co/kotoba-tech/kotoba-whisper-v2.0), [v2.0-ggml](https://huggingface.co/kotoba-tech/kotoba-whisper-v2.0-ggml), [v2.0-faster](https://huggingface.co/kotoba-tech/kotoba-whisper-v2.0-faster), [v2.1](https://huggingface.co/kotoba-tech/kotoba-whisper-v2.1), [v2.2](https://huggingface.co/kotoba-tech/kotoba-whisper-v2.2)) | Distil-Whisper | ReazonSpeech<br>(+ Multilingual LibriSpeech) | Kotoba Technologies | Apache 2.0 |
| [ReazonSpeech](https://research.reazon.jp/projects/ReazonSpeech/)<br>([espnet-v1](https://huggingface.co/reazon-research/reazonspeech-espnet-v1), [espnet-next](https://huggingface.co/reazon-research/reazonspeech-espnet-next), [espnet-v2](https://huggingface.co/reazon-research/reazonspeech-espnet-v2), [nemo-v2](https://huggingface.co/reazon-research/reazonspeech-nemo-v2)) | ESPnet (Conformer-Transducer) ã¾ãŸã¯ NeMo (FastConformer-RNNT) | ReazonSpeech | ãƒ¬ã‚¢ã‚¾ãƒ³ãƒ»ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ | Apache 2.0 |

<a id="speech-others"></a>
### ãã®ä»–

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [J-Moshi](https://github.com/nu-dialogue/j-moshi)<br>([j-moshi](https://huggingface.co/nu-dialogue/j-moshi), [j-moshi-ext](https://huggingface.co/nu-dialogue/j-moshi-ext)) | Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ»éŸ³å£°åŸºç›¤ãƒ¢ãƒ‡ãƒ« (Moshi) | éŸ³å£°å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆJ-CHAT, æ—¥æœ¬èªCallhome, CSJ, æ—…è¡Œä»£ç†åº—å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹, ç‹¬è‡ªã®é›‘è«‡å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹, ç‹¬è‡ªã®ç›¸è«‡å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹ï¼‰, ãƒ†ã‚­ã‚¹ãƒˆå¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆæ—¥æœ¬èªPersonaChat, æ—¥æœ¬èªEmpatheticDialogues, æ—¥æœ¬èªæ—¥å¸¸å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹, RealPersonaChatï¼‰ | åå¤§ æ±ä¸­ç ” | CC BY-NC 4.0 |
| [Kotoba-Speech](https://huggingface.co/kotoba-tech/kotoba-speech-v0.1)<br>([v0.1](https://huggingface.co/kotoba-tech/kotoba-speech-v0.1)) | Transformer | ä¸æ˜ | Kotoba Technologies | Apache 2.0 |
| [ãã—ãªã ](https://www.aist.go.jp/aist_j/press_release/pr2025/pr20250310/pr20250310.html)<br>([base](https://huggingface.co/imprt/kushinada-hubert-base), [large](https://huggingface.co/imprt/kushinada-hubert-large)) | HuBERT | ç´„6ä¸‡æ™‚é–“ã®æ—¥æœ¬èªãƒ†ãƒ¬ãƒ“æ”¾é€éŸ³å£° | ç”£ç·ç ” çŸ¥çš„ãƒ¡ãƒ‡ã‚£ã‚¢å‡¦ç†ç ”ç©¶ãƒãƒ¼ãƒ  | Apache 2.0 |
| [æ±å¤§HuBERT](https://huggingface.co/sarulab-speech/hubert-base-jtube)<br>([base-jtube](https://huggingface.co/sarulab-speech/hubert-base-jtube)) | HuBERT | JTubeSpeech | æ±å¤§ çŒ¿æ¸¡ãƒ»é«˜é“ç ” | MIT |
| [ã„ã–ãªã¿](https://www.aist.go.jp/aist_j/press_release/pr2025/pr20250310/pr20250310.html)<br>([base](https://huggingface.co/imprt/izanami-wav2vec2-base), [large](https://huggingface.co/imprt/izanami-wav2vec2-large)) | wav2vec 2.0 | ç´„6ä¸‡æ™‚é–“ã®æ—¥æœ¬èªãƒ†ãƒ¬ãƒ“æ”¾é€éŸ³å£° | ç”£ç·ç ” çŸ¥çš„ãƒ¡ãƒ‡ã‚£ã‚¢å‡¦ç†ç ”ç©¶ãƒãƒ¼ãƒ  | Apache 2.0 |
| [Reazon wav2vec 2.0](https://research.reazon.jp/blog/2024-10-21-Wav2Vec2-base-release.html)<br>([base](https://huggingface.co/reazon-research/japanese-wav2vec2-base), [large](https://huggingface.co/reazon-research/japanese-wav2vec2-large)) | wav2vec 2.0 | ReazonSpeech | ãƒ¬ã‚¢ã‚¾ãƒ³ãƒ»ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ | Apache 2.0 |

<a id="music"></a>
## éŸ³æ¥½è¨€èªãƒ¢ãƒ‡ãƒ« (Music-Language Models)

<a id="music-text-conversion"></a>
### éŸ³æ¥½-ãƒ†ã‚­ã‚¹ãƒˆé–“å¤‰æ›

|    |  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£  |  å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹  |  é–‹ç™ºå…ƒ  | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ |
|:---|:---:|:---:|:---:|:---:|
| [Japanese MULAN](https://huggingface.co/line-corporation/japanese-mulan-base)<br>([japanese-mulan-base](https://huggingface.co/line-corporation/japanese-mulan-base)) | MULAN (AST + GLuCoSE) | ã€œ20k ç¤¾å†…éŸ³æ¥½-ãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ | LINEãƒ¤ãƒ•ãƒ¼ | Apache 2.0 |

<a id="benchmark-suites"></a>
## æ—¥æœ¬èªLLMè©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¾ã¨ã‚

<a id="hybrid-benchmark-suites"></a>
### è¤‡åˆå‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰4](https://wandb.ai/llm-leaderboard/nejumi-leaderboard4/reports/Nejumi-LLM-4--VmlldzoxMzc1OTk1MA) | LLM ã®æ—¥æœ¬èªèƒ½åŠ›ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºï¼ˆã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»é–¢æ•°å‘¼ã³å‡ºã—ï¼‰ã€æ¨è«–èƒ½åŠ›ï¼ˆæ•°å­¦çš„ãƒ»è«–ç†çš„ãƒ»æŠ½è±¡çš„æ¨è«–ï¼‰ã€å°‚é–€çŸ¥è­˜ã€å®‰å…¨æ€§è©•ä¾¡ï¼ˆæŒ‡ç¤ºè¿½å¾“ãƒ»å¹»è¦šæŠ‘åˆ¶ï¼‰ç­‰ã®è¦³ç‚¹ã§ç·åˆçš„ã«è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚é«˜é›£åº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å°å…¥ã«ã‚ˆã‚Šä¸Šä½ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½å·®ã‚’æ˜ç¢ºåŒ–ã€‚è©³ã—ãã¯[ã“ã¡ã‚‰ã®è¨˜äº‹](https://note.com/wandb_jp/n/ncfd9d23221b3)ã‚’å‚ç…§ | Weights & Biases |
| [Swallow LLM Leaderboard v2](https://swallow-llm.github.io/leaderboard/index-post.ja.html) | æ§˜ã€…ãª LLM ã‚’æ—¥æœ¬èªç†è§£ãƒ»ç”Ÿæˆã‚¿ã‚¹ã‚¯ã€æ—¥æœ¬èªãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±ã‚¿ã‚¹ã‚¯ã€è‹±èªç†è§£ãƒ»ç”Ÿæˆã‚¿ã‚¹ã‚¯ã® 3 ç¨®é¡ã‹ã‚‰ç·åˆçš„ã«è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚v2ã§ã¯æ¨è«–ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¨è«–ã‚„æ€è€ƒé€£é–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¡ç”¨ã—ã€ã‚ˆã‚Šé«˜é›£åº¦ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆè¨ˆ12ã‚¿ã‚¹ã‚¯ï¼šæ—¥æœ¬èª6ã€è‹±èª6ï¼‰ã§è©•ä¾¡ã‚’å®Ÿæ–½ã€‚ã¾ãŸã€æ—¢å­˜ã® LLM è©•ä¾¡ãƒ„ãƒ¼ãƒ«ã‚’çµ±åˆãƒ»æ”¹ä¿®ã—ãŸè©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚ã‚‹ [swallow-evaluation](https://github.com/swallow-llm/swallow-evaluation) ã«åŠ ãˆã¦ã€æ–°ãŸã«æ¨è«–å‹ãƒ¢ãƒ‡ãƒ«å¯¾å¿œã® [swallow-evaluation-instruct](https://github.com/swallow-llm/swallow-evaluation-instruct) ã‚’å…¬é–‹ã—ã¦ã„ã‚‹ã€‚ | Swallowãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ |

<a id="basic-benchmark-suites"></a>
### åŸºæœ¬çš„ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [ã‚ªãƒ¼ãƒ—ãƒ³æ—¥æœ¬èªLLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰](https://huggingface.co/spaces/llm-jp/open-japanese-llm-leaderboard) | [llm-jp-eval](#llm-jp-eval) ã‚’æ´»ç”¨ã—ã€16ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã§æ—¥æœ¬èªã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚| LLM-jp, Hugging Face |
| <a id="llm-jp-eval"></a> [llm-jp-eval](https://github.com/llm-jp/llm-jp-eval) | è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¨ªæ–­ã—ã¦æ—¥æœ¬èª LLM ã‚’è‡ªå‹•è©•ä¾¡ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹ã€‚<br>å¯¾å¿œã—ã¦ã„ã‚‹å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã¯[ã“ã¡ã‚‰](https://github.com/llm-jp/llm-jp-eval/tree/main/src/llm_jp_eval/jaster)ã‹ã‚‰ç¢ºèªã§ãã‚‹ï¼ˆã“ã®ä¸­ã«ã¯ JNLI ã‚„ JCommonsenseQA ã¨ã„ã£ãŸ JGLUE ã®ã‚¿ã‚¹ã‚¯ãªã©ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ | LLM-jp |
| [JP Language Model Evaluation Harness](https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable) | Stability AI ã«ã‚ˆã‚‹ [EleutherAI/lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) ã®ãƒ•ã‚©ãƒ¼ã‚¯ã€‚è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¨ªæ–­ã—ã¦æ—¥æœ¬èª LLM ã‚’è‡ªå‹•è©•ä¾¡ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹ã€‚<br>å¯¾å¿œã—ã¦ã„ã‚‹å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã¯[ã“ã¡ã‚‰](https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/lm_eval/tasks/ja)ã‹ã‚‰ç¢ºèªã§ãã‚‹ï¼ˆã“ã®ä¸­ã«ã¯ JNLI ã‚„ JCommonsenseQA ã¨ã„ã£ãŸ JGLUE ã®ã‚¿ã‚¹ã‚¯ãªã©ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ | Stability AI |
| [JGLUE](https://github.com/yahoojapan/JGLUE) | [GLUE ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](https://gluebenchmark.com/)ã®æ—¥æœ¬èªç‰ˆã¨ã—ã¦æ§‹ç¯‰ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚MARC-ja, JCoLA, JSTS, JNLI, JSQuAD, JCommonsenseQA ã® 6 ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ï¼ˆ[JCoLA](https://github.com/osekilab/JCoLA) ã¯æ±å¤§å¤§é–¢ç ”ã«ã‚ˆã‚Šä½œæˆï¼‰ã€‚å„ã‚¿ã‚¹ã‚¯ã®è©³ç´°ã¯[ã“ã¡ã‚‰](https://www.jstage.jst.go.jp/article/jnlp/30/1/30_63/_article/-char/ja)ã‚„[ã“ã¡ã‚‰](https://techblog.yahoo.co.jp/entry/2022122030379907/)ã‚’å‚ç…§ | æ—©å¤§ æ²³åŸç ”, ãƒ¤ãƒ•ãƒ¼ |
| <a id="jmmlu"></a> [JMMLU](https://github.com/nlp-waseda/JMMLU) | [MMLU ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](https://github.com/hendrycks/test)ã®æ—¥æœ¬èªç‰ˆã¨ã—ã¦æ§‹ç¯‰ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚è‡ªç„¶ç§‘å­¦ãƒ»äººæ–‡ç§‘å­¦ãƒ»ç¤¾ä¼šç§‘å­¦ã®å¹…åºƒã„å­¦è¡“é ˜åŸŸã‹ã‚‰ 4 æŠå•é¡Œã‚’æ§‹æˆã—ã¦ã„ã‚‹ã€‚å…ƒã® MMLU ã‚’ç¿»è¨³ã—ãŸã ã‘ã§ãªãã€æ—¥æœ¬ç‹¬è‡ªã®æ–‡åŒ–çš„èƒŒæ™¯ã«åŸºã¥ãå•é¡Œï¼ˆæ—¥æœ¬å•é¡Œï¼‰ã‚’æ–°ãŸã«è¿½åŠ ã—ã¦ã„ã‚‹ã®ãŒç‰¹å¾´ã§ã‚ã‚‹ã€‚ | æ—©å¤§ æ²³åŸç ” |
<!-- | [æ—¥æœ¬èª Open LLM Leaderboard](http://wandb.me/llm-jp-openllmleaderboard) | Huggingface ã® [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) ã¨åŒæ§˜ã®æ¤œè¨¼ã‚’æ—¥æœ¬èª LLM ã«å¯¾ã—ã¦è¡Œã£ãŸã‚‚ã®ã€‚æ—¥æœ¬èª LLM ã®è‹±èªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ€§èƒ½ã‚’ç¢ºèªã§ãã‚‹ã€‚ | LLM-jp | -->

<a id="open-ended-benchmark-suites"></a>
### ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆèƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| <a id="jp-mt-bench"></a> [Japanese MT-bench](https://github.com/Stability-AI/FastChat/tree/jp-stable/fastchat/llm_judge) | ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±èƒ½åŠ›ã‚’å•ã† [MT-bench](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge) ã®æ—¥æœ¬èªç‰ˆã€‚Writing, Roleplay, Reasoning, Math, Coding, Extraction, STEM, Humanities ã® 8 ã¤ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ 10 å•ãšã¤ã€è¨ˆ 80 å•ãŒåéŒ²ã•ã‚Œã¦ã„ã‚‹ã€‚ãªãŠã€æ—¥æœ¬èªç‰ˆä½œæˆã®éš›ã«ã¯ã€æ—¥æœ¬ã®æ–‡åŒ–ã«åˆã†ã‚ˆã†ã«è³ªå•å†…å®¹ã«ä¸€éƒ¨ä¿®æ­£ãŒåŠ ãˆã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>GPT-4 ã«ã‚ˆã‚‹ 10 æ®µéšã®çµ¶å¯¾è©•ä¾¡ã‚’è¡Œã†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚ | Stability AI |
| <a id="elyza-tasks"></a> [ELYZA-tasks-100](https://huggingface.co/datasets/elyza/ELYZA-tasks-100) | è¤‡é›‘ãªæŒ‡ç¤ºãƒ»ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€100ä»¶ã®æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã§ã€å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦è©•ä¾¡è¦³ç‚¹ãŒã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚Œã¦ã„ã‚‹ã€‚<br>è¦ç´„ã‚’ä¿®æ­£ã—ä¿®æ­£ç®‡æ‰€ã‚’èª¬æ˜ã™ã‚‹ã‚¿ã‚¹ã‚¯ã€å…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰æŠ½è±¡çš„ãªæ•™è¨“ã‚’è¿°ã¹ã‚‹ã‚¿ã‚¹ã‚¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æ±²ã¿å½¹ã«ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æŒ¯ã‚‹èˆã†ã‚¿ã‚¹ã‚¯ã€å ´åˆåˆ†ã‘ã‚’å¿…è¦ã¨ã™ã‚‹è¤‡é›‘ãªç®—æ•°ã®ã‚¿ã‚¹ã‚¯ã€æœªçŸ¥ã®è¨€èªã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—æ—¥æœ¬èªè¨³ã™ã‚‹é«˜åº¦ãªæ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã€è¤‡æ•°ã®æŒ‡ç¤ºã‚’è¸ã¾ãˆãŸä¸Šã§youtubeã®å¯¾è©±ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã€æ¶ç©ºã®ç”Ÿãç‰©ã‚„ç†Ÿèªã«é–¢ã™ã‚‹ç”Ÿæˆãƒ»å¤§å–œåˆ©ãªã©ã®æƒ³åƒåŠ›ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ãªã©ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã€‚ | ELYZA |
| [Preferred Generation Benchmark<br>(pfgen-bench)](https://github.com/pfnet-research/pfgen-bench) | 50 å•ã®æ—¥æœ¬èªåœç‰¹æœ‰ã®å¸¸è­˜å•é¡Œã‚’ã‚‚ã¨ã«ã€LLMã®æ—¥æœ¬èªç”Ÿæˆèƒ½åŠ›ã‚’ Fluency(æµæš¢ã•)ã€Truthfulness(çœŸå®Ÿæ€§)ã€Helpfulness(æœ‰ç”¨æ€§)ã®3ã¤ã®è©•ä¾¡è»¸ã‹ã‚‰è¨ˆæ¸¬ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚n-gram ã‚„ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã®æŒ‡æ¨™ã®è¨ˆç®—ã‚’è¡Œã†ã“ã¨ã«ã‚ˆã‚Šã€LLM-as-a-Judge ã‚’è¡Œã‚ãšã«è©•ä¾¡ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã®ãŒç‰¹å¾´ã§ã‚ã‚‹ã€‚ | Preferred Elements (Preferred Networks) |
| <a id="rakuda-benchmark"></a> [Rakuda Benchmark](https://github.com/yuzu-ai/japanese-llm-ranking) | æ—¥æœ¬ã®åœ°ç†ã€æ­´å²ã€æ”¿æ²»ã€ç¤¾ä¼šã«é–¢ã™ã‚‹[40å•ã®è‡ªç”±è³ªå•](https://huggingface.co/datasets/yuzuai/rakuda-questions)ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ã«å‡ºåŠ›ã‚’è¡Œã‚ã›ã‚‹ã€‚GPT-4 ãŒåŒã˜è³ªå•ã«å¯¾ã™ã‚‹2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’æ¯”ã¹ã€ã©ã¡ã‚‰ã®ç­”ãˆãŒå„ªã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚¯ä»˜ã‘ã‚’è¡Œã†ã€‚ | YuzuAI |
| [Japanese Vicuna QA Benchmark](https://github.com/ku-nlp/ja-vicuna-qa-benchmark) | MT-Bench ã®å‰èº«ã§ã‚ã‚‹ [vicuna-blog-eval](https://github.com/lm-sys/vicuna-blog-eval) ã®æ—¥æœ¬èªç‰ˆã€‚ä¸€èˆ¬ã€çŸ¥è­˜ã€ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã€å¸¸è­˜ã€ãƒ•ã‚§ãƒ«ãƒŸæ¨å®šã€åå®Ÿä»®æƒ³ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€æ•°å­¦ã€ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã«é–¢ã™ã‚‹ 80 å•ã®è³ªå•ã‚’åéŒ²ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€GPT-4 ã«ã‚ˆã‚‹è‡ªå‹•è©•ä¾¡ï¼ˆå‹ç‡è¨ˆç®—ï¼‰ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¯[ã“ã¡ã‚‰](http://wandb.me/llm-jp-vicunaleaderboard) | äº¬å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢ç ”ç©¶å®¤ |
| <a id="tengu-bench"></a> [Tengu-Bench](https://huggingface.co/datasets/lightblue/tengu_bench) | æ§˜ã€…ãªã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æˆã‚‹ 120 å•ã®è‡ªç”±è³ªå•ãŒåéŒ²ã•ã‚Œã¦ã„ã‚‹ã€‚è³ªå•ã®ã‚«ãƒ†ã‚´ãƒªã¯ä»¥ä¸‹ã®é€šã‚Š: è¡¨ã®èª­ã¿å–ã‚Šã€è«–ç†ãƒ‘ã‚ºãƒ«ã€ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã€Function callingã€é•·ã„æ–‡æ›¸è¦ç´„ï¼ˆåƒãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Šï¼‰ã€ä¼šè©±è¦ç´„ã€é•·ã„æ–‡æ›¸ã®Closed QAï¼ˆåƒãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Šï¼‰ã€æ•¬èªã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆã€æ•°å­¦ã€ç¿»è¨³ã€æŠ½å‡ºã€å€«ç†çš„åˆ¶å¾¡ã€ã‚³ã‚¹ãƒˆè¦‹ç©ã€æ—¥æœ¬ã€é›‘è«‡ã€ãƒ€ã‚¸ãƒ£ãƒ¬ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€å»ºè¨­ã€ãƒ“ã‚¸ãƒã‚¹ã€æ³•å¾‹åˆ¤æ–­ã€æ”¿æ²»ã€æ¶ç©ºã®è³ªå• | Lightblue |
| [Shaberi](https://github.com/lightblue-tech/japanese_llm_eval) | [Japanese MT-bench](#jp-mt-bench)ã€[Rakuda Benchmark](#rakuda-benchmark)ã€[ELYZA-tasks-100](#elyza-tasks)ã€[Tengu-Bench](#tengu-bench) ã®è©•ä¾¡ã‚’ã¾ã¨ã‚ã¦è¡Œã†ã“ã¨ãŒã§ãã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ãªãŠã€Shisa.AI ã«ã‚ˆã‚‹[ãƒ•ã‚©ãƒ¼ã‚¯](https://github.com/shisa-ai/shaberi)ã‚‚å­˜åœ¨ã™ã‚‹ | Lightblue |

<a id="domain-specific-benchmark-suites"></a>
### ç‰¹å®šãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [Japanese Language Model Financial Evaluation Harness](https://github.com/pfnet-research/japanese-lm-fin-harness) | é‡‘èåˆ†é‡ã«ãŠã‘ã‚‹æ—¥æœ¬èª LLM ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚é‡‘èåˆ†é‡ã«ãŠã‘ã‚‹æ„Ÿæƒ…åˆ†æã‚¿ã‚¹ã‚¯(chabsa)ã€è¨¼åˆ¸åˆ†æã«ãŠã‘ã‚‹åŸºç¤çŸ¥è­˜ã‚¿ã‚¹ã‚¯(cma_basics)ã€å…¬èªä¼šè¨ˆå£«è©¦é¨“ã«ãŠã‘ã‚‹ç›£æŸ»ã«é–¢ã™ã‚‹ã‚¿ã‚¹ã‚¯(cpa_audit)ã€ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚·ãƒ£ãƒ«ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼è©¦é¨“ã®é¸æŠè‚¢å•é¡Œã®ã‚¿ã‚¹ã‚¯(fp2)ã€è¨¼åˆ¸å¤–å‹™å“¡è©¦é¨“ã®æ¨¡æ“¬è©¦é¨“ã‚¿ã‚¹ã‚¯(security_sales_1)ã‚’å«ã‚€ã€‚è©³ç´°ã¯[ã“ã¡ã‚‰](https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/C6-4.pdf)ã‚’å‚ç…§ | Preferred Networks |
| [pfmt-bench-fin-ja](https://github.com/pfnet-research/pfmt-bench-fin-ja) | é‡‘èåˆ†é‡ã«ãŠã‘ã‚‹æ—¥æœ¬èª LLM ã®ç”Ÿæˆèƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ | Preferred Networks |
| [Stockmark Business Questions](https://huggingface.co/datasets/stockmark/business-questions) | å¸‚å ´å‹•å‘ã€æ™‚äº‹å•é¡Œã€ç¤¾ä¼šèª²é¡Œã€ãƒ“ã‚¸ãƒã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ãªã©ã®çŸ¥è­˜ã‚’å•ã†å•é¡ŒãŒ50é¡ŒåéŒ²ã•ã‚Œã¦ã„ã‚‹ã€‚ | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ |
| <a id="jmedllm"></a> [JMED-LLM](https://github.com/sociocom/JMED-LLM) | æ—¥æœ¬èªåŒ»ç™‚åˆ†é‡ã«ãŠã‘ã‚‹ LLM ã®è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ã“ã‚Œã¾ã§ã«é–‹ç™ºã•ã‚Œã¦ããŸæ—¥æœ¬èªã®åŒ»ç™‚è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ LLM ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ã«ã¾ã¨ã‚ã¦ã„ã‚‹ã€‚ | NAIST ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç ”ç©¶å®¤ |
| [JMedBench](https://huggingface.co/datasets/Coldog2333/JMedBench) | æ—¥æœ¬èªåŒ»ç™‚åˆ†é‡ã® LLM ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚é¸æŠè‚¢å•é¡Œã€æ©Ÿæ¢°ç¿»è¨³ã€å›ºæœ‰è¡¨ç¾æŠ½å‡ºã€æ–‡æ›¸åˆ†é¡ã€æ–‡é¡ä¼¼åº¦è¨ˆç®—ã® 5 ç¨®é¡ã€è¨ˆ 20 å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒåéŒ²ã•ã‚Œã¦ã„ã‚‹ï¼ˆä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ [JMMLU](#jmmlu) ã®åŒ»ç™‚åˆ†é‡å•é¡Œã‚„ [JMED-LLM](#jmedllm) ã‹ã‚‰å€Ÿç”¨ã•ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ã¾ãŸã€JMedBench ã§ã®è©•ä¾¡ã‚’ç°¡å˜ã«è¡Œã†ãŸã‚ã®ãƒ„ãƒ¼ãƒ« [med-eval](https://github.com/nii-nlp/med-eval) ãŒé–‹ç™ºã•ã‚Œã¦ã„ã‚‹ã€‚ | NII ç›¸æ¾¤ç ” |
| [Japanese Medical Language Model Evaluation Harness](https://github.com/stardust-coder/japanese-lm-med-harness) | ãƒ¯ãƒ³ã‚³ãƒãƒ³ãƒ‰ã§å®Ÿè¡Œå¯èƒ½ãªåŒ»ç™‚åˆ†é‡ã«ç‰¹åŒ–ã—ãŸLLMã®æ—¥è‹±èƒ½åŠ›è©•ä¾¡ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‚ | å€‹äºº ([â€‹åŠ©ç”°ä¸€æ™Ÿ](https://scholar.google.co.jp/citations?user=Dc_v0BsAAAAJ)) |
| [YakugakuQA](https://github.com/EQUES-Inc/pharma-LLM-eval) | è–¬å‰¤å¸«å›½å®¶è©¦é¨“ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸæ—¥æœ¬èªè£½è–¬åˆ†é‡ã®çŸ¥è­˜ã‚’å•ã†è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚äº‹å®Ÿã«åŸºã¥ãè–¬å­¦çŸ¥è­˜ã‚’æ¸¬å®šã™ã‚‹ã€‚ | EQUES Inc. |
| [NayoseQA](https://github.com/EQUES-Inc/pharma-LLM-eval) | æ—¥æœ¬èªè£½è–¬åˆ†é‡ã§ã®å¤šè¨€èªé–“ç”¨èªå¯¾å¿œãƒ»æ­£è¦åŒ–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚åŒç¾©èªã‚„å°‚é–€ç”¨èªã®ç†è§£åº¦ã‚’æ¸¬å®šã™ã‚‹ã€‚ | EQUES Inc. |
| [SogoCheck](https://github.com/EQUES-Inc/pharma-LLM-eval) | å¯¾ã¨ãªã‚‹æ–‡ç« é–“ã®ä¸€è²«æ€§æ¨è«–ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã€‚GPT-4oã§ã‚‚æ€§èƒ½ãŒä½ã„é«˜é›£åº¦ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã€‚ | EQUES Inc. |
| [karakuri-bench](https://huggingface.co/datasets/karakuri-ai/karakuri-bench-v0.1) | æ—¥æœ¬èª LLM ã®ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã«ãŠã‘ã‚‹æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ | ã‚«ãƒ©ã‚¯ãƒª |

<a id="factuality-safety-benchmark-suites"></a>
### äº‹å®Ÿæ€§ãƒ»å®‰å…¨æ€§ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [JTruthfulQA](https://github.com/nlp-waseda/JTruthfulQA) | LLM ã®äº‹å®Ÿæ€§ã‚’è©•ä¾¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ [TruthfulQA](https://github.com/sylinrl/TruthfulQA) ã®æ—¥æœ¬èªç‰ˆã€‚è¿·ä¿¡ãªã©ã®ã€ä¸€éƒ¨ã®äººã€…ã«ä¿¡ã˜ã‚‰ã‚Œã¦ã„ã‚‹ãŒäº‹å®Ÿã¨ã¯è¨€ãˆãªã„äº‹è±¡ã«é–¢ã™ã‚‹è³ªå•ç¾¤ã¨ã€æ—¥æœ¬å›ºæœ‰ã®çŸ¥è­˜ã«é–¢ã™ã‚‹è³ªå•ç¾¤ãŒã€ä¸€ã‹ã‚‰åé›†ã•ã‚Œã¦ã„ã‚‹ã€‚ | æ—©å¤§ æ²³åŸç ” |
| [JCommonsenseMorality](https://github.com/Language-Media-Lab/commonsense-moral-ja/blob/main/README_JP.md) | æ—¥æœ¬èªã®å¸¸è­˜é“å¾³ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚è¡Œç‚ºã‚’è¡¨ã™æ–‡ã«å¯¾ã—ã¦ã€é“å¾³çš„ã«é–“é•ã£ã¦ã„ã‚‹ã‹è¨±å®¹ã§ãã‚‹ã‹ã® 2 å€¤ãƒ©ãƒ™ãƒ«ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ | åŒ—å¤§ è¨€èªãƒ¡ãƒ‡ã‚£ã‚¢å­¦ç ”ç©¶å®¤ |
| [JBBQ](https://github.com/ynklab/JBBQ_data) | ç¤¾ä¼šæ€§ãƒã‚¤ã‚¢ã‚¹QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ [BBQ](https://github.com/nyu-mll/BBQ) ã‚’ã€æ—¥æœ¬ã®æ–‡åŒ–ãƒ»æ…£ç¿’ã‚’è¸ã¾ãˆã¦ç¿»è¨³ã€ä¿®æ­£ã€å•é¡Œè¿½åŠ ã‚’è¡Œã„ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ | æ±å¤§ è°·ä¸­ç ” |

<a id="logical-reasoning-benchmark-suites"></a>
### è«–ç†æ¨è«–èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [JFLD (Japanese Formal Logic Deduction)](https://aclanthology.org/2024.lrec-main.832/) | æ—¥æœ¬èª LLM ã®æ¼”ç¹¹æ¨è«–èƒ½åŠ›ã‚’å•ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆåŒè‘—è€…ã‚‰ãŒææ¡ˆã—ã¦ã„ã‚‹ [FLD (Formal Logic Deduction)](https://github.com/hitachi-nlp/FLD) ã®æ—¥æœ¬èªç‰ˆï¼‰ã€‚LLM ãŒæŒã¤çŸ¥è­˜ã¨åˆ‡ã‚Šåˆ†ã‘ã¦è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã«ã€åå®Ÿä»®æƒ³çš„ãªã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã®ãŒç‰¹å¾´ã§ã‚ã‚‹ã€‚ | æ—¥ç«‹è£½ä½œæ‰€ |
| [JHumanEval](https://huggingface.co/datasets/kogi-jwu/jhumaneval) | è‹±èªã®æŒ‡ç¤ºã‹ã‚‰ Python ã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ [HumanEval](https://huggingface.co/datasets/openai/openai_humaneval) ã®æ—¥æœ¬èªç‰ˆã€‚æ—¥æœ¬èªç‰ˆã‚’ä½œæˆã™ã‚‹éš›ã«ã¯ã€ã¾ãšæ©Ÿæ¢°ç¿»è¨³ã«ã‹ã‘ãŸã‚ã¨ã€äººæ‰‹ã§ã®ä¿®æ­£ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚ | æ—¥æœ¬å¥³å­å¤§ å€‰å…‰ç ” |
| [JMultiPL-E](https://huggingface.co/datasets/tohoku-nlp/JMultiPL-E) | OpenAI HumanEval ã‚’ãƒ™ãƒ¼ã‚¹ã« 17 ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªï¼ˆC++, C#, Go, Java, JavaScript, PHP, Ruby, Rust, Scala, Swift, TypeScript ãªã©ï¼‰ã§ã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚å¤šè¨€èªã§ã®ã‚³ãƒ¼ãƒ‰ç†è§£ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹ã€‚| æ±åŒ—å¤§ è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ— |

<a id="controllabilitiy-benchmark-suites"></a>
### åˆ¶ç´„ä»˜ãã®ç”Ÿæˆèƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [LCTG Bench](https://github.com/CyberAgentAILab/LCTG-Bench) | æ—¥æœ¬èª LLM ã®åˆ¶å¾¡æ€§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚å‡ºåŠ›ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€æ–‡å­—æ•°ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€NGãƒ¯ãƒ¼ãƒ‰ã® 4 ã¤ã®è¦³ç‚¹ã‹ã‚‰ã€LLM ãŒåˆ¶ç´„ã‚’å®ˆã£ã¦å‡ºåŠ›ã‚’è¡Œãˆã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ã€‚ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚‚åˆã‚ã›ã¦è©•ä¾¡ã™ã‚‹ã€‚ | ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ |

<a id="embeddings-benchmark-suites"></a>
### åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [JMTEB](https://www.sbintuitions.co.jp/blog/entry/2024/05/16/130848) | [MTEB](https://github.com/embeddings-benchmark/mteb)ã®æ—¥æœ¬èªç‰ˆã¨ã—ã¦ä½œæˆã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br>æ–‡æ›¸ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€æ–‡æ›¸åˆ†é¡ã€æ–‡é–“é¡ä¼¼åº¦ã€æ–‡ãƒšã‚¢ãƒ©ãƒ™ãƒ«äºˆæ¸¬ã€æ–‡æ›¸æŠ½å‡ºã®5ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã‚‹ï¼ˆãã®å¾Œã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ãŒæ–°ãŸã«è¿½åŠ ï¼‰ã€‚ | SB Intuitions |
| [JQaRA](https://github.com/hotchpotch/JQaRA/) | æ—¥æœ¬èªã®æ–‡æ›¸æŠ½å‡ºãƒ»ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ç²¾åº¦è©•ä¾¡ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚1,667ä»¶ã®è³ªå•æ–‡ãã‚Œãã‚Œã«å¯¾ã—ã€å€™è£œã¨ãªã‚‹100ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ãŠã‚Šã€ãã®ã†ã¡1ä»¶ä»¥ä¸ŠãŒè³ªå•æ–‡ã«å›ç­”ã§ãã‚‹å†…å®¹ã«ãªã£ã¦ã„ã‚‹ã€‚è³ªå•æ–‡ã¯ [JAQKET](https://www.nlp.ecei.tohoku.ac.jp/projects/jaqket/) ã‚’ã€å€™è£œã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯æ—¥æœ¬èª Wikipedia ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚ | å€‹äºº (èˆ˜é‡ç¥ä¸€) |
| [JaCWIR](https://github.com/hotchpotch/JaCWIR) | Wikipedia ä»¥å¤–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§æ–‡æ›¸æŠ½å‡ºãƒ»ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®è©•ä¾¡ã‚’è¡Œãˆã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚5,000ä»¶ã®è³ªå•æ–‡ãã‚Œãã‚Œã«å¯¾ã—ã€ãã®è³ªå•æ–‡ãŒä½œæˆã•ã‚Œã‚‹å…ƒã«ãªã£ãŸ 1 ä»¶ã® Webãƒšãƒ¼ã‚¸ã¨ã€è³ªå•æ–‡ã¨ã¯é–¢ä¿‚ã®ãªã„ 99 ä»¶ã® Web ãƒšãƒ¼ã‚¸ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚| å€‹äºº (èˆ˜é‡ç¥ä¸€) |

<a id="vl-benchmark-suites"></a>
### è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ« (Vision-Language Models) ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|   | èª¬æ˜ | é–‹ç™ºå…ƒ |
|:---|:---|:---:|
| [llm-jp-eval-mm](https://github.com/llm-jp/llm-jp-eval-mm) | æ—¥æœ¬èªVLMã®æ€§èƒ½ã‚’è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ« | å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç ”ç©¶é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼ |
| [BusinessSlideVQA](https://github.com/stockmarkteam/business-slide-questions) | è¤‡é›‘ãªæ—¥æœ¬èªãƒ“ã‚¸ãƒã‚¹ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã«é–¢ã™ã‚‹220å•ã®è³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚æ–‡æ›¸ç†è§£èƒ½åŠ›ã®è©•ä¾¡ã‚’ç›®çš„ã¨ã—ã¦è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã€‚ | ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ |
| [JMMMU](https://mmmu-japanese-benchmark.github.io/JMMMU/) | [MMMU ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](https://mmmu-benchmark.github.io/)ã®æ—¥æœ¬èªç‰ˆã¨ã—ã¦æ§‹ç¯‰ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚720 ä»¶ã® MMMU ã®ç¿»è¨³ç‰ˆã®å•é¡Œã¨ 600 ä»¶ã®æ—¥æœ¬æ–‡åŒ–ç‰¹æœ‰ã®æ–°è¦ã®å•é¡Œã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚ | æ±å¤§ ç›¸æ¾¤ç ” |
| [JDocQA](https://github.com/mizuumi/JDocQA) | æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆãƒ‘ãƒ³ãƒ•ãƒ¬ãƒƒãƒˆã€ã‚¹ãƒ©ã‚¤ãƒ‰ã€ãƒ¬ãƒãƒ¼ãƒˆã€Web ã‚µã‚¤ãƒˆï¼‰ã‚’ã‚‚ã¨ã«æ§‹ç¯‰ã•ã‚ŒãŸã€åˆè¨ˆ 11,600 ä»¶ã®è³ªå•ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹è³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚è§£ç­”ä¸èƒ½å•é¡Œã‚’å«ã‚ã€æ§˜ã€…ãªè³ªå•å½¢å¼ã®è³ªå•ãŒåéŒ²ã•ã‚Œã¦ã„ã‚‹ã€‚ | NAIST æ¸¡è¾ºç ” |
| [Heron VLM ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ powered by nejumi@WandB](https://api.wandb.ai/links/vision-language-leaderboard/h2lxge4n) | [Japanese-Heron-Bench](#japanese-heron-bench) ã¨ [LLaVA-Bench-In-the-Wild (Japanese)](#llava-bench-in-the-wild) ã®è©•ä¾¡çµæœã‚’ã¾ã¨ã‚ã¦ã„ã‚‹ã€‚ | Turing, Weights & Biases |
| <a id="japanese-heron-bench"></a> [Japanese-Heron-Bench](https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench) | 21 æšã®ç”»åƒã«å¯¾ã—ã¦è¨ˆ 102 å•ã®è³ªå•ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æ—¥æœ¬ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’è¦æ±‚ã™ã‚‹ç”»åƒãƒ»è³ªå•ã«ãªã£ã¦ã„ã‚‹ã®ãŒç‰¹å¾´ã§ã‚ã‚‹ã€‚ | Turing |
| [JA-VLM-Bench-In-the-Wild](https://huggingface.co/datasets/SakanaAI/JA-VLM-Bench-In-the-Wild) | Sakana AI ãŒ EvoVLM-JP-v1-7B ã®è©•ä¾¡ã®ãŸã‚ã«ç‹¬è‡ªã«ç”¨æ„ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚42 æšã®ç”»åƒã«å¯¾ã—ã¦è¨ˆ 50 å•ã®è³ªå•ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æ—¥æœ¬ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’è¦æ±‚ã™ã‚‹ç”»åƒãƒ»è³ªå•ã«ãªã£ã¦ã„ã‚‹ã®ãŒç‰¹å¾´ã§ã‚ã‚‹ã€‚ | Sakana AI |
| [JA-Multi-Image-VQA](https://huggingface.co/datasets/SakanaAI/JA-Multi-Image-VQA) | è¤‡æ•°ã®ç”»åƒã«å¯¾ã™ã‚‹æ—¥æœ¬èªã§ã®è³ªç–‘å¿œç­”èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ | Sakana AI |
| <a id="llava-bench-in-the-wild"></a> [LLaVA-Bench-In-the-Wild (Japanese)](https://github.com/turingmotors/heron/tree/main/playground/data/llava-bench-in-the-wild) | [LLaVA-Bench-In-the-Wild](https://huggingface.co/datasets/liuhaotian/llava-bench-in-the-wild) ã‚’ DeepL ã§æ—¥æœ¬èªã«è¨³ã—ãŸã‚‚ã®ã€‚24 æšã®ç”»åƒã«å¯¾ã—ã¦è¨ˆ 60 å•ã®è³ªå•ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ | Turing |
| [LLaVA-Bench (COCO) Japanese](https://github.com/turingmotors/heron/tree/main/playground/data/llava-bench-ja) | LLaVA ã®è©•ä¾¡ã«ä½¿ã‚ã‚ŒãŸ LLaVA-Bench (COCO) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ DeepL ã§æ—¥æœ¬èªã«è¨³ã—ãŸã‚‚ã®ã€‚30 æšã®ç”»åƒã«å¯¾ã—ã¦å„ 3 ç¨®é¡ã®è³ªå•ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ | Turing |
| [Japanese Visual Genome VQA dataset](https://github.com/yahoojapan/ja-vg-vqa) | [Visual Genome dataset](https://homes.cs.washington.edu/~ranjay/visualgenome/index.html) ã®ç”»åƒã‚’ã‚‚ã¨ã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸè³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® 500 ä»¶ã‚’åˆ‡ã‚Šå‡ºã—ãŸ [JA-VG-VQA-500](https://huggingface.co/datasets/SakanaAI/JA-VG-VQA-500) ãŒ VLM ã®è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦ç”¨ã„ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚ | ãƒ¤ãƒ•ãƒ¼ |

<a id="reference"></a>
## å„ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åŸè«–æ–‡

<!--@include: @/parts/references_model.md-->

<a id="reference-training"></a>
## LLMã®å­¦ç¿’æ‰‹æ³•ã®åŸè«–æ–‡

<!--@include: @/parts/references_training.md-->

<a id="contributors"></a>
## ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«è²¢çŒ®ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼ã®ã¿ãªã•ã‚“ã§ã™ï¼

<a href="https://github.com/llm-jp/awesome-japanese-llm/graphs/contributors" target="_blank" rel="noreferrer">
  <img loading="lazy" src="./figures/contributors.svg" alt="ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼" />
</a>

<a id="citation"></a>
## å¼•ç”¨

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®è¦ç´„ã¯ãƒ—ãƒ¬ãƒ—ãƒªãƒ³ãƒˆã¨ã—ã¦ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™:
[Exploring Open Large Language Models for the Japanese Language: A Practical Guide](https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/682/2035)

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã«ã¤ã„ã¦è¨€åŠã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®é€šã‚Šå¼•ç”¨ã—ã¦ãã ã•ã„:

```
@article{awesomeJapanese2024,
    title={{Exploring Open Large Language Models for the Japanese Language: A Practical Guide}},
    author={Kaito Sugimoto},
    doi={10.51094/jxiv.682},
    journal={Jxiv preprint},
    year={2024}
}
```

[^1]: ãŸã ã—ã€ãƒ¢ãƒ‡ãƒ«é«˜é€ŸåŒ–ã®ãŸã‚æœ¬å®¶ã® Llama ã«å¯¾ã—ã¦ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ã‚’åŠ ãˆã¦ã„ã‚‹ã€‚è©³ã—ãã¯ä»¥ä¸‹ã‚’å‚ç…§: [PLaMo-13Bã‚’å…¬é–‹ã—ã¾ã—ãŸ](https://tech.preferred.jp/ja/blog/llm-plamo/)

[^2]: è©³ç´°ã¯æ˜è¨˜ã•ã‚Œã¦ã„ãªã„ãŒã€ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªè¨˜è¿°ãŒã‚ã‚‹: ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«åŠ ãˆã€Stability AI JapanãŒä½œæˆã—ãŸç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ã€EleutherAI Polyglot project ã®æ—¥æœ¬èªãƒãƒ¼ãƒ åŠã³ Stable Community Japan ã®ãƒ¡ãƒ³ãƒãƒ¼ã®å”åŠ›ã®ã‚‚ã¨ã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã€

[^3]: é€šå¸¸ã®å·¦ã‹ã‚‰å³ã«å˜èªã‚’äºˆæ¸¬ã™ã‚‹ä»£ã‚ã‚Šã«ã€å³ã‹ã‚‰å·¦ã«å˜èªã‚’äºˆæ¸¬ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‚’è¡Œã£ãŸç ”ç©¶ã§ã‚ã‚‹ã€‚é€šå¸¸æ–¹å‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¨é€†æ–¹å‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚

[^4]: â—‹: HuggingFace ã® Model Hub ã«ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ãŠã‚Šã€`AutoModel.from_pretrained()` ç­‰ã§ã™ãèª­ã¿è¾¼ã‚ã‚‹ã€‚ â–³: Model Hub ã«ã¯ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŒã€HuggingFace (transformers, æ—§ pytorch-transformers) ã®å½¢å¼ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚âœ•: ãƒ¢ãƒ‡ãƒ«ãŒHuggingFaceã«å¯¾å¿œã—ã¦ã„ãªã„ã€‚

[^5]: ãŸã ã—ã€æœ€å¤§ç³»åˆ—é•·ãŒ 2048 ã«æ‹¡å¼µã•ã‚Œã¦ã„ã‚‹ã»ã‹ã€å…ƒã® BERT ã«å¯¾ã—ã¦æ§˜ã€…ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ãŒæ–½ã•ã‚Œã¦ã„ã‚‹ã€‚è©³ã—ãã¯ HuggingFace ãƒªãƒã‚¸ãƒˆãƒªã® README ã‚’å‚ç…§ã€‚

[^6]: æ§˜ã€…ãªå½¢æ…‹ç´ è§£æå™¨ã¨ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰åŒ–æ‰‹æ³•ã®çµ„ã¿åˆã‚ã›ã‚’è©¦ã—ãŸç ”ç©¶ã§ã‚ã‚‹ã€‚å…¨ã¦ã®çµ„ã¿åˆã‚ã›ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ²è¼‰ã™ã‚‹ã®ã¯å¤§å¤‰ãªã®ã§ã€ã“ã“ã§ã¯å®Ÿé¨“ã§æœ€ã‚‚å¹³å‡ã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ãŒé«˜ã„ Juman++ + BPE ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä»£è¡¨ã¨ã—ã¦æ²è¼‰ã—ã¦ã„ã‚‹ã€‚

[^7]: nlp-waseda/roberta-base-japanese åŠã³ nlp-waseda/roberta-large-japanese ã¯ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³é•·ã‚’128ã§äº‹å‰å­¦ç¿’ã—ã¦ã„ã‚‹ãŒã€nlp-waseda/roberta-large-japanese-seq512 ã¯512ã§äº‹å‰å­¦ç¿’ã—ã¦ã„ã‚‹

[^8]: ãŸã ã—ã€æœ€å¤§ç³»åˆ—é•·ãŒé€šå¸¸ã® 512 ã‹ã‚‰ 1282 ã¾ã§æ‹¡å¼µã•ã‚Œã¦ãŠã‚Šã€ã‚ˆã‚Šé•·ã„å…¥åŠ›æ–‡ã‚’æ‰±ã†ã“ã¨ãŒã§ãã‚‹

[^9]: small ã®æ–¹ã¯æ—¥æœ¬èª Wikipedia ã¨æ—¥æœ¬èªé‡‘èã‚³ãƒ¼ãƒ‘ã‚¹ã‚’åˆã‚ã›ã¦ã‚¹ã‚¯ãƒ©ãƒƒãƒå­¦ç¿’ã—ã¦ã„ã‚‹ãŒã€base ã®æ–¹ã¯æ±åŒ—å¤§BERTã«æ—¥æœ¬èªé‡‘èã‚³ãƒ¼ãƒ‘ã‚¹ã‚’è¿½åŠ å­¦ç¿’ã—ã¦ã„ã‚‹ã¨ã„ã†é•ã„ãŒã‚ã‚‹

[^10]: ä¸‡ç—…WordPieceãƒ¢ãƒ‡ãƒ«ã¯ MeCab (IPAè¾æ›¸+ä¸‡ç—…è¾æ›¸) ã§å˜èªåˆ†å‰²ã—ãŸå¾Œ WordPiece ã§ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰åŒ–ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã€SentencePieceãƒ¢ãƒ‡ãƒ«ã¯å˜èªåˆ†å‰²ã›ãšã«ç›´æ¥ Unigram ã§ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰åŒ–ã™ã‚‹ãƒ¢ãƒ‡ãƒ«

[^11]: Instruction Tuning ã‚’è¡Œã£ãŸå¾Œã«ã€Llama 3 Instruct ã¨ Llama 3 Base ã®å·®åˆ†ã® Chat Vector ã‚’åŠ ãˆã¦ã„ã‚‹ã€‚

[^12]: Instruction Tuning ã«ãŠã„ã¦ã€GPT-3.5, GPT-4 ç­‰ã® OpenAI ã®ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦å­¦ç¿’ã—ã¦ã„ã‚‹ãŸã‚ã€OpenAI ã®è¦ç´„ã«é•åã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

[^13]: ãŸã ã—ã€KARAKURI LM ã‚’å•†ç”¨åˆ©ç”¨ã—ãŸã„å ´åˆã¯ã€é–‹ç™ºå…ƒã§ã‚ã‚‹ã‚«ãƒ©ã‚¯ãƒªæ ªå¼ä¼šç¤¾ã«ç›´æ¥é€£çµ¡ãŒå¿…è¦ã§ã‚ã‚‹ã¨ã—ã¦ã„ã‚‹ã€‚

[^14]: ãŸã ã—ã€ç ”ç©¶ãŠã‚ˆã³æ•™è‚²ã‚’ç›®çš„ã¨ã—ãŸåˆ©ç”¨ã‚’å¿µé ­ã«ç½®ãã‚ˆã†å‘¼ã³ã‹ã‘ã¦ã„ã‚‹ã€‚ã¾ãŸã€ãƒãƒ¼ã‚¸å…ƒã®ãƒ¢ãƒ‡ãƒ«ã®ã„ãã¤ã‹ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯ Apache 2.0 ã§ã¯ãªã„ç‚¹ã«ã‚‚æ³¨æ„ã™ã‚‹ã“ã¨ã€‚

[^15]: è©³ç´°ã¯ä»¥ä¸‹ã®ãƒ“ãƒ‡ã‚ªã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹: [æ¾å°¾ç ” GENIAC LLMé–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ç¬¬1ãƒ•ã‚§ãƒ¼ã‚ºçµæœç™ºè¡¨ä¼š 2024.06.01 @ æ±äº¬å¤§å­¦ ç¦æ­¦ãƒ›ãƒ¼ãƒ« @ 58:22](https://youtu.be/Ju_KgrGhANY?si=zUhZ1S6dznGeF0Gi&t=3502)

[^16]: ãŸã ã—ã€é€šå¸¸ã® BERT (base) ã¨æ¯”ã¹ã¦ Layer ã‚„ Attention Head ã®æ•°ãŒå°‘ãªã„ã€‚

[^17]: Instruction Tuning ã‚’è¡Œã†å‰ã«ã€Llama 3 Instruct ã¨ Llama 3 Base ã®å·®åˆ†ã® Chat Vector ã‚’åŠ ãˆã¦ã„ã‚‹ã€‚

[^18]: ãã‚Œãã‚Œã®ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ã¯ä½œè€…ã‚‰ã®[è«–æ–‡](https://www.jstage.jst.go.jp/article/jnlp/31/2/31_707/_pdf/-char/ja)ã®ç¬¬4ç« ã‚’å‚ç…§ã€‚ãªãŠã€SC-2M-wiki ãƒ¢ãƒ‡ãƒ«ã¯ Wikipedia ã§ã®ã¿äº‹å‰å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å³å¯†ã«ã¯ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã€‚

[^19]: è©³ç´°ã¯ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚ç…§: [å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«Tanuki-8B, 8x8Bã®ä½ç½®ã¥ã‘ã‚„é–‹ç™ºæŒ‡é‡ãªã©](https://zenn.dev/matsuolab/articles/377f7ae8b1169e), [å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã™ã‚‹ã«ã‚ãŸã£ã¦ã®äº‹å‰ãƒ»äº‹å¾Œå­¦ç¿’ã®æˆ¦ç•¥ãƒ¡ãƒ¢ãƒ¼ç‰¹ã«åˆæˆãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ãƒ¼](https://zenn.dev/matsuolab/articles/34036f017fae9e)

[^20]: ORPO ã‚’è¡Œã†å‰ã«ã€Gemma 2 Instruct ã¨ Gemma 2 Base ã®å·®åˆ†ã® Chat Vector ã‚’åŠ ãˆã¦ã„ã‚‹ã€‚

[^21]: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆ†é¡ã¯ [Dense Text Retrieval based on Pretrained Language Models: A Survey (Zhao+, 2022)](https://arxiv.org/abs/2211.14876) ã‚’å‚è€ƒã«è¡Œã£ãŸã€‚Bi-Encoder ã¯ 2ã¤ã®å…¥åŠ›ã‚’å€‹åˆ¥ã«ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã—ã€ãã‚Œãã‚Œãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ãŸä¸Šã§ã€ãã‚Œã‚‰ã®å†…ç©ã‚„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’å…¥åŠ›ã®è¿‘ã•ã¨ã—ã¦å®šå¼åŒ–ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹ã€‚ãã‚Œã«å¯¾ã—ã€Cross-Encoder ã¯ 2 ã¤ã®å…¥åŠ›ã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®ã‚’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã—ã€ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã§è¿‘ã•ã‚’ç›´æ¥è¨ˆç®—ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹ã€‚æƒ…å ±æŠ½å‡ºã®åˆ†é‡ã§ã¯ã€Cross-Encoder ã®æ–¹ãŒè¨ˆç®—ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ãŒã€å…¥åŠ›ã®è¿‘ã•ã‚’ã‚ˆã‚Šãã‚ç´°ã‹ããƒ¢ãƒ‡ãƒ«ãŒè¨ˆç®—ã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ãŸã‚ã€æŠ½å‡ºçµæœã®é †åºã‚’å†æ¤œè¨ã™ã‚‹ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã¨ã—ã¦ç”¨ã„ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚å¤šã„ã€‚ãªãŠã€Bi-Encoder ã®ä¸­ã§ã‚‚ã€å…¥åŠ›ã‚’å˜ä¸€ã®ãƒ™ã‚¯ãƒˆãƒ«ã§ã¯ãªãï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ãªã©ã®ï¼‰è¤‡æ•°ã®ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ã‚¿ã‚¤ãƒ—ã®ã‚‚ã®ï¼ˆä¾‹: ColBERTï¼‰ãŒã‚ã‚‹ãŸã‚ã€Single-representation bi-encoders ã¨ Multi-representation bi-encoders ã«ã•ã‚‰ã«ç´°åˆ†åŒ–ã—ã¦ã„ã‚‹ã€‚

[^22]: ä¸€éƒ¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ã‚’åŠ ãˆã¦ã„ã‚‹ã€‚è©³ã—ãã¯ä»¥ä¸‹ã‚’å‚ç…§: [1,000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¦æ¨¡ã®ç‹¬è‡ªLLMã€ŒPLaMo-100Bã€ã®äº‹å‰å­¦ç¿’](https://tech.preferred.jp/ja/blog/plamo-100b/)

[^23]: Llama ã‹ã‚‰ Causal Attention ã‚’å–ã‚Šé™¤ãã“ã¨ã«ã‚ˆã‚Šã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚
